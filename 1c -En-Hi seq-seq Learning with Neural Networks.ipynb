{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MjTMLaX0Un22"
   },
   "source": [
    "# 1 - Sequence to Sequence Learning with Neural Networks\n",
    "<font size = 5>**Hindi to English Translation**</font>\n",
    "\n",
    "<font size = 4> References:</font> \n",
    "- <font size = 4> https://github.com/cfiltnlp/IITB-English-Hindi-PC\n",
    "- <font size = 4> https://github.com/bentrevett/pytorch-seq2seq\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jMIVwQyitAXd"
   },
   "source": [
    "## Import Libraries\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-13T01:38:10.549070Z",
     "iopub.status.busy": "2022-02-13T01:38:10.548896Z",
     "iopub.status.idle": "2022-02-13T01:38:10.551310Z",
     "shell.execute_reply": "2022-02-13T01:38:10.551016Z",
     "shell.execute_reply.started": "2022-02-13T01:38:10.549028Z"
    },
    "id": "uJ_bduoJoSVX",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T22:44:43.072596Z",
     "iopub.status.busy": "2022-04-02T22:44:43.072450Z",
     "iopub.status.idle": "2022-04-02T22:44:43.210242Z",
     "shell.execute_reply": "2022-04-02T22:44:43.209760Z",
     "shell.execute_reply.started": "2022-04-02T22:44:43.072582Z"
    },
    "id": "JiUqMdpCUn24",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.nn.utils import clip_grad_norm_, clip_grad_value_\n",
    "\n",
    "import torchtext \n",
    "from torchtext.vocab import vocab\n",
    "\n",
    "import spacy\n",
    "#import stanza\n",
    "\n",
    "from datasets import load_dataset_builder, load_dataset \n",
    "\n",
    "import numpy as np\n",
    "from collections import Counter, OrderedDict\n",
    "import random\n",
    "import math\n",
    "import time\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import joblib\n",
    "import pickle\n",
    "import swifter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T22:34:34.115668Z",
     "iopub.status.busy": "2022-04-02T22:34:34.115549Z",
     "iopub.status.idle": "2022-04-02T22:34:34.117762Z",
     "shell.execute_reply": "2022-04-02T22:34:34.117326Z",
     "shell.execute_reply.started": "2022-04-02T22:34:34.115655Z"
    },
    "id": "9uY_ZBxdtH_k",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T22:34:34.294918Z",
     "iopub.status.busy": "2022-04-02T22:34:34.294762Z",
     "iopub.status.idle": "2022-04-02T22:34:34.297357Z",
     "shell.execute_reply": "2022-04-02T22:34:34.297039Z",
     "shell.execute_reply.started": "2022-04-02T22:34:34.294903Z"
    },
    "id": "FngugrWKl23D",
    "tags": []
   },
   "outputs": [],
   "source": [
    "folder = Path('/home/harpreet/Insync/google_drive_harpreet/Research/NLP/pytorch-seq2seq')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T22:34:36.446070Z",
     "iopub.status.busy": "2022-04-02T22:34:36.445915Z",
     "iopub.status.idle": "2022-04-02T22:34:36.448430Z",
     "shell.execute_reply": "2022-04-02T22:34:36.448083Z",
     "shell.execute_reply.started": "2022-04-02T22:34:36.446055Z"
    },
    "id": "91gNGmdCvrvp",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pip install -U spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2022-04-02T22:34:36.876321Z",
     "iopub.status.busy": "2022-04-02T22:34:36.876135Z",
     "iopub.status.idle": "2022-04-02T22:34:36.883169Z",
     "shell.execute_reply": "2022-04-02T22:34:36.882775Z",
     "shell.execute_reply.started": "2022-04-02T22:34:36.876306Z"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1644709177244,
     "user": {
      "displayName": "Harpreet Singh",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgoHXww3A9iD3K6JH0yfUWV-xv9zq1wI6_3E9i8yw=s64",
      "userId": "10443507700807192111"
     },
     "user_tz": 360
    },
    "id": "PY9-guO2Un25",
    "outputId": "0078e670-6b14-4d4b-8505-db30d782b966",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('0.11.0', '1.10.0', True, '3.2.4')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torchtext.__version__, torch.__version__, torch.cuda.is_available(), spacy.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wRVU8aBPUn26"
   },
   "source": [
    "# Set Seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T22:34:41.632918Z",
     "iopub.status.busy": "2022-04-02T22:34:41.632375Z",
     "iopub.status.idle": "2022-04-02T22:34:41.635941Z",
     "shell.execute_reply": "2022-04-02T22:34:41.635597Z",
     "shell.execute_reply.started": "2022-04-02T22:34:41.632902Z"
    },
    "id": "vzCQltiuUn26",
    "tags": []
   },
   "outputs": [],
   "source": [
    "SEED = 1234\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-01T00:00:54.606189Z",
     "iopub.status.busy": "2022-02-01T00:00:54.606047Z",
     "iopub.status.idle": "2022-02-01T00:00:54.608419Z",
     "shell.execute_reply": "2022-02-01T00:00:54.608102Z",
     "shell.execute_reply.started": "2022-02-01T00:00:54.606174Z"
    },
    "id": "7OKdOYoVUn28"
   },
   "source": [
    "## Load Data and Tokenize\n",
    "\n",
    "Next, we download and load the train, validation and test data. \n",
    "\n",
    "The dataset we'll be using is the [IIT Bombay English-Hindi Corpus](https://www.cfilt.iitb.ac.in/iitb_parallel/). \n",
    "Anoop Kunchukuttan, Pratik Mehta, Pushpak Bhattacharyya. The IIT Bombay English-Hindi Parallel Corpus. Language Resources and Evaluation Conference. 2018.\n",
    "\n",
    "The datset can be  downloaded from huggingface library as well"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-10T18:33:11.371154Z",
     "iopub.status.busy": "2022-02-10T18:33:11.370992Z",
     "iopub.status.idle": "2022-02-10T18:33:11.373347Z",
     "shell.execute_reply": "2022-02-10T18:33:11.372964Z",
     "shell.execute_reply.started": "2022-02-10T18:33:11.371124Z"
    },
    "id": "LKQ8AxwHl23G",
    "tags": []
   },
   "source": [
    "### Load Data and create DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2022-02-14T07:01:06.626833Z",
     "iopub.status.busy": "2022-02-14T07:01:06.626690Z",
     "iopub.status.idle": "2022-02-14T07:01:06.629995Z",
     "shell.execute_reply": "2022-02-14T07:01:06.629651Z",
     "shell.execute_reply.started": "2022-02-14T07:01:06.626819Z"
    },
    "executionInfo": {
     "elapsed": 28,
     "status": "ok",
     "timestamp": 1644647086115,
     "user": {
      "displayName": "Harpreet Singh",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgoHXww3A9iD3K6JH0yfUWV-xv9zq1wI6_3E9i8yw=s64",
      "userId": "10443507700807192111"
     },
     "user_tz": 360
    },
    "id": "gK0EsgZOl23G",
    "outputId": "78fcf58d-39a0-4b16-a9de-7114364c831f",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndataset_builder = load_dataset_builder('cfilt/iitb-english-hindi')\\nprint(dataset_builder.cache_dir)\\nprint(f'\\n{dataset_builder.info.features}')\\nprint(f'\\n{dataset_builder.info.splits}')\\n\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the datsset without downloading it\n",
    "# need to run this cell only once\n",
    "'''\n",
    "dataset_builder = load_dataset_builder('cfilt/iitb-english-hindi')\n",
    "print(dataset_builder.cache_dir)\n",
    "print(f'\\n{dataset_builder.info.features}')\n",
    "print(f'\\n{dataset_builder.info.splits}')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-14T07:01:07.330073Z",
     "iopub.status.busy": "2022-02-14T07:01:07.329930Z",
     "iopub.status.idle": "2022-02-14T07:01:07.332473Z",
     "shell.execute_reply": "2022-02-14T07:01:07.332063Z",
     "shell.execute_reply.started": "2022-02-14T07:01:07.330058Z"
    },
    "id": "ck4Ll0DLl23H",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# need to run this cell only once\n",
    "#dataset = load_dataset(\"cfilt/iitb-english-hindi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-14T07:01:07.889416Z",
     "iopub.status.busy": "2022-02-14T07:01:07.888877Z",
     "iopub.status.idle": "2022-02-14T07:01:07.891562Z",
     "shell.execute_reply": "2022-02-14T07:01:07.891294Z",
     "shell.execute_reply.started": "2022-02-14T07:01:07.889367Z"
    },
    "id": "xSLbydm0l23H",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# need to run this cell only once\n",
    "#dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-14T07:01:08.230267Z",
     "iopub.status.busy": "2022-02-14T07:01:08.230089Z",
     "iopub.status.idle": "2022-02-14T07:01:08.232555Z",
     "shell.execute_reply": "2022-02-14T07:01:08.232251Z",
     "shell.execute_reply.started": "2022-02-14T07:01:08.230233Z"
    },
    "id": "9soHmZzMtAXg",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# need to run this cell only once\n",
    "#dataset['train'][0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-14T07:01:08.472757Z",
     "iopub.status.busy": "2022-02-14T07:01:08.472626Z",
     "iopub.status.idle": "2022-02-14T07:01:08.474663Z",
     "shell.execute_reply": "2022-02-14T07:01:08.474349Z",
     "shell.execute_reply.started": "2022-02-14T07:01:08.472742Z"
    },
    "id": "UPntMcopl23H",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# need to run this cell only once\n",
    "# pd.DataFrame(dataset['train'][0:2]['translation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2022-02-14T07:01:08.666740Z",
     "iopub.status.busy": "2022-02-14T07:01:08.666598Z",
     "iopub.status.idle": "2022-02-14T07:01:08.669838Z",
     "shell.execute_reply": "2022-02-14T07:01:08.669427Z",
     "shell.execute_reply.started": "2022-02-14T07:01:08.666726Z"
    },
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1644647087670,
     "user": {
      "displayName": "Harpreet Singh",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgoHXww3A9iD3K6JH0yfUWV-xv9zq1wI6_3E9i8yw=s64",
      "userId": "10443507700807192111"
     },
     "user_tz": 360
    },
    "id": "UStEOeBll23H",
    "outputId": "0c20a997-ec08-4268-cf3b-f22f413b5670",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndf={}\\nfor split in ['train', 'validation', 'test']:\\n    df[split] = pd.DataFrame(dataset[split]['translation'])\\n\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## need to run this cell only once\n",
    "# Note : There is a better and easier way of converting HUgging Face Datsets to Pandas and viceversa\n",
    "'''\n",
    "df={}\n",
    "for split in ['train', 'validation', 'test']:\n",
    "    df[split] = pd.DataFrame(dataset[split]['translation'])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-14T07:01:09.295755Z",
     "iopub.status.busy": "2022-02-14T07:01:09.295599Z",
     "iopub.status.idle": "2022-02-14T07:01:09.298167Z",
     "shell.execute_reply": "2022-02-14T07:01:09.297693Z",
     "shell.execute_reply.started": "2022-02-14T07:01:09.295740Z"
    },
    "id": "Iqm5oCHCl23I",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#df['train'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-14T07:01:09.521226Z",
     "iopub.status.busy": "2022-02-14T07:01:09.521054Z",
     "iopub.status.idle": "2022-02-14T07:01:09.524377Z",
     "shell.execute_reply": "2022-02-14T07:01:09.524034Z",
     "shell.execute_reply.started": "2022-02-14T07:01:09.521211Z"
    },
    "id": "DMupUWi2l23I",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# need to run this cell only once\n",
    "#df['train'].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-14T07:01:09.729238Z",
     "iopub.status.busy": "2022-02-14T07:01:09.729101Z",
     "iopub.status.idle": "2022-02-14T07:01:09.731294Z",
     "shell.execute_reply": "2022-02-14T07:01:09.730984Z",
     "shell.execute_reply.started": "2022-02-14T07:01:09.729224Z"
    },
    "id": "heXF40iFl23I",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# need to run this cell only once\n",
    "#df['test'].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-14T07:01:09.879045Z",
     "iopub.status.busy": "2022-02-14T07:01:09.878920Z",
     "iopub.status.idle": "2022-02-14T07:01:09.881282Z",
     "shell.execute_reply": "2022-02-14T07:01:09.880857Z",
     "shell.execute_reply.started": "2022-02-14T07:01:09.879031Z"
    },
    "id": "Z9MhWM6Zl23I",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# need to run this cell only once\n",
    "#df['validation'].head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z8HEHfMGl23I",
    "tags": []
   },
   "source": [
    "### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-14T07:01:10.736410Z",
     "iopub.status.busy": "2022-02-14T07:01:10.736172Z",
     "iopub.status.idle": "2022-02-14T07:01:10.739101Z",
     "shell.execute_reply": "2022-02-14T07:01:10.738567Z",
     "shell.execute_reply.started": "2022-02-14T07:01:10.736378Z"
    },
    "id": "eboUqZ8HUn28",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# need to run this cell only once\n",
    "#nlp_en = stanza.Pipeline(lang='en', processors = 'tokenize', tokenize_no_split = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-14T07:01:10.944409Z",
     "iopub.status.busy": "2022-02-14T07:01:10.944044Z",
     "iopub.status.idle": "2022-02-14T07:01:10.946314Z",
     "shell.execute_reply": "2022-02-14T07:01:10.945900Z",
     "shell.execute_reply.started": "2022-02-14T07:01:10.944393Z"
    },
    "id": "uIiToCCOl23J",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# need to run this cell only once\n",
    "#nlp_hi = stanza.Pipeline(lang='hi', processors = 'tokenize', tokenize_no_split = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dqPoMmkOUn29"
   },
   "source": [
    "Next, we create the tokenizer functions. These can be passed to torchtext and will take in the sentence as a string and return the sentence as a list of tokens.\n",
    "\n",
    "<font color = 'red'>**In the paper we are implementing, they find it beneficial to reverse the order of the input which they believe \"introduces many short term dependencies in the data that make the optimization problem much easier\".We copy this by reversing the German sentence after it has been transformed into a list of tokens.**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2022-02-14T07:01:12.056688Z",
     "iopub.status.busy": "2022-02-14T07:01:12.056546Z",
     "iopub.status.idle": "2022-02-14T07:01:12.060116Z",
     "shell.execute_reply": "2022-02-14T07:01:12.059724Z",
     "shell.execute_reply.started": "2022-02-14T07:01:12.056674Z"
    },
    "executionInfo": {
     "elapsed": 33,
     "status": "ok",
     "timestamp": 1644647090035,
     "user": {
      "displayName": "Harpreet Singh",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgoHXww3A9iD3K6JH0yfUWV-xv9zq1wI6_3E9i8yw=s64",
      "userId": "10443507700807192111"
     },
     "user_tz": 360
    },
    "id": "BPVYRwB-Un29",
    "outputId": "8d558625-18bc-4d71-f354-dd040844d8a9",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef my_tokenizer(stanza_pipeline, data, reverse =False, ):\\n    token_list =[]\\n    for text in data:\\n        doc = stanza_pipeline(text)\\n        tokens =[]\\n        for sent in doc.sentences:            \\n            for token in sent.tokens:\\n                tokens.append(token.text)\\n        if reverse:\\n            tokens.reverse()\\n        token_list.append(tokens) \\n    return token_list\\n'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# need to run this cell only once\n",
    "'''\n",
    "def my_tokenizer(stanza_pipeline, data, reverse =False, ):\n",
    "    token_list =[]\n",
    "    for text in data:\n",
    "        doc = stanza_pipeline(text)\n",
    "        tokens =[]\n",
    "        for sent in doc.sentences:            \n",
    "            for token in sent.tokens:\n",
    "                tokens.append(token.text)\n",
    "        if reverse:\n",
    "            tokens.reverse()\n",
    "        token_list.append(tokens) \n",
    "    return token_list\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-14T07:01:12.609372Z",
     "iopub.status.busy": "2022-02-14T07:01:12.609213Z",
     "iopub.status.idle": "2022-02-14T07:01:12.611717Z",
     "shell.execute_reply": "2022-02-14T07:01:12.611286Z",
     "shell.execute_reply.started": "2022-02-14T07:01:12.609352Z"
    },
    "id": "HGltDMn7l23J",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# need to run this cell only once\n",
    "#df['test']['hi'][0:2].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-14T07:01:13.224489Z",
     "iopub.status.busy": "2022-02-14T07:01:13.224295Z",
     "iopub.status.idle": "2022-02-14T07:01:13.227025Z",
     "shell.execute_reply": "2022-02-14T07:01:13.226613Z",
     "shell.execute_reply.started": "2022-02-14T07:01:13.224459Z"
    },
    "id": "gm2--tYKl23J",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# need to run this cell only once\n",
    "#df['test']['en'][0:2].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-14T07:01:13.434901Z",
     "iopub.status.busy": "2022-02-14T07:01:13.434737Z",
     "iopub.status.idle": "2022-02-14T07:01:13.436879Z",
     "shell.execute_reply": "2022-02-14T07:01:13.436519Z",
     "shell.execute_reply.started": "2022-02-14T07:01:13.434880Z"
    },
    "id": "YzLypmfol23J",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# need to run this cell only once\n",
    "#my_tokenizer(nlp_hi, df['test']['hi'][0:2].values, reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-14T07:01:13.605382Z",
     "iopub.status.busy": "2022-02-14T07:01:13.605189Z",
     "iopub.status.idle": "2022-02-14T07:01:13.607881Z",
     "shell.execute_reply": "2022-02-14T07:01:13.607458Z",
     "shell.execute_reply.started": "2022-02-14T07:01:13.605364Z"
    },
    "id": "p3gC-TpSl23J",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# need to run this cell only once\n",
    "#my_tokenizer(nlp_en, df['test']['en'][0:2].values, reverse=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2022-02-14T07:01:14.036046Z",
     "iopub.status.busy": "2022-02-14T07:01:14.035843Z",
     "iopub.status.idle": "2022-02-14T07:01:14.039491Z",
     "shell.execute_reply": "2022-02-14T07:01:14.039188Z",
     "shell.execute_reply.started": "2022-02-14T07:01:14.036014Z"
    },
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1644647091226,
     "user": {
      "displayName": "Harpreet Singh",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgoHXww3A9iD3K6JH0yfUWV-xv9zq1wI6_3E9i8yw=s64",
      "userId": "10443507700807192111"
     },
     "user_tz": 360
    },
    "id": "pzxVlJJKl23K",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "e46fb9ca-f564-46cf-ef10-401847f5758e",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfor split in ['train', 'validation', 'test']:\\n    df[split]['source_tokens'] = my_tokenizer(nlp_hi, df[split]['hi'].values, reverse = True)\\n    df[split]['target_tokens'] = my_tokenizer(nlp_en, df[split]['en'].values)\\n    df[split] = df[split][['source_tokens', 'target_tokens']]\\n\""
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# need to run this cell only once\n",
    "'''\n",
    "for split in ['train', 'validation', 'test']:\n",
    "    df[split]['source_tokens'] = my_tokenizer(nlp_hi, df[split]['hi'].values, reverse = True)\n",
    "    df[split]['target_tokens'] = my_tokenizer(nlp_en, df[split]['en'].values)\n",
    "    df[split] = df[split][['source_tokens', 'target_tokens']]\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_train = df['train']\n",
    "#df_valid = df['validation']\n",
    "#df_test = df['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T22:42:01.866817Z",
     "iopub.status.busy": "2022-04-02T22:42:01.866605Z",
     "iopub.status.idle": "2022-04-02T22:42:01.905320Z",
     "shell.execute_reply": "2022-04-02T22:42:01.904937Z",
     "shell.execute_reply.started": "2022-04-02T22:42:01.866802Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#df['train']  = df_train.rename(columns = {'source_tokens': 'source_tokens_reversed'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T22:42:26.882367Z",
     "iopub.status.busy": "2022-04-02T22:42:26.882228Z",
     "iopub.status.idle": "2022-04-02T22:42:26.885661Z",
     "shell.execute_reply": "2022-04-02T22:42:26.885303Z",
     "shell.execute_reply.started": "2022-04-02T22:42:26.882354Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#df_test = df_test.rename(columns = {'source_tokens: 'source_tokens_reversed'})\n",
    "#df_valid = df_valid.rename(columns = {'source_tokens': 'source_tokens_reversed'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T22:48:58.229433Z",
     "iopub.status.busy": "2022-04-02T22:48:58.229275Z",
     "iopub.status.idle": "2022-04-02T22:49:02.531618Z",
     "shell.execute_reply": "2022-04-02T22:49:02.531110Z",
     "shell.execute_reply.started": "2022-04-02T22:48:58.229418Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/1659083 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#df_train['source_tokens'] = df_train['source_tokens_reversed'].swifter.apply(\n",
    "#                                                           lambda x: x[::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T22:49:41.758557Z",
     "iopub.status.busy": "2022-04-02T22:49:41.758361Z",
     "iopub.status.idle": "2022-04-02T22:49:41.778960Z",
     "shell.execute_reply": "2022-04-02T22:49:41.778697Z",
     "shell.execute_reply.started": "2022-04-02T22:49:41.758543Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/2507 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#df_test['source_tokens'] = df_test['source_tokens_reversed'].swifter.apply(\n",
    "#                                                           lambda x: x[::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T22:49:56.770233Z",
     "iopub.status.busy": "2022-04-02T22:49:56.770091Z",
     "iopub.status.idle": "2022-04-02T22:49:56.788243Z",
     "shell.execute_reply": "2022-04-02T22:49:56.787915Z",
     "shell.execute_reply.started": "2022-04-02T22:49:56.770218Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/520 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#df_valid['source_tokens'] = df_valid['source_tokens_reversed'].swifter.apply(\n",
    "#                                                           lambda x: x[::-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4PTv8nsRl23K"
   },
   "source": [
    "#### Save Tokenized data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T22:57:41.472810Z",
     "iopub.status.busy": "2022-04-02T22:57:41.472666Z",
     "iopub.status.idle": "2022-04-02T22:57:55.442382Z",
     "shell.execute_reply": "2022-04-02T22:57:55.441988Z",
     "shell.execute_reply.started": "2022-04-02T22:57:41.472795Z"
    },
    "id": "q-TWyvI9l23K",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# need to run this cell only once\n",
    "#df_train.to_pickle(path=folder/'df_train_hi_en')\n",
    "#df_test.to_pickle(path=folder/'df_test_hi_en')\n",
    "#df_test.to_pickle(path=folder/'df_valid_hi_en')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EQFjo0_dUL2I"
   },
   "source": [
    "## Load Tokenized Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T22:58:06.948976Z",
     "iopub.status.busy": "2022-04-02T22:58:06.948243Z",
     "iopub.status.idle": "2022-04-02T22:58:19.775416Z",
     "shell.execute_reply": "2022-04-02T22:58:19.774973Z",
     "shell.execute_reply.started": "2022-04-02T22:58:06.948959Z"
    },
    "id": "Uh71ereCl23K",
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_pickle(folder/'df_train_hi_en')\n",
    "df_test = pd.read_pickle(folder/'df_test_hi_en')\n",
    "df_valid = pd.read_pickle(folder/'df_valid_hi_en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T22:58:21.437425Z",
     "iopub.status.busy": "2022-04-02T22:58:21.437267Z",
     "iopub.status.idle": "2022-04-02T22:58:21.444529Z",
     "shell.execute_reply": "2022-04-02T22:58:21.444226Z",
     "shell.execute_reply.started": "2022-04-02T22:58:21.437396Z"
    },
    "id": "n4WaFnDVl23K",
    "outputId": "56176530-531a-42e8-b8e7-5ebc599741fc",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_tokens_reversed</th>\n",
       "      <th>target_tokens</th>\n",
       "      <th>source_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[दें, लाभ, का, व्यायाम, पहुंचनीयता, को, अनुप्र...</td>\n",
       "      <td>[Give, your, application, an, accessibility, w...</td>\n",
       "      <td>[अपने, अनुप्रयोग, को, पहुंचनीयता, व्यायाम, का,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[अन्वेषक, पहुंचनीयता, एक्सेर्साइसर]</td>\n",
       "      <td>[Accerciser, Accessibility, Explorer]</td>\n",
       "      <td>[एक्सेर्साइसर, पहुंचनीयता, अन्वेषक]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[खाका, प्लग-इन, डिफोल्ट, लिए, के, पटल, निचले]</td>\n",
       "      <td>[The, default, plugin, layout, for, the, botto...</td>\n",
       "      <td>[निचले, पटल, के, लिए, डिफोल्ट, प्लग-इन, खाका]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[खाका, प्लग-इन, डिफोल्ट, लिए, के, पटल, ऊपरी]</td>\n",
       "      <td>[The, default, plugin, layout, for, the, top, ...</td>\n",
       "      <td>[ऊपरी, पटल, के, लिए, डिफोल्ट, प्लग-इन, खाका]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[है, गया, किया, निष्क्रिय, से, रूप, डिफोल्ट, ज...</td>\n",
       "      <td>[A, list, of, plugins, that, are, disabled, by...</td>\n",
       "      <td>[उन, प्लग-इनों, की, सूची, जिन्हें, डिफोल्ट, रू...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              source_tokens_reversed  \\\n",
       "0  [दें, लाभ, का, व्यायाम, पहुंचनीयता, को, अनुप्र...   \n",
       "1                [अन्वेषक, पहुंचनीयता, एक्सेर्साइसर]   \n",
       "2      [खाका, प्लग-इन, डिफोल्ट, लिए, के, पटल, निचले]   \n",
       "3       [खाका, प्लग-इन, डिफोल्ट, लिए, के, पटल, ऊपरी]   \n",
       "4  [है, गया, किया, निष्क्रिय, से, रूप, डिफोल्ट, ज...   \n",
       "\n",
       "                                       target_tokens  \\\n",
       "0  [Give, your, application, an, accessibility, w...   \n",
       "1              [Accerciser, Accessibility, Explorer]   \n",
       "2  [The, default, plugin, layout, for, the, botto...   \n",
       "3  [The, default, plugin, layout, for, the, top, ...   \n",
       "4  [A, list, of, plugins, that, are, disabled, by...   \n",
       "\n",
       "                                       source_tokens  \n",
       "0  [अपने, अनुप्रयोग, को, पहुंचनीयता, व्यायाम, का,...  \n",
       "1                [एक्सेर्साइसर, पहुंचनीयता, अन्वेषक]  \n",
       "2      [निचले, पटल, के, लिए, डिफोल्ट, प्लग-इन, खाका]  \n",
       "3       [ऊपरी, पटल, के, लिए, डिफोल्ट, प्लग-इन, खाका]  \n",
       "4  [उन, प्लग-इनों, की, सूची, जिन्हें, डिफोल्ट, रू...  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T22:58:25.869111Z",
     "iopub.status.busy": "2022-04-02T22:58:25.868987Z",
     "iopub.status.idle": "2022-04-02T22:58:25.877807Z",
     "shell.execute_reply": "2022-04-02T22:58:25.877472Z",
     "shell.execute_reply.started": "2022-04-02T22:58:25.869097Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_tokens_reversed</th>\n",
       "      <th>target_tokens</th>\n",
       "      <th>source_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[?, बॉक्स, ब्लैक, में, कार, आपकी]</td>\n",
       "      <td>[A, black, box, in, your, car, ?]</td>\n",
       "      <td>[आपकी, कार, में, ब्लैक, बॉक्स, ?]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[।, है, जाता, हो, फिट, से, सफ़ाई, पर, डैशबोर्ड...</td>\n",
       "      <td>[As, America, 's, road, planners, struggle, to...</td>\n",
       "      <td>[जबकि, अमेरिका, के, सड़क, योजनाकार, ,, ध्वस्त,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[।, है, चुका, बन, मुद्दा, का, प्रयास, विवादास्...</td>\n",
       "      <td>[The, devices, ,, which, track, every, mile, a...</td>\n",
       "      <td>[यह, डिवाइस, ,, जो, मोटर-चालक, द्वारा, वाहन, च...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[।, है, गया, बन, मुद्दा, का, गठबंधनों, जीवंत, ...</td>\n",
       "      <td>[The, usually, dull, arena, of, highway, plann...</td>\n",
       "      <td>[आम, तौर, पर, हाईवे, नियोजन, जैसा, उबाऊ, काम, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[।, हैं, गए, मिल, साथ, के, समूहों, पर्यावरणीय,...</td>\n",
       "      <td>[Libertarians, have, joined, environmental, gr...</td>\n",
       "      <td>[आपने, द्वारा, ड्राइव, किए, गए, मील, ,, तथा, स...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              source_tokens_reversed  \\\n",
       "0                  [?, बॉक्स, ब्लैक, में, कार, आपकी]   \n",
       "1  [।, है, जाता, हो, फिट, से, सफ़ाई, पर, डैशबोर्ड...   \n",
       "2  [।, है, चुका, बन, मुद्दा, का, प्रयास, विवादास्...   \n",
       "3  [।, है, गया, बन, मुद्दा, का, गठबंधनों, जीवंत, ...   \n",
       "4  [।, हैं, गए, मिल, साथ, के, समूहों, पर्यावरणीय,...   \n",
       "\n",
       "                                       target_tokens  \\\n",
       "0                  [A, black, box, in, your, car, ?]   \n",
       "1  [As, America, 's, road, planners, struggle, to...   \n",
       "2  [The, devices, ,, which, track, every, mile, a...   \n",
       "3  [The, usually, dull, arena, of, highway, plann...   \n",
       "4  [Libertarians, have, joined, environmental, gr...   \n",
       "\n",
       "                                       source_tokens  \n",
       "0                  [आपकी, कार, में, ब्लैक, बॉक्स, ?]  \n",
       "1  [जबकि, अमेरिका, के, सड़क, योजनाकार, ,, ध्वस्त,...  \n",
       "2  [यह, डिवाइस, ,, जो, मोटर-चालक, द्वारा, वाहन, च...  \n",
       "3  [आम, तौर, पर, हाईवे, नियोजन, जैसा, उबाऊ, काम, ...  \n",
       "4  [आपने, द्वारा, ड्राइव, किए, गए, मील, ,, तथा, स...  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_valid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T22:58:26.751094Z",
     "iopub.status.busy": "2022-04-02T22:58:26.750497Z",
     "iopub.status.idle": "2022-04-02T22:58:26.759571Z",
     "shell.execute_reply": "2022-04-02T22:58:26.759153Z",
     "shell.execute_reply.started": "2022-04-02T22:58:26.751076Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_tokens_reversed</th>\n",
       "      <th>target_tokens</th>\n",
       "      <th>source_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[?, बॉक्स, ब्लैक, में, कार, आपकी]</td>\n",
       "      <td>[A, black, box, in, your, car, ?]</td>\n",
       "      <td>[आपकी, कार, में, ब्लैक, बॉक्स, ?]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[।, है, जाता, हो, फिट, से, सफ़ाई, पर, डैशबोर्ड...</td>\n",
       "      <td>[As, America, 's, road, planners, struggle, to...</td>\n",
       "      <td>[जबकि, अमेरिका, के, सड़क, योजनाकार, ,, ध्वस्त,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[।, है, चुका, बन, मुद्दा, का, प्रयास, विवादास्...</td>\n",
       "      <td>[The, devices, ,, which, track, every, mile, a...</td>\n",
       "      <td>[यह, डिवाइस, ,, जो, मोटर-चालक, द्वारा, वाहन, च...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[।, है, गया, बन, मुद्दा, का, गठबंधनों, जीवंत, ...</td>\n",
       "      <td>[The, usually, dull, arena, of, highway, plann...</td>\n",
       "      <td>[आम, तौर, पर, हाईवे, नियोजन, जैसा, उबाऊ, काम, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[।, हैं, गए, मिल, साथ, के, समूहों, पर्यावरणीय,...</td>\n",
       "      <td>[Libertarians, have, joined, environmental, gr...</td>\n",
       "      <td>[आपने, द्वारा, ड्राइव, किए, गए, मील, ,, तथा, स...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              source_tokens_reversed  \\\n",
       "0                  [?, बॉक्स, ब्लैक, में, कार, आपकी]   \n",
       "1  [।, है, जाता, हो, फिट, से, सफ़ाई, पर, डैशबोर्ड...   \n",
       "2  [।, है, चुका, बन, मुद्दा, का, प्रयास, विवादास्...   \n",
       "3  [।, है, गया, बन, मुद्दा, का, गठबंधनों, जीवंत, ...   \n",
       "4  [।, हैं, गए, मिल, साथ, के, समूहों, पर्यावरणीय,...   \n",
       "\n",
       "                                       target_tokens  \\\n",
       "0                  [A, black, box, in, your, car, ?]   \n",
       "1  [As, America, 's, road, planners, struggle, to...   \n",
       "2  [The, devices, ,, which, track, every, mile, a...   \n",
       "3  [The, usually, dull, arena, of, highway, plann...   \n",
       "4  [Libertarians, have, joined, environmental, gr...   \n",
       "\n",
       "                                       source_tokens  \n",
       "0                  [आपकी, कार, में, ब्लैक, बॉक्स, ?]  \n",
       "1  [जबकि, अमेरिका, के, सड़क, योजनाकार, ,, ध्वस्त,...  \n",
       "2  [यह, डिवाइस, ,, जो, मोटर-चालक, द्वारा, वाहन, च...  \n",
       "3  [आम, तौर, पर, हाईवे, नियोजन, जैसा, उबाऊ, काम, ...  \n",
       "4  [आपने, द्वारा, ड्राइव, किए, गए, मील, ,, तथा, स...  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "10cbb6be0f4d43c784ad2edc5fae94ee"
     ]
    },
    "execution": {
     "iopub.execute_input": "2022-04-02T22:58:32.109976Z",
     "iopub.status.busy": "2022-04-02T22:58:32.109831Z",
     "iopub.status.idle": "2022-04-02T22:58:33.337107Z",
     "shell.execute_reply": "2022-04-02T22:58:33.336700Z",
     "shell.execute_reply.started": "2022-04-02T22:58:32.109962Z"
    },
    "id": "LWASHxDg56yc",
    "outputId": "40d7a213-ecfe-451f-b26b-de4143dc9309",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "830bf9e38622485daa4bc2e49be9fecb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/1659083 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_train['source_len']= df_train['source_tokens'].swifter.apply(lambda x : len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T22:58:34.133136Z",
     "iopub.status.busy": "2022-04-02T22:58:34.132993Z",
     "iopub.status.idle": "2022-04-02T22:58:34.137309Z",
     "shell.execute_reply": "2022-04-02T22:58:34.137050Z",
     "shell.execute_reply.started": "2022-04-02T22:58:34.133121Z"
    },
    "id": "Ifo6AOh056yc",
    "outputId": "29503882-b29f-471a-b636-98bf4344fd02",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1463"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['source_len'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T22:58:34.870768Z",
     "iopub.status.busy": "2022-04-02T22:58:34.870557Z",
     "iopub.status.idle": "2022-04-02T22:58:34.874851Z",
     "shell.execute_reply": "2022-04-02T22:58:34.874481Z",
     "shell.execute_reply.started": "2022-04-02T22:58:34.870753Z"
    },
    "id": "sj3vAb6z56yc",
    "outputId": "aadecd5d-786e-46a8-cf5d-f5249deec7f1",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['source_len'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T22:58:38.496142Z",
     "iopub.status.busy": "2022-04-02T22:58:38.495998Z",
     "iopub.status.idle": "2022-04-02T22:58:38.501085Z",
     "shell.execute_reply": "2022-04-02T22:58:38.500748Z",
     "shell.execute_reply.started": "2022-04-02T22:58:38.496128Z"
    },
    "id": "XgmUiJhN56yc",
    "outputId": "2d172fae-1a86-4bc8-b3e0-35e911d33ca7",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15.419901234597667"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['source_len'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "If-BMrTctAXj",
    "tags": []
   },
   "source": [
    "## Build Vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-14T07:01:59.507438Z",
     "iopub.status.busy": "2022-02-14T07:01:59.507313Z",
     "iopub.status.idle": "2022-02-14T07:01:59.510160Z",
     "shell.execute_reply": "2022-02-14T07:01:59.509919Z",
     "shell.execute_reply.started": "2022-02-14T07:01:59.507425Z"
    },
    "id": "GY9kL2JxtAXj",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef create_vocab(text, min_freq, specials):\\n    my_counter = Counter()\\n    for sent in text:\\n      my_counter.update(sent)  \\n    my_vocab = vocab(my_counter, min_freq = min_freq)\\n    for i, special in enumerate(specials):\\n        my_vocab.insert_token(special, i)\\n    my_vocab.set_default_index(0)\\n        \\n    return my_vocab\\n'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# need to run this cell only once\n",
    "\n",
    "# Function to create vocab and insert special tokens\n",
    "# the function should take text, min_freq and specials as input\n",
    "# also set the index for default words to 0.\n",
    "\n",
    "'''\n",
    "def create_vocab(text, min_freq, specials):\n",
    "    my_counter = Counter()\n",
    "    for sent in text:\n",
    "      my_counter.update(sent)  \n",
    "    my_vocab = vocab(my_counter, min_freq = min_freq)\n",
    "    for i, special in enumerate(specials):\n",
    "        my_vocab.insert_token(special, i)\n",
    "    my_vocab.set_default_index(0)\n",
    "        \n",
    "    return my_vocab\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-14T07:02:00.778190Z",
     "iopub.status.busy": "2022-02-14T07:02:00.778046Z",
     "iopub.status.idle": "2022-02-14T07:02:00.780488Z",
     "shell.execute_reply": "2022-02-14T07:02:00.780163Z",
     "shell.execute_reply.started": "2022-02-14T07:02:00.778176Z"
    },
    "id": "dcvIJAIHtAXj",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# need to run this cell only once\n",
    "#source_vocab = create_vocab(text= df_train.source_tokens.values, min_freq=300,specials= ['<UNK>', '<BOS>', '<EOS>','<PAD>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-14T07:02:01.215544Z",
     "iopub.status.busy": "2022-02-14T07:02:01.215379Z",
     "iopub.status.idle": "2022-02-14T07:02:01.217838Z",
     "shell.execute_reply": "2022-02-14T07:02:01.217567Z",
     "shell.execute_reply.started": "2022-02-14T07:02:01.215528Z"
    },
    "id": "2qZ2lNqal23L",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# need to run this cell only once\n",
    "#target_vocab = create_vocab(text= df_train.target_tokens.values, min_freq=300,specials= ['<UNK>', '<BOS>', '<EOS>','<PAD>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-14T07:02:01.648583Z",
     "iopub.status.busy": "2022-02-14T07:02:01.648286Z",
     "iopub.status.idle": "2022-02-14T07:02:01.650757Z",
     "shell.execute_reply": "2022-02-14T07:02:01.650323Z",
     "shell.execute_reply.started": "2022-02-14T07:02:01.648564Z"
    },
    "id": "qtEt9Sh-tAXk",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#len(source_vocab), len(target_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-14T07:02:02.171104Z",
     "iopub.status.busy": "2022-02-14T07:02:02.170959Z",
     "iopub.status.idle": "2022-02-14T07:02:02.173552Z",
     "shell.execute_reply": "2022-02-14T07:02:02.172934Z",
     "shell.execute_reply.started": "2022-02-14T07:02:02.171090Z"
    },
    "id": "XCHCrc4Dl23M",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# need to run this cell only once\n",
    "#pickle.dump(source_vocab, open(folder/'source_vocab_hi_en.pkl', 'wb'))\n",
    "#pickle.dump(target_vocab, open(folder/'target_vocab_hi_en.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1BEf_jK2Tz6E"
   },
   "source": [
    "## Load Vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T22:58:54.634803Z",
     "iopub.status.busy": "2022-04-02T22:58:54.634647Z",
     "iopub.status.idle": "2022-04-02T22:58:54.702406Z",
     "shell.execute_reply": "2022-04-02T22:58:54.702037Z",
     "shell.execute_reply.started": "2022-04-02T22:58:54.634788Z"
    },
    "id": "cvsVAiyHl23M",
    "tags": []
   },
   "outputs": [],
   "source": [
    "source_vocab = pickle.load(open(folder/'source_vocab_hi_en.pkl','rb'))\n",
    "target_vocab = pickle.load(open(folder/'target_vocab_hi_en.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-14T07:02:04.345619Z",
     "iopub.status.busy": "2022-02-14T07:02:04.345482Z",
     "iopub.status.idle": "2022-02-14T07:02:04.347957Z",
     "shell.execute_reply": "2022-02-14T07:02:04.347600Z",
     "shell.execute_reply.started": "2022-02-14T07:02:04.345606Z"
    },
    "id": "bf9fu5L2tAXk",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#pd.DataFrame(source_vocab.get_stoi().items(), columns=['tokens', 'index']).sort_values(by = ['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-14T07:02:04.750876Z",
     "iopub.status.busy": "2022-02-14T07:02:04.750513Z",
     "iopub.status.idle": "2022-02-14T07:02:04.752806Z",
     "shell.execute_reply": "2022-02-14T07:02:04.752493Z",
     "shell.execute_reply.started": "2022-02-14T07:02:04.750860Z"
    },
    "id": "8pKCTbN6tAXk",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# check index of unknown word - it should be zero\n",
    "#source_vocab['abracdabra']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2022-04-02T22:58:59.674798Z",
     "iopub.status.busy": "2022-04-02T22:58:59.674654Z",
     "iopub.status.idle": "2022-04-02T22:58:59.677788Z",
     "shell.execute_reply": "2022-04-02T22:58:59.677519Z",
     "shell.execute_reply.started": "2022-04-02T22:58:59.674783Z"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1644711299230,
     "user": {
      "displayName": "Harpreet Singh",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgoHXww3A9iD3K6JH0yfUWV-xv9zq1wI6_3E9i8yw=s64",
      "userId": "10443507700807192111"
     },
     "user_tz": 360
    },
    "id": "SprHodI2l23M",
    "outputId": "7120fb6d-a662-44ab-b097-0855a95f721b",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_vocab['from']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2022-04-02T22:59:02.151760Z",
     "iopub.status.busy": "2022-04-02T22:59:02.151616Z",
     "iopub.status.idle": "2022-04-02T22:59:02.154758Z",
     "shell.execute_reply": "2022-04-02T22:59:02.154460Z",
     "shell.execute_reply.started": "2022-04-02T22:59:02.151745Z"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1644711300332,
     "user": {
      "displayName": "Harpreet Singh",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgoHXww3A9iD3K6JH0yfUWV-xv9zq1wI6_3E9i8yw=s64",
      "userId": "10443507700807192111"
     },
     "user_tz": 360
    },
    "id": "yJjpoffol23M",
    "outputId": "8c4b060c-e83e-4b46-ee88-ceed439244a3",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6115, 6537)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(source_vocab), len(target_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "feccYoeWtAXk"
   },
   "source": [
    "# Create Dataset and Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T22:59:28.931811Z",
     "iopub.status.busy": "2022-04-02T22:59:28.931656Z",
     "iopub.status.idle": "2022-04-02T22:59:28.935109Z",
     "shell.execute_reply": "2022-04-02T22:59:28.934791Z",
     "shell.execute_reply.started": "2022-04-02T22:59:28.931784Z"
    },
    "id": "fCMXepKUtAXk",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class EngHindi(Dataset):\n",
    "    \n",
    "    '''\n",
    "    Takes input as (X1, X2)\n",
    "    X1 : pandas series for  source language\n",
    "    X2 : pndas series for target language\n",
    "    '''\n",
    "    def __init__(self, X1, X2):\n",
    "        self.X1 = X1\n",
    "        self.X2 = X2\n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.X1)\n",
    "    \n",
    "    def __getitem__(self, indices):\n",
    "        source_examples = self.X1.iloc[indices]  \n",
    "        target_examples = self.X2.iloc[indices]\n",
    "        return source_examples, target_examples    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T22:59:29.522854Z",
     "iopub.status.busy": "2022-04-02T22:59:29.522700Z",
     "iopub.status.idle": "2022-04-02T22:59:29.525881Z",
     "shell.execute_reply": "2022-04-02T22:59:29.525548Z",
     "shell.execute_reply.started": "2022-04-02T22:59:29.522840Z"
    },
    "id": "-Q32VBamtAXl",
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainset = EngHindi(df_train['source_tokens_reversed'], df_train['target_tokens'])\n",
    "testset =  EngHindi(df_test['source_tokens_reversed'], df_test['target_tokens'])\n",
    "validset = EngHindi(df_valid['source_tokens_reversed'], df_valid['target_tokens'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2022-04-02T22:59:32.925868Z",
     "iopub.status.busy": "2022-04-02T22:59:32.925709Z",
     "iopub.status.idle": "2022-04-02T22:59:32.929372Z",
     "shell.execute_reply": "2022-04-02T22:59:32.928958Z",
     "shell.execute_reply.started": "2022-04-02T22:59:32.925840Z"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1644711314280,
     "user": {
      "displayName": "Harpreet Singh",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgoHXww3A9iD3K6JH0yfUWV-xv9zq1wI6_3E9i8yw=s64",
      "userId": "10443507700807192111"
     },
     "user_tz": 360
    },
    "id": "2md5tDSutAXl",
    "outputId": "ea376959-3389-402b-8142-8c5f6c86bf51",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['दें', 'लाभ', 'का', 'व्यायाम', 'पहुंचनीयता', 'को', 'अनुप्रयोग', 'अपने'],\n",
       " ['Give', 'your', 'application', 'an', 'accessibility', 'workout'])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainset.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2022-04-02T22:59:33.386959Z",
     "iopub.status.busy": "2022-04-02T22:59:33.386831Z",
     "iopub.status.idle": "2022-04-02T22:59:33.390264Z",
     "shell.execute_reply": "2022-04-02T22:59:33.389915Z",
     "shell.execute_reply.started": "2022-04-02T22:59:33.386942Z"
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1644711314818,
     "user": {
      "displayName": "Harpreet Singh",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgoHXww3A9iD3K6JH0yfUWV-xv9zq1wI6_3E9i8yw=s64",
      "userId": "10443507700807192111"
     },
     "user_tz": 360
    },
    "id": "L18xzZrltAXl",
    "outputId": "4781fac9-4102-40c1-add9-284d555e9e50",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1659083, 2507, 2507)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trainset), len(testset), len(validset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2022-04-02T22:59:33.821521Z",
     "iopub.status.busy": "2022-04-02T22:59:33.821367Z",
     "iopub.status.idle": "2022-04-02T22:59:33.824565Z",
     "shell.execute_reply": "2022-04-02T22:59:33.824300Z",
     "shell.execute_reply.started": "2022-04-02T22:59:33.821493Z"
    },
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1644711320965,
     "user": {
      "displayName": "Harpreet Singh",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgoHXww3A9iD3K6JH0yfUWV-xv9zq1wI6_3E9i8yw=s64",
      "userId": "10443507700807192111"
     },
     "user_tz": 360
    },
    "id": "TehVY0IoQUvb",
    "outputId": "4a2b8ea2-0ec8-430b-fbee-2d10f2753f55",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33181.66"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trainset)*0.02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T22:59:34.184899Z",
     "iopub.status.busy": "2022-04-02T22:59:34.184700Z",
     "iopub.status.idle": "2022-04-02T22:59:34.206131Z",
     "shell.execute_reply": "2022-04-02T22:59:34.205669Z",
     "shell.execute_reply.started": "2022-04-02T22:59:34.184878Z"
    },
    "id": "wDzZ5HlFQOYA",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get subset of data\n",
    "# We will be using only 100 images for nboth train and validation datasets\n",
    "train_sample_size = int(len(trainset)*0.02)\n",
    "\n",
    "# Getting n random indices\n",
    "train_subset_indices = random.sample(range(0, len(trainset)), train_sample_size)\n",
    "\n",
    "# Getting subset of dataset\n",
    "train_subset = torch.utils.data.Subset(trainset, train_subset_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2022-04-02T22:59:34.572018Z",
     "iopub.status.busy": "2022-04-02T22:59:34.571680Z",
     "iopub.status.idle": "2022-04-02T22:59:34.575359Z",
     "shell.execute_reply": "2022-04-02T22:59:34.574846Z",
     "shell.execute_reply.started": "2022-04-02T22:59:34.571967Z"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1644711333448,
     "user": {
      "displayName": "Harpreet Singh",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgoHXww3A9iD3K6JH0yfUWV-xv9zq1wI6_3E9i8yw=s64",
      "userId": "10443507700807192111"
     },
     "user_tz": 360
    },
    "id": "D5ALqVW9QsUz",
    "outputId": "c0912d32-532e-4c6a-ee35-4838e50de191",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(['।', 'होगा', 'सुनिश्चित', 'भविष्य', 'का', 'राष्ट्र', 'हमारे', 'और', 'बढ़ेगा', 'आधार', 'का', 'पीरामिड', 'नवाचार', 'हमारे', 'से', 'बोने', 'बीज', 'के', 'शक्ति', 'की', 'नवाचारों', 'और', 'विचारों', 'नए', 'में', 'बच्चों', 'स्कूली'], ['Seeding', 'the', 'power', 'of', 'ideas', 'and', 'innovation', 'in', 'schoolchildren', 'will', 'broaden', 'the', 'base', 'of', 'our', 'innovation', 'pyramid', 'and', 'secure', 'the', 'future', 'of', 'our', 'nation', '.'])\n"
     ]
    }
   ],
   "source": [
    "print(train_subset.__getitem__(11))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T22:59:34.970705Z",
     "iopub.status.busy": "2022-04-02T22:59:34.970469Z",
     "iopub.status.idle": "2022-04-02T22:59:34.974089Z",
     "shell.execute_reply": "2022-04-02T22:59:34.973702Z",
     "shell.execute_reply.started": "2022-04-02T22:59:34.970685Z"
    },
    "id": "bPg8WslltAXl",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# transform text to indexes and append eos and bos\n",
    "# finally convert to tensors\n",
    "def text_transform(my_vocab, text):\n",
    "    text_num = [my_vocab['<BOS>']] + [my_vocab[word] for word in text] + [my_vocab['<EOS>']]\n",
    "    return torch.tensor(text_num)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2022-04-02T22:59:35.318234Z",
     "iopub.status.busy": "2022-04-02T22:59:35.318067Z",
     "iopub.status.idle": "2022-04-02T22:59:35.321315Z",
     "shell.execute_reply": "2022-04-02T22:59:35.320839Z",
     "shell.execute_reply.started": "2022-04-02T22:59:35.318216Z"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1644711355996,
     "user": {
      "displayName": "Harpreet Singh",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgoHXww3A9iD3K6JH0yfUWV-xv9zq1wI6_3E9i8yw=s64",
      "userId": "10443507700807192111"
     },
     "user_tz": 360
    },
    "id": "bpQKiRHLtAXl",
    "outputId": "863ec3ae-ba24-4ac7-acd8-8062b165da5f",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Bad', 'current', 'tag', 'value', '.']\n"
     ]
    }
   ],
   "source": [
    "text = train_subset.__getitem__(13)[1]\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2022-04-02T22:59:35.721453Z",
     "iopub.status.busy": "2022-04-02T22:59:35.721321Z",
     "iopub.status.idle": "2022-04-02T22:59:35.725382Z",
     "shell.execute_reply": "2022-04-02T22:59:35.724901Z",
     "shell.execute_reply.started": "2022-04-02T22:59:35.721437Z"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1644711360489,
     "user": {
      "displayName": "Harpreet Singh",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgoHXww3A9iD3K6JH0yfUWV-xv9zq1wI6_3E9i8yw=s64",
      "userId": "10443507700807192111"
     },
     "user_tz": 360
    },
    "id": "-QZp7ZlAl23N",
    "outputId": "6e80bbb5-483e-4e78-a924-a41260739a97",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([   1, 1032,   37,  672,  104,   33,    2])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_transform(target_vocab, text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T22:59:36.083345Z",
     "iopub.status.busy": "2022-04-02T22:59:36.083202Z",
     "iopub.status.idle": "2022-04-02T22:59:36.086769Z",
     "shell.execute_reply": "2022-04-02T22:59:36.086373Z",
     "shell.execute_reply.started": "2022-04-02T22:59:36.083331Z"
    },
    "id": "CgKupdZ1Un2-",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def collate_batch(batch):\n",
    "    source_list, target_list = [], []\n",
    "    for source, target in batch:\n",
    "        source_tensor = text_transform(source_vocab, source)\n",
    "        target_tensor = text_transform(target_vocab, target)\n",
    "        source_list.append(source_tensor)\n",
    "        target_list.append(target_tensor)\n",
    "        \n",
    "    source_pad = pad_sequence(source_list, batch_first=False, padding_value= source_vocab['<PAD>'])\n",
    "    target_pad = pad_sequence(target_list, batch_first=False, padding_value= target_vocab['<PAD>'])\n",
    "    \n",
    "    return source_pad, target_pad     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T22:59:36.499269Z",
     "iopub.status.busy": "2022-04-02T22:59:36.499108Z",
     "iopub.status.idle": "2022-04-02T22:59:36.501960Z",
     "shell.execute_reply": "2022-04-02T22:59:36.501591Z",
     "shell.execute_reply.started": "2022-04-02T22:59:36.499255Z"
    },
    "id": "knmDrwd5l23N",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#?DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T22:59:36.858444Z",
     "iopub.status.busy": "2022-04-02T22:59:36.858287Z",
     "iopub.status.idle": "2022-04-02T22:59:36.861135Z",
     "shell.execute_reply": "2022-04-02T22:59:36.860870Z",
     "shell.execute_reply.started": "2022-04-02T22:59:36.858430Z"
    },
    "id": "EqHCA63DUn2_",
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size = 2\n",
    "train_loader = DataLoader(trainset, batch_size=batch_size, shuffle= True,collate_fn = collate_batch )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2022-04-02T22:59:37.150211Z",
     "iopub.status.busy": "2022-04-02T22:59:37.150019Z",
     "iopub.status.idle": "2022-04-02T22:59:37.257907Z",
     "shell.execute_reply": "2022-04-02T22:59:37.257577Z",
     "shell.execute_reply.started": "2022-04-02T22:59:37.150171Z"
    },
    "executionInfo": {
     "elapsed": 108,
     "status": "ok",
     "timestamp": 1644711376440,
     "user": {
      "displayName": "Harpreet Singh",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgoHXww3A9iD3K6JH0yfUWV-xv9zq1wI6_3E9i8yw=s64",
      "userId": "10443507700807192111"
     },
     "user_tz": 360
    },
    "id": "-NUpXpJYtAXm",
    "outputId": "b02ebb4b-bcdb-4c6c-afdc-86174b332337",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[   1,    1],\n",
      "        [2448,   29],\n",
      "        [4585,  174],\n",
      "        [ 146,  175],\n",
      "        [ 355,   31],\n",
      "        [1390,  802],\n",
      "        [ 528, 1386],\n",
      "        [1700,    2],\n",
      "        [   6,    3],\n",
      "        [ 168,    3],\n",
      "        [2294,    3],\n",
      "        [   8,    3],\n",
      "        [5179,    3],\n",
      "        [  25,    3],\n",
      "        [   0,    3],\n",
      "        [   0,    3],\n",
      "        [  34,    3],\n",
      "        [   0,    3],\n",
      "        [  41,    3],\n",
      "        [5556,    3],\n",
      "        [  37,    3],\n",
      "        [2499,    3],\n",
      "        [  34,    3],\n",
      "        [   6,    3],\n",
      "        [   0,    3],\n",
      "        [  37,    3],\n",
      "        [2597,    3],\n",
      "        [2225,    3],\n",
      "        [  10,    3],\n",
      "        [3058,    3],\n",
      "        [  25,    3],\n",
      "        [5928,    3],\n",
      "        [3405,    3],\n",
      "        [   8,    3],\n",
      "        [   0,    3],\n",
      "        [ 176,    3],\n",
      "        [1504,    3],\n",
      "        [  21,    3],\n",
      "        [4014,    3],\n",
      "        [   2,    3]])\n"
     ]
    }
   ],
   "source": [
    "for source, target in train_loader:\n",
    "  print(source)\n",
    "  break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T22:59:37.932729Z",
     "iopub.status.busy": "2022-04-02T22:59:37.932586Z",
     "iopub.status.idle": "2022-04-02T22:59:37.935559Z",
     "shell.execute_reply": "2022-04-02T22:59:37.935192Z",
     "shell.execute_reply.started": "2022-04-02T22:59:37.932715Z"
    },
    "id": "axyZQ-4z1B-z",
    "tags": []
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "\n",
    "train_loader = DataLoader(train_subset, batch_size=BATCH_SIZE, shuffle = True, collate_fn = collate_batch )\n",
    "valid_loader = DataLoader(validset, batch_size=BATCH_SIZE, shuffle = False, collate_fn = collate_batch )\n",
    "test_loader = DataLoader(testset, batch_size=BATCH_SIZE, shuffle = False, collate_fn = collate_batch )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mhyhh7uCUn2_"
   },
   "source": [
    "## Building the Seq2Seq Model\n",
    "\n",
    "We'll be building our model in three parts. The encoder, the decoder and a seq2seq model that encapsulates the encoder and decoder and will provide a way to interface with each.\n",
    "\n",
    "### Encoder (LSTM)\n",
    "\n",
    "First, the encoder, a 2 layer LSTM. The paper we are implementing uses a 4-layer LSTM, but in the interest of training time we cut this down to 2-layers. The concept of multi-layer RNNs is easy to expand from 2 to 4 layers. \n",
    "\n",
    "\n",
    "So our encoder looks something like this: \n",
    "\n",
    "![](assets/seq2seq2.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T22:59:38.651502Z",
     "iopub.status.busy": "2022-04-02T22:59:38.651357Z",
     "iopub.status.idle": "2022-04-02T22:59:38.654077Z",
     "shell.execute_reply": "2022-04-02T22:59:38.653703Z",
     "shell.execute_reply.started": "2022-04-02T22:59:38.651488Z"
    },
    "id": "7hDyvkpXl23O",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#?nn.Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T22:59:39.318472Z",
     "iopub.status.busy": "2022-04-02T22:59:39.318344Z",
     "iopub.status.idle": "2022-04-02T22:59:39.320804Z",
     "shell.execute_reply": "2022-04-02T22:59:39.320446Z",
     "shell.execute_reply.started": "2022-04-02T22:59:39.318457Z"
    },
    "id": "a5MD-oUwxGGs",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#?nn.LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xWxHXrMBGPgL"
   },
   "source": [
    "### Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T22:59:41.946004Z",
     "iopub.status.busy": "2022-04-02T22:59:41.945858Z",
     "iopub.status.idle": "2022-04-02T22:59:41.950861Z",
     "shell.execute_reply": "2022-04-02T22:59:41.950357Z",
     "shell.execute_reply.started": "2022-04-02T22:59:41.945990Z"
    },
    "id": "zabfsjZOUn3A",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, vocab_size, emb_dim, hidden_dim,\n",
    "                 pad_idx, emb_drop_prob, num_layers, \n",
    "                 rnn_drop_prob):\n",
    "      \n",
    "      super().__init__()\n",
    "\n",
    "      self.vocab_size = vocab_size\n",
    "      self.emb_dim = emb_dim\n",
    "      self.pad_idx= pad_idx\n",
    "      self.emb_drop_prob=emb_drop_prob\n",
    "      self.hidden_dim = hidden_dim\n",
    "      self.num_layers = num_layers\n",
    "      self.rnn_drop_prob = rnn_drop_prob\n",
    "      \n",
    "      self.embedding = nn.Embedding(num_embeddings= self.vocab_size,\n",
    "                                        embedding_dim=self.emb_dim,\n",
    "                                        padding_idx=self.pad_idx)\n",
    "\n",
    "      self.dropout = nn.Dropout(p = self.emb_drop_prob)\n",
    "\n",
    "      self.lstm_layer = nn.LSTM(input_size=self.emb_dim,\n",
    "                               hidden_size=self.hidden_dim,\n",
    "                               num_layers=self.num_layers,\n",
    "                               batch_first=False,\n",
    "                               bidirectional=False,\n",
    "                               dropout = self.rnn_drop_prob\n",
    "                                 )\n",
    "\n",
    "      \n",
    "        \n",
    "    def forward(self, source_indices):\n",
    "      # source_indices: [seq_len, batch_size]\n",
    "      emb = self.embedding(source_indices) # shape : [seq_len, batch_size, emb_dim]\n",
    "      emb_drop = self.dropout(emb) # shape : [seq_len, batch_size, emb_dim]\n",
    "      \n",
    "      \n",
    "      output, (hidden, cell) = self.lstm_layer(emb_drop ) # h0, c0 are optional\n",
    "      # output : [seq_len, batch_size, directions * hidden_dim]\n",
    "      # hidden : [directions* num_layers, batch_size, hidden_dim]\n",
    "\n",
    "      return hidden, cell       \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7esX6rp0Un3A"
   },
   "source": [
    "### Decoder\n",
    "\n",
    "Next, we'll build our decoder, which will also be a 2-layer (4 in the paper) LSTM.\n",
    "\n",
    "![](assets/seq2seq3.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T22:59:42.759658Z",
     "iopub.status.busy": "2022-04-02T22:59:42.759513Z",
     "iopub.status.idle": "2022-04-02T22:59:42.764670Z",
     "shell.execute_reply": "2022-04-02T22:59:42.764253Z",
     "shell.execute_reply.started": "2022-04-02T22:59:42.759644Z"
    },
    "id": "AVkx_S2fUn3A",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, vocab_size, emb_dim, hidden_dim, \n",
    "                 pad_idx, emb_drop_prob, num_layers, \n",
    "                 rnn_drop_prob):\n",
    "      \n",
    "     \n",
    "      super().__init__()\n",
    "\n",
    "      self.vocab_size = vocab_size\n",
    "      self.emb_dim = emb_dim\n",
    "      self.pad_idx= pad_idx\n",
    "      self.emb_drop_prob=emb_drop_prob\n",
    "      self.hidden_dim = hidden_dim\n",
    "      self.num_layers = num_layers\n",
    "      self.rnn_drop_prob = rnn_drop_prob\n",
    "      \n",
    "\n",
    "      self.embedding = nn.Embedding(num_embeddings= self.vocab_size,\n",
    "                                        embedding_dim=self.emb_dim,\n",
    "                                        padding_idx=self.pad_idx)\n",
    "\n",
    "      self.dropout = nn.Dropout(p = self.emb_drop_prob)\n",
    "\n",
    "      self.lstm_layer = nn.LSTM(input_size=self.emb_dim,\n",
    "                               hidden_size=self.hidden_dim,\n",
    "                               num_layers=self.num_layers,\n",
    "                               batch_first=False,\n",
    "                               bidirectional=False,\n",
    "                               dropout = self.rnn_drop_prob\n",
    "                                 )\n",
    "      \n",
    "      self.linear= nn.Linear(in_features=self.hidden_dim,\n",
    "                                 out_features=self.vocab_size)\n",
    "\n",
    "      \n",
    "        \n",
    "    def forward(self, input_token, hidden, cell):\n",
    "\n",
    "      # in decoder we pass one token at a time- seq_len is 1\n",
    "      # shape of input_token : [batch_size]\n",
    "\n",
    "      #input_token = input_token.unsqueeze(0) # [1, batch_size, emb_dim]\n",
    "      #print(input_token.shape) \n",
    "            \n",
    "      emb = self.dropout(self.embedding(input_token)) \n",
    "      # emb - [batch_size, emb_dim]\n",
    "      \n",
    "      # lstm layer needs input in the shape: [seq_len, batch_size, emb_dim]\n",
    "      # we will add a redundant dimension to change  the shape of emb\n",
    "      emb = emb.unsqueeze(0)\n",
    "      \n",
    "      #print(emb.shape)\n",
    "      output, (hidden, cell) = self.lstm_layer(emb,(hidden, cell) )\n",
    "\n",
    "      # output - [seq_len, batch_size, directions * hidden_dim]\n",
    "      # sequence length is always one for decoder as we pass one token at a time\n",
    "      # we never use bidirectional for decoder as decoder cannot look ahead\n",
    "      # hence shapes \n",
    "      # output: [1, batch_size, hidden_dim) \n",
    "      # hidden - [num_layers, batch_size, hidden_dim]\n",
    "\n",
    "      output = output.squeeze(0) # squeeze out the redundant dim to make it work for linear layer\n",
    "      # output: [1, batch_size, hidden_dim) \n",
    "      prediction = self.linear(output)\n",
    "      # prediction: [batch_size, decoder_vocab_size] \n",
    "      # each word is projected to vocab size\n",
    "      \n",
    "\n",
    "\n",
    "      return prediction, hidden, cell\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VNxlQ5KYUn3A"
   },
   "source": [
    "### Seq2Seq\n",
    "\n",
    "For the final part of the implemenetation, we'll implement the seq2seq model. This will handle: \n",
    "- receiving the input/source sentence\n",
    "- using the encoder to produce the context vectors \n",
    "- using the decoder to produce the predicted output/target sentence\n",
    "\n",
    "Our full model will look like this:\n",
    "\n",
    "![](assets/seq2seq4.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T22:59:43.510277Z",
     "iopub.status.busy": "2022-04-02T22:59:43.510131Z",
     "iopub.status.idle": "2022-04-02T22:59:43.512651Z",
     "shell.execute_reply": "2022-04-02T22:59:43.512240Z",
     "shell.execute_reply.started": "2022-04-02T22:59:43.510263Z"
    },
    "id": "H6lYtI_XEd30",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#?nn.LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T22:59:43.944944Z",
     "iopub.status.busy": "2022-04-02T22:59:43.944799Z",
     "iopub.status.idle": "2022-04-02T22:59:43.946993Z",
     "shell.execute_reply": "2022-04-02T22:59:43.946714Z",
     "shell.execute_reply.started": "2022-04-02T22:59:43.944929Z"
    },
    "id": "OfPmmJiX48d4",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#?torch.argmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T22:59:44.132947Z",
     "iopub.status.busy": "2022-04-02T22:59:44.132776Z",
     "iopub.status.idle": "2022-04-02T22:59:44.137468Z",
     "shell.execute_reply": "2022-04-02T22:59:44.136940Z",
     "shell.execute_reply.started": "2022-04-02T22:59:44.132931Z"
    },
    "id": "kH4m5zk7Un3B",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, device ):\n",
    "\n",
    "      super().__init__()\n",
    "\n",
    "      self.decoder = decoder\n",
    "      self.encoder = encoder\n",
    "      self.device = device\n",
    "      \n",
    "\n",
    "      assert self.decoder.hidden_dim == self.encoder.hidden_dim, \\\n",
    "      'The hidden_dim for encoder and decoder should be equal'\n",
    "\n",
    "      assert self.decoder.num_layers == self.encoder.num_layers, \\\n",
    "      ' The number of layers in encoder and decoder should be same'\n",
    "\n",
    "\n",
    "        \n",
    "    def forward(self, source_indices, target_indices, teacher_enf_ratio ):\n",
    "      # source_indices, target_indices # [seq_len, batch_size]\n",
    "      \n",
    "      \n",
    "\n",
    "      seq_len = target_indices.shape[0]\n",
    "      batch_size =  target_indices.shape[1]\n",
    "      vocab_size = self.decoder.vocab_size\n",
    "\n",
    "      predictions = torch.zeros((seq_len, batch_size, vocab_size)).to(self.device) # [tar_len, batch_size, target_vocab_size]\n",
    "\n",
    "      hidden, cell = self.encoder(source_indices) # [directions * num_layer, batch_size, hidden_dim]\n",
    "\n",
    "      input_token = target_indices[0,:] # [batch_size]\n",
    "\n",
    "      # we will not update the predictions corresponding to first token -<BOS> \n",
    "\n",
    "      for i in range(1, len(target_indices)):\n",
    "        prediction, hidden, cell = self.decoder(input_token, hidden, cell) # prediction: [batch_size, decoder_vocab_size] \n",
    "\n",
    "        # update predictions\n",
    "        predictions[i] = prediction\n",
    "\n",
    "        teacher_force = torch.rand(1) < teacher_enf_ratio\n",
    "\n",
    "        if teacher_force:\n",
    "          input_token = target_indices[i,:]\n",
    "        else:\n",
    "          input_token = torch.argmax(prediction, dim =1) # batch_size\n",
    "\n",
    "      return predictions # [tar_len, batch_size, target_vocab_size]     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2022-04-02T22:59:44.597026Z",
     "iopub.status.busy": "2022-04-02T22:59:44.596864Z",
     "iopub.status.idle": "2022-04-02T22:59:44.608574Z",
     "shell.execute_reply": "2022-04-02T22:59:44.608279Z",
     "shell.execute_reply.started": "2022-04-02T22:59:44.596999Z"
    },
    "executionInfo": {
     "elapsed": 24,
     "status": "ok",
     "timestamp": 1644711389969,
     "user": {
      "displayName": "Harpreet Singh",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgoHXww3A9iD3K6JH0yfUWV-xv9zq1wI6_3E9i8yw=s64",
      "userId": "10443507700807192111"
     },
     "user_tz": 360
    },
    "id": "zZ6bYFOpLJBA",
    "outputId": "c4369e2b-12ed-4620-fb49-b2b16b124621",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0583])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.rand(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HyPbOrlHUn3B"
   },
   "source": [
    "# Training the Seq2Seq Model\n",
    "\n",
    "Now we have our model implemented, we can begin training it. \n",
    "\n",
    "First, we'll initialize our model. As mentioned before, the input and output dimensions are defined by the size of the vocabulary. The embedding dimesions and dropout for the encoder and decoder can be different, but the number of layers and the size of the hidden/cell states must be the same. \n",
    "\n",
    "We then define the encoder, decoder and then our Seq2Seq model, which we place on the `device`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2022-04-02T22:59:44.978019Z",
     "iopub.status.busy": "2022-04-02T22:59:44.977877Z",
     "iopub.status.idle": "2022-04-02T22:59:46.844290Z",
     "shell.execute_reply": "2022-04-02T22:59:46.843909Z",
     "shell.execute_reply.started": "2022-04-02T22:59:44.978005Z"
    },
    "executionInfo": {
     "elapsed": 75,
     "status": "ok",
     "timestamp": 1644711392928,
     "user": {
      "displayName": "Harpreet Singh",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgoHXww3A9iD3K6JH0yfUWV-xv9zq1wI6_3E9i8yw=s64",
      "userId": "10443507700807192111"
     },
     "user_tz": 360
    },
    "id": "xg6tH3mDUn3B",
    "outputId": "a72e8323-d94a-4e37-e67f-b076eb8eeba9",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Seq2Seq(\n",
       "  (decoder): Decoder(\n",
       "    (embedding): Embedding(6537, 256, padding_idx=3)\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "    (lstm_layer): LSTM(256, 256, num_layers=2, dropout=0.5)\n",
       "    (linear): Linear(in_features=256, out_features=6537, bias=True)\n",
       "  )\n",
       "  (encoder): Encoder(\n",
       "    (embedding): Embedding(6115, 128, padding_idx=3)\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "    (lstm_layer): LSTM(128, 256, num_layers=2, dropout=0.5)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list of hyperparameters for encoder, decoder, model\n",
    "ENC_VOCAB_SIZE = len(source_vocab)\n",
    "ENC_EMB = 128\n",
    "HID_DIM = 256\n",
    "ENC_PAD_IDX = source_vocab['<PAD>']\n",
    "ENC_EMB_DROP_PROB = 0.5\n",
    "NUM_LAYERS = 2\n",
    "ENC_RNN_DROP_PROB = 0.5\n",
    "\n",
    "DEC_VOCAB_SIZE = len(target_vocab)\n",
    "DEC_EMB = 256\n",
    "DEC_PAD_IDX = target_vocab['<PAD>']\n",
    "DEC_EMB_DROP_PROB = 0.5\n",
    "DEC_RNN_DROP_PROB = 0.5\n",
    "\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "enc = Encoder(vocab_size=ENC_VOCAB_SIZE , emb_dim =ENC_EMB, hidden_dim=HID_DIM,\n",
    "              pad_idx=ENC_PAD_IDX, emb_drop_prob=ENC_EMB_DROP_PROB, num_layers=NUM_LAYERS, \n",
    "              rnn_drop_prob=ENC_RNN_DROP_PROB)\n",
    "\n",
    "dec = Decoder(vocab_size=DEC_VOCAB_SIZE, emb_dim=DEC_EMB, hidden_dim=HID_DIM, \n",
    "              pad_idx=DEC_PAD_IDX, emb_drop_prob=DEC_EMB_DROP_PROB, num_layers=NUM_LAYERS, \n",
    "              rnn_drop_prob=DEC_RNN_DROP_PROB)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "model = Seq2Seq(encoder=enc, decoder=dec, device=device )\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R8QiCSrzUn3B"
   },
   "source": [
    "Next up is initializing the weights of our model. In the paper they state they initialize all weights from a uniform distribution between -0.08 and +0.08, i.e. $\\mathcal{U}(-0.08, 0.08)$.\n",
    "\n",
    "We initialize weights in PyTorch by creating a function which we `apply` to our model. When using `apply`, the `init_weights` function will be called on every module and sub-module within our model. For each module we loop through all of the parameters and sample them from a uniform distribution with `nn.init.uniform_`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T22:59:46.845124Z",
     "iopub.status.busy": "2022-04-02T22:59:46.845025Z",
     "iopub.status.idle": "2022-04-02T22:59:46.847178Z",
     "shell.execute_reply": "2022-04-02T22:59:46.846841Z",
     "shell.execute_reply.started": "2022-04-02T22:59:46.845111Z"
    },
    "id": "dd6Cm6gIQ5bH",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#?model.named_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2022-04-02T22:59:46.847733Z",
     "iopub.status.busy": "2022-04-02T22:59:46.847624Z",
     "iopub.status.idle": "2022-04-02T22:59:46.850939Z",
     "shell.execute_reply": "2022-04-02T22:59:46.850698Z",
     "shell.execute_reply.started": "2022-04-02T22:59:46.847722Z"
    },
    "executionInfo": {
     "elapsed": 29,
     "status": "ok",
     "timestamp": 1644711394772,
     "user": {
      "displayName": "Harpreet Singh",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgoHXww3A9iD3K6JH0yfUWV-xv9zq1wI6_3E9i8yw=s64",
      "userId": "10443507700807192111"
     },
     "user_tz": 360
    },
    "id": "8a9Kgdh5Un3B",
    "outputId": "62142e9e-7a40-44db-d141-cb171774ac88",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def init_weights(m):\n",
    "    for param in model.parameters():\n",
    "      nn.init.uniform_(param.data,-0.08, 0.08)\n",
    "# initilaize weights of  the model\n",
    "# model.apply(init_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kX8djfNtUn3B"
   },
   "source": [
    "We also define a function that will calculate the number of trainable parameters in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T22:59:47.007638Z",
     "iopub.status.busy": "2022-04-02T22:59:47.007511Z",
     "iopub.status.idle": "2022-04-02T22:59:47.009903Z",
     "shell.execute_reply": "2022-04-02T22:59:47.009514Z",
     "shell.execute_reply.started": "2022-04-02T22:59:47.007623Z"
    },
    "id": "DnbVucQjR0eH",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#?model.parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2022-04-02T22:59:48.696828Z",
     "iopub.status.busy": "2022-04-02T22:59:48.696687Z",
     "iopub.status.idle": "2022-04-02T22:59:48.699874Z",
     "shell.execute_reply": "2022-04-02T22:59:48.699537Z",
     "shell.execute_reply.started": "2022-04-02T22:59:48.696815Z"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1644711396408,
     "user": {
      "displayName": "Harpreet Singh",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgoHXww3A9iD3K6JH0yfUWV-xv9zq1wI6_3E9i8yw=s64",
      "userId": "10443507700807192111"
     },
     "user_tz": 360
    },
    "id": "SJW-AD6NUn3C",
    "outputId": "b97635e7-9d96-482b-da49-59d23b7341e9",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 6,110,473 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum([param.numel() for param in model.parameters() if param.requires_grad == True])\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kqFRDWy5Un3C"
   },
   "source": [
    "We define our optimizer, which we use to update our parameters in the training loop. Check out [this](http://ruder.io/optimizing-gradient-descent/) post for information about different optimizers. Here, we'll use Adam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T22:59:49.807814Z",
     "iopub.status.busy": "2022-04-02T22:59:49.807672Z",
     "iopub.status.idle": "2022-04-02T22:59:49.810415Z",
     "shell.execute_reply": "2022-04-02T22:59:49.810059Z",
     "shell.execute_reply.started": "2022-04-02T22:59:49.807800Z"
    },
    "id": "uQW8MwmpUn3C",
    "tags": []
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr= LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vP8-nNUgUn3C"
   },
   "source": [
    "Next, we define our loss function. The `CrossEntropyLoss` function calculates both the log softmax as well as the negative log-likelihood of our predictions. \n",
    "\n",
    "Our loss function calculates the average loss per token, however by passing the index of the `<pad>` token as the `ignore_index` argument we ignore the loss whenever the target token is a padding token. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T22:59:50.995858Z",
     "iopub.status.busy": "2022-04-02T22:59:50.995406Z",
     "iopub.status.idle": "2022-04-02T22:59:50.997570Z",
     "shell.execute_reply": "2022-04-02T22:59:50.997294Z",
     "shell.execute_reply.started": "2022-04-02T22:59:50.995841Z"
    },
    "id": "KBzVHWtZYH1q",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#?nn.CrossEntropyLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T22:59:51.271790Z",
     "iopub.status.busy": "2022-04-02T22:59:51.271665Z",
     "iopub.status.idle": "2022-04-02T22:59:51.274345Z",
     "shell.execute_reply": "2022-04-02T22:59:51.273948Z",
     "shell.execute_reply.started": "2022-04-02T22:59:51.271776Z"
    },
    "id": "HqDGxXU-2A7y",
    "tags": []
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss(ignore_index=DEC_PAD_IDX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DTSE8TjRUn3C"
   },
   "source": [
    "Next, we'll define our training loop. \n",
    "\n",
    "First, we'll set the model into \"training mode\" with `model.train()`. This will turn on dropout (and batch normalization, which we aren't using) and then iterate through our data iterator.\n",
    "\n",
    "As stated before, our decoder loop starts at 1, not 0. This means the 0th element of our `outputs` tensor remains all zeros. So our `trg` and `outputs` look something like:\n",
    "\n",
    "$$\\begin{align*}\n",
    "\\text{trg} = [<sos>, &y_1, y_2, y_3, <eos>]\\\\\n",
    "\\text{outputs} = [0, &\\hat{y}_1, \\hat{y}_2, \\hat{y}_3, <eos>]\n",
    "\\end{align*}$$\n",
    "\n",
    "Here, when we calculate the loss, we cut off the first element of each tensor to get:\n",
    "\n",
    "$$\\begin{align*}\n",
    "\\text{trg} = [&y_1, y_2, y_3, <eos>]\\\\\n",
    "\\text{outputs} = [&\\hat{y}_1, \\hat{y}_2, \\hat{y}_3, <eos>]\n",
    "\\end{align*}$$\n",
    "\n",
    "At each iteration:\n",
    "- get the source and target sentences from the batch, $X$ and $Y$\n",
    "- zero the gradients calculated from the last batch\n",
    "- feed the source and target into the model to get the output, $\\hat{Y}$\n",
    "- as the loss function only works on 2d inputs with 1d targets we need to flatten each of them with `.view`\n",
    "    - we slice off the first column of the output and target tensors as mentioned above\n",
    "- calculate the gradients with `loss.backward()`\n",
    "- clip the gradients to prevent them from exploding (a common issue in RNNs)\n",
    "- update the parameters of our model by doing an optimizer step\n",
    "- sum the loss value to a running total\n",
    "\n",
    "Finally, we return the loss that is averaged over all batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T22:59:52.396099Z",
     "iopub.status.busy": "2022-04-02T22:59:52.395977Z",
     "iopub.status.idle": "2022-04-02T22:59:52.398398Z",
     "shell.execute_reply": "2022-04-02T22:59:52.398129Z",
     "shell.execute_reply.started": "2022-04-02T22:59:52.396086Z"
    },
    "id": "mbO7CDnSlH83",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#?clip_grad_norm_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T22:59:52.658106Z",
     "iopub.status.busy": "2022-04-02T22:59:52.657930Z",
     "iopub.status.idle": "2022-04-02T22:59:52.662447Z",
     "shell.execute_reply": "2022-04-02T22:59:52.662099Z",
     "shell.execute_reply.started": "2022-04-02T22:59:52.658092Z"
    },
    "id": "BYKiriabUn3C",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#scaler = torch.cuda.amp.GradScaler()\n",
    "def train(model, iterator, optimizer, criterion, clip, teacher_enf_ratio):\n",
    "\n",
    "  model.train()\n",
    "  epoch_loss = 0\n",
    "\n",
    "  for src , tgt in iterator:\n",
    "    src = src.to(device)\n",
    "    tgt = tgt.to(device)\n",
    "    \n",
    "\n",
    "    # get predictions\n",
    "    logits = model(src, tgt, teacher_enf_ratio)\n",
    "\n",
    "    tgt = tgt[1:,:] # first seq corresponds to token '<BOS>'\n",
    "    logits = logits[1:, :]\n",
    "\n",
    "    num_classes  = logits.shape[-1]\n",
    "    logits = logits.view(-1, num_classes) # [(trg_seq_length-1) * batch_size, num_classes]\n",
    "    tgt = tgt.view(-1) # [(trg_seq_length-1) * batch_size]\n",
    "\n",
    "    # set gradients to zero to avoid gradient accumulation from previous iterations\n",
    "    optimizer.zero_grad\n",
    "\n",
    "    # calculate loss\n",
    "    #with torch.cuda.amp.autocast():\n",
    "    loss = criterion(logits, tgt)\n",
    "\n",
    "    # calculate gradients\n",
    "    loss.backward()\n",
    "    #scaler.scale(loss).backward()\n",
    "\n",
    "    # clip gradients\n",
    "    clip_grad_norm_(model.parameters(), clip)\n",
    "\n",
    "    # update parameters\n",
    "    optimizer.step()\n",
    "    \n",
    "    #scaler.step(optimizer)\n",
    "    #scaler.update()\n",
    "    \n",
    "    epoch_loss+= loss.item()\n",
    "\n",
    "  return epoch_loss/len(iterator)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XEEHX3lcUn3C"
   },
   "source": [
    "Our evaluation loop is similar to our training loop, however as we aren't updating any parameters we don't need to pass an optimizer or a clip value.\n",
    "\n",
    "We must remember to set the model to evaluation mode with `model.eval()`. This will turn off dropout (and batch normalization, if used).\n",
    "\n",
    "We use the `with torch.no_grad()` block to ensure no gradients are calculated within the block. This reduces memory consumption and speeds things up. \n",
    "\n",
    "The iteration loop is similar (without the parameter updates), however we must ensure we turn teacher forcing off for evaluation. This will cause the model to only use it's own predictions to make further predictions within a sentence, which mirrors how it would be used in deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T22:59:53.621099Z",
     "iopub.status.busy": "2022-04-02T22:59:53.620929Z",
     "iopub.status.idle": "2022-04-02T22:59:53.623368Z",
     "shell.execute_reply": "2022-04-02T22:59:53.623035Z",
     "shell.execute_reply.started": "2022-04-02T22:59:53.621070Z"
    },
    "id": "lpszry-1qZBY",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#?model.state_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2022-04-02T22:59:53.909469Z",
     "iopub.status.busy": "2022-04-02T22:59:53.909299Z",
     "iopub.status.idle": "2022-04-02T22:59:53.912464Z",
     "shell.execute_reply": "2022-04-02T22:59:53.912046Z",
     "shell.execute_reply.started": "2022-04-02T22:59:53.909440Z"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1644711402706,
     "user": {
      "displayName": "Harpreet Singh",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgoHXww3A9iD3K6JH0yfUWV-xv9zq1wI6_3E9i8yw=s64",
      "userId": "10443507700807192111"
     },
     "user_tz": 360
    },
    "id": "9zn4MU29vVbb",
    "outputId": "b80d3452-b232-4083-ca75-39e1be1430e7",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nm=torch.arange(10).view(5,2)\\nprint(m)\\nm = m[1:]\\nprint(m)\\n'"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "m=torch.arange(10).view(5,2)\n",
    "print(m)\n",
    "m = m[1:]\n",
    "print(m)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T22:59:54.595622Z",
     "iopub.status.busy": "2022-04-02T22:59:54.595481Z",
     "iopub.status.idle": "2022-04-02T22:59:54.599405Z",
     "shell.execute_reply": "2022-04-02T22:59:54.598978Z",
     "shell.execute_reply.started": "2022-04-02T22:59:54.595609Z"
    },
    "id": "q_0CMMb9Un3C",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion, teacher_enf_ratio):\n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "  \n",
    "\n",
    "    with torch.no_grad():\n",
    "      for src , tgt in iterator:\n",
    "\n",
    "        src = src.to(device) # [src_seq_len, batch_size]\n",
    "\n",
    "        tgt = tgt.to(device) # [tgt_seq_len, batch_size]\n",
    "\n",
    "        # get predictions\n",
    "        logits = model(src, tgt, teacher_enf_ratio) # [trg_seq_length, batch_size, tgt_vocab_size]\n",
    "\n",
    "        tgt = tgt[1:,:] # first seq corresponds to token '<BOS>'\n",
    "        logits = logits[1:, :]\n",
    "\n",
    "        num_classes  = logits.shape[-1]\n",
    "        logits = logits.view(-1, num_classes) # [(trg_seq_length-1) * batch_size, num_classes]\n",
    "        tgt = tgt.view(-1) # [(trg_seq_length-1) * batch_size]\n",
    "\n",
    "        # calculate loss\n",
    "        loss = criterion(logits, tgt)\n",
    "\n",
    "        epoch_loss+= loss.item()\n",
    "\n",
    "    return epoch_loss/len(iterator)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dBWvFyRmUn3D"
   },
   "source": [
    "Next, we'll create a function that we'll use to tell us how long an epoch takes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T22:59:55.631142Z",
     "iopub.status.busy": "2022-04-02T22:59:55.630997Z",
     "iopub.status.idle": "2022-04-02T22:59:55.633924Z",
     "shell.execute_reply": "2022-04-02T22:59:55.633487Z",
     "shell.execute_reply.started": "2022-04-02T22:59:55.631129Z"
    },
    "id": "dwfIeh7XUn3D",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2022-04-02T22:59:56.201505Z",
     "iopub.status.busy": "2022-04-02T22:59:56.201365Z",
     "iopub.status.idle": "2022-04-02T22:59:56.204393Z",
     "shell.execute_reply": "2022-04-02T22:59:56.204149Z",
     "shell.execute_reply.started": "2022-04-02T22:59:56.201491Z"
    },
    "executionInfo": {
     "elapsed": 23,
     "status": "ok",
     "timestamp": 1644711404963,
     "user": {
      "displayName": "Harpreet Singh",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgoHXww3A9iD3K6JH0yfUWV-xv9zq1wI6_3E9i8yw=s64",
      "userId": "10443507700807192111"
     },
     "user_tz": 360
    },
    "id": "_cqyilmll23Q",
    "outputId": "52c9d66e-0fc0-4842-d86a-b6f069805b7e",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nstart_time = time.time()\\nprint('start time', start_time)\\ntime.sleep(63)\\nend_time = time.time()\\nprint('end time', end_time)\\nelapsed_time = end_time-start_time\\nprint('elapsed time', elapsed_time)\\nelapsed_mins= int(elapsed_time/60)\\nprint('elapsed mins',elapsed_mins)\\nelapsed_secs = int(elapsed_time - (elapsed_mins * 60))\\nprint('elapsed secs', elapsed_secs)\\n\""
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# understanding the above function\n",
    "'''\n",
    "start_time = time.time()\n",
    "print('start time', start_time)\n",
    "time.sleep(63)\n",
    "end_time = time.time()\n",
    "print('end time', end_time)\n",
    "elapsed_time = end_time-start_time\n",
    "print('elapsed time', elapsed_time)\n",
    "elapsed_mins= int(elapsed_time/60)\n",
    "print('elapsed mins',elapsed_mins)\n",
    "elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "print('elapsed secs', elapsed_secs)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n16Yz_VcUn3D"
   },
   "source": [
    "We can finally start training our model!\n",
    "\n",
    "At each epoch, we'll be checking if our model has achieved the best validation loss so far. If it has, we'll update our best validation loss and save the parameters of our model (called `state_dict` in PyTorch). Then, when we come to test our model, we'll use the saved parameters used to achieve the best validation loss. \n",
    "\n",
    "We'll be printing out both the loss and the perplexity at each epoch. It is easier to see a change in perplexity than a change in loss as the numbers are much bigger."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T22:59:57.232833Z",
     "iopub.status.busy": "2022-04-02T22:59:57.232692Z",
     "iopub.status.idle": "2022-04-02T22:59:59.915144Z",
     "shell.execute_reply": "2022-04-02T22:59:59.914841Z",
     "shell.execute_reply.started": "2022-04-02T22:59:57.232819Z"
    },
    "id": "hwb9CKodYAwm",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import  gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 683
    },
    "execution": {
     "iopub.execute_input": "2022-04-02T22:59:59.915897Z",
     "iopub.status.busy": "2022-04-02T22:59:59.915785Z",
     "iopub.status.idle": "2022-04-02T23:24:26.598678Z",
     "shell.execute_reply": "2022-04-02T23:24:26.596334Z",
     "shell.execute_reply.started": "2022-04-02T22:59:59.915884Z"
    },
    "executionInfo": {
     "elapsed": 10333,
     "status": "error",
     "timestamp": 1644711418496,
     "user": {
      "displayName": "Harpreet Singh",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgoHXww3A9iD3K6JH0yfUWV-xv9zq1wI6_3E9i8yw=s64",
      "userId": "10443507700807192111"
     },
     "user_tz": 360
    },
    "id": "7vyJuNQzUn3D",
    "outputId": "76d30891-a136-4293-9914-6c1d38586441",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Time: 1m 41s\n",
      "\tTrain Loss: 5.989 | Train PPL: 398.859\n",
      "\t Val. Loss: 5.773 |  Val. PPL: 321.345\n",
      "Epoch: 02 | Time: 1m 45s\n",
      "\tTrain Loss: 5.684 | Train PPL: 294.098\n",
      "\t Val. Loss: 5.739 |  Val. PPL: 310.634\n",
      "Epoch: 03 | Time: 1m 42s\n",
      "\tTrain Loss: 5.528 | Train PPL: 251.549\n",
      "\t Val. Loss: 5.749 |  Val. PPL: 313.863\n",
      "Epoch: 04 | Time: 1m 43s\n",
      "\tTrain Loss: 5.412 | Train PPL: 224.110\n",
      "\t Val. Loss: 5.678 |  Val. PPL: 292.425\n",
      "Epoch: 05 | Time: 2m 29s\n",
      "\tTrain Loss: 5.290 | Train PPL: 198.379\n",
      "\t Val. Loss: 5.697 |  Val. PPL: 297.979\n",
      "Epoch: 06 | Time: 2m 44s\n",
      "\tTrain Loss: 5.193 | Train PPL: 179.974\n",
      "\t Val. Loss: 5.673 |  Val. PPL: 290.974\n",
      "Epoch: 07 | Time: 3m 41s\n",
      "\tTrain Loss: 5.124 | Train PPL: 168.079\n",
      "\t Val. Loss: 5.593 |  Val. PPL: 268.519\n",
      "Epoch: 08 | Time: 4m 12s\n",
      "\tTrain Loss: 5.076 | Train PPL: 160.099\n",
      "\t Val. Loss: 5.594 |  Val. PPL: 268.719\n",
      "Epoch: 09 | Time: 2m 25s\n",
      "\tTrain Loss: 5.050 | Train PPL: 156.020\n",
      "\t Val. Loss: 5.630 |  Val. PPL: 278.551\n",
      "Epoch: 10 | Time: 1m 59s\n",
      "\tTrain Loss: 4.995 | Train PPL: 147.690\n",
      "\t Val. Loss: 5.561 |  Val. PPL: 260.001\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 10\n",
    "CLIP = 1\n",
    "TRAIN_TEACHER_ENF_RATIO = 0.5\n",
    "VALID_TEACHER_ENF_RATIO = 0 # turn off teacher enforcing for evaluation\n",
    "\n",
    "min_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_loss = train(model, train_loader, optimizer, criterion, CLIP, TRAIN_TEACHER_ENF_RATIO)\n",
    "    valid_loss = evaluate(model, valid_loader, criterion, VALID_TEACHER_ENF_RATIO)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    \n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "    # save the model corresponding to min vlaid loss\n",
    "    if valid_loss<min_valid_loss:\n",
    "      min_valid_loss = valid_loss\n",
    "      torch.save(model.state_dict(), folder/'1c_en_hi.pt')\n",
    "    \n",
    "   \n",
    "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UeXMknRvUn3D"
   },
   "source": [
    "We'll load the parameters (`state_dict`) that gave our model the best validation loss and run it the model on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-03T04:10:31.213313Z",
     "iopub.status.busy": "2022-04-03T04:10:31.213185Z",
     "iopub.status.idle": "2022-04-03T04:10:32.575974Z",
     "shell.execute_reply": "2022-04-03T04:10:32.575636Z",
     "shell.execute_reply.started": "2022-04-03T04:10:31.213299Z"
    },
    "id": "YFz9w3KmUn3D",
    "outputId": "7a774bcc-4e6a-49fb-9aa9-7721ca632267",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Test Loss: 5.561 | Test PPL: 260.001 |\n"
     ]
    }
   ],
   "source": [
    "# load the saved model and get test loss\n",
    "model.load_state_dict(torch.load(folder/'1c_en_hi.pt'))\n",
    "test_loss = evaluate(model, test_loader, criterion, 0)\n",
    "print(f'| Test Loss: {test_loss:.3f} | Test PPL: {math.exp(test_loss):7.3f} |')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3d61-wekUn3D"
   },
   "source": [
    "In the following notebook we'll implement a model that achieves improved test perplexity, but only uses a single layer in the encoder and the decoder."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "z8HEHfMGl23I"
   ],
   "machine_shape": "hm",
   "name": "1c -En-Hi seq-seq Learning with Neural Networks.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "pt10",
   "language": "python",
   "name": "pt10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
