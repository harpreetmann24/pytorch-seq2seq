{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MjTMLaX0Un22"
   },
   "source": [
    "# <font color = 'blue'>1 - Sequence to Sequence Learning with Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jMIVwQyitAXd"
   },
   "source": [
    "# <font color = 'blue'>Import Libraries\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-03T05:01:44.278948Z",
     "iopub.status.busy": "2022-04-03T05:01:44.278813Z",
     "iopub.status.idle": "2022-04-03T05:01:44.281081Z",
     "shell.execute_reply": "2022-04-03T05:01:44.280709Z",
     "shell.execute_reply.started": "2022-04-03T05:01:44.278935Z"
    },
    "id": "9uY_ZBxdtH_k",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-03T05:02:28.901755Z",
     "iopub.status.busy": "2022-04-03T05:02:28.901618Z",
     "iopub.status.idle": "2022-04-03T05:02:28.904480Z",
     "shell.execute_reply": "2022-04-03T05:02:28.904103Z",
     "shell.execute_reply.started": "2022-04-03T05:02:28.901742Z"
    },
    "id": "LLLu5aF_VkRw",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "data_folder = Path('/home/harpreet/Insync/google_drive_shaannoor/Data/NLP')\n",
    "#data_folder = Path('/content/drive/MyDrive/Data/NLP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-26T11:42:32.416568Z",
     "iopub.status.busy": "2022-03-26T11:42:32.416418Z",
     "iopub.status.idle": "2022-03-26T11:42:32.418651Z",
     "shell.execute_reply": "2022-03-26T11:42:32.418385Z",
     "shell.execute_reply.started": "2022-03-26T11:42:32.416526Z"
    },
    "id": "91gNGmdCvrvp",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pip install -U spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2022-04-03T05:02:57.627708Z",
     "iopub.status.busy": "2022-04-03T05:02:57.627571Z",
     "iopub.status.idle": "2022-04-03T05:02:58.443545Z",
     "shell.execute_reply": "2022-04-03T05:02:58.443110Z",
     "shell.execute_reply.started": "2022-04-03T05:02:57.627696Z"
    },
    "executionInfo": {
     "elapsed": 103,
     "status": "ok",
     "timestamp": 1643995178240,
     "user": {
      "displayName": "Shaannoor Mann",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "02520257695567980696"
     },
     "user_tz": 360
    },
    "id": "PY9-guO2Un25",
    "outputId": "1859f72c-9677-4072-d8aa-644fe11d8ec2",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('0.11.0', '1.10.0', True, '3.2.4')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torchtext, torch, spacy\n",
    "torchtext.__version__, torch.__version__, torch.cuda.is_available(), spacy.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wRVU8aBPUn26"
   },
   "source": [
    "# <font color = 'blue'> Set Seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-03T05:03:28.588064Z",
     "iopub.status.busy": "2022-04-03T05:03:28.587920Z",
     "iopub.status.idle": "2022-04-03T05:03:28.591699Z",
     "shell.execute_reply": "2022-04-03T05:03:28.591281Z",
     "shell.execute_reply.started": "2022-04-03T05:03:28.588050Z"
    },
    "id": "vzCQltiuUn26",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "SEED = 1234\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-01T00:00:54.606189Z",
     "iopub.status.busy": "2022-02-01T00:00:54.606047Z",
     "iopub.status.idle": "2022-02-01T00:00:54.608419Z",
     "shell.execute_reply": "2022-02-01T00:00:54.608102Z",
     "shell.execute_reply.started": "2022-02-01T00:00:54.606174Z"
    },
    "id": "7OKdOYoVUn28"
   },
   "source": [
    "# <font color = 'blue'> Load Data and Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2022-03-26T11:42:35.515964Z",
     "iopub.status.busy": "2022-03-26T11:42:35.515826Z",
     "iopub.status.idle": "2022-03-26T11:42:35.518301Z",
     "shell.execute_reply": "2022-03-26T11:42:35.517859Z",
     "shell.execute_reply.started": "2022-03-26T11:42:35.515951Z"
    },
    "executionInfo": {
     "elapsed": 8397,
     "status": "ok",
     "timestamp": 1643995195567,
     "user": {
      "displayName": "Shaannoor Mann",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "02520257695567980696"
     },
     "user_tz": 360
    },
    "id": "9soHmZzMtAXg",
    "outputId": "9e44002b-f861-433d-f054-249b229e27cb",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2022-03-26T11:42:35.845618Z",
     "iopub.status.busy": "2022-03-26T11:42:35.845480Z",
     "iopub.status.idle": "2022-03-26T11:42:35.847843Z",
     "shell.execute_reply": "2022-03-26T11:42:35.847501Z",
     "shell.execute_reply.started": "2022-03-26T11:42:35.845605Z"
    },
    "executionInfo": {
     "elapsed": 9421,
     "status": "ok",
     "timestamp": 1643995212286,
     "user": {
      "displayName": "Shaannoor Mann",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "02520257695567980696"
     },
     "user_tz": 360
    },
    "id": "qRspLoflUn28",
    "outputId": "2158b71a-b359-4ce2-b19f-ea07f1d67114",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!python -m spacy download de_core_news_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-03T05:03:37.949964Z",
     "iopub.status.busy": "2022-04-03T05:03:37.949818Z",
     "iopub.status.idle": "2022-04-03T05:03:39.090248Z",
     "shell.execute_reply": "2022-04-03T05:03:39.089731Z",
     "shell.execute_reply.started": "2022-04-03T05:03:37.949950Z"
    },
    "id": "eboUqZ8HUn28",
    "tags": []
   },
   "outputs": [],
   "source": [
    "nlp_de = spacy.load('de_core_news_sm')\n",
    "nlp_en = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dqPoMmkOUn29"
   },
   "source": [
    "<font color ='green'>\n",
    "Next, we create the tokenizer functions. These can be passed to torchtext and will take in the sentence as a string and return the sentence as a list of tokens.\n",
    "\n",
    "<font color = 'red'>**In the paper we are implementing, they find it beneficial to reverse the order of the input which they believe \"introduces many short term dependencies in the data that make the optimization problem much easier\".We copy this by reversing the German sentence after it has been transformed into a list of tokens.**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BPVYRwB-Un29"
   },
   "source": [
    "<font color ='green'> Next, we download and load the train, validation and test data. \n",
    "The dataset we'll be using is the [Multi30k dataset](https://github.com/multi30k/dataset). This is a dataset with ~30,000 parallel English, German and French sentences, each with ~12 words per sentence. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-26T11:42:37.810200Z",
     "iopub.status.busy": "2022-03-26T11:42:37.810034Z",
     "iopub.status.idle": "2022-03-26T11:42:37.812629Z",
     "shell.execute_reply": "2022-03-26T11:42:37.812188Z",
     "shell.execute_reply.started": "2022-03-26T11:42:37.810186Z"
    },
    "id": "I6x_k8CDWBnS",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!mkdir /home/harpreet/Insync/google_drive_shaannoor/Data/NLP/Multi30k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-03T05:08:24.770914Z",
     "iopub.status.busy": "2022-04-03T05:08:24.770773Z",
     "iopub.status.idle": "2022-04-03T05:08:24.812932Z",
     "shell.execute_reply": "2022-04-03T05:08:24.812536Z",
     "shell.execute_reply.started": "2022-04-03T05:08:24.770900Z"
    },
    "id": "nKVEUK7JUn29",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for this example we are choosing only first two rows\n",
    "import pandas as pd\n",
    "from torchtext.datasets import Multi30k\n",
    "for split in ['train', 'valid', 'test']:\n",
    "    df[split] = pd.DataFrame(Multi30k(root= data_folder/'Multi30k', \n",
    "                                      split=split,language_pair=('de', 'en')))[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-03T05:08:28.240832Z",
     "iopub.status.busy": "2022-04-03T05:08:28.240691Z",
     "iopub.status.idle": "2022-04-03T05:08:28.243396Z",
     "shell.execute_reply": "2022-04-03T05:08:28.242977Z",
     "shell.execute_reply.started": "2022-04-03T05:08:28.240818Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-03T05:08:28.413712Z",
     "iopub.status.busy": "2022-04-03T05:08:28.413558Z",
     "iopub.status.idle": "2022-04-03T05:08:28.416232Z",
     "shell.execute_reply": "2022-04-03T05:08:28.415931Z",
     "shell.execute_reply.started": "2022-04-03T05:08:28.413698Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "execution": {
     "iopub.execute_input": "2022-04-03T05:08:28.895353Z",
     "iopub.status.busy": "2022-04-03T05:08:28.895197Z",
     "iopub.status.idle": "2022-04-03T05:08:28.900979Z",
     "shell.execute_reply": "2022-04-03T05:08:28.900727Z",
     "shell.execute_reply.started": "2022-04-03T05:08:28.895339Z"
    },
    "executionInfo": {
     "elapsed": 122,
     "status": "ok",
     "timestamp": 1643995235646,
     "user": {
      "displayName": "Shaannoor Mann",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "02520257695567980696"
     },
     "user_tz": 360
    },
    "id": "tnMfvu1htAXi",
    "outputId": "07d716c2-bf2e-4253-9625-1c911d4d8ec1",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Zwei junge weiße Männer sind im Freien in der Nähe vieler Büsche.\\n</td>\n",
       "      <td>Two young, White males are outside near many bushes.\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mehrere Männer mit Schutzhelmen bedienen ein Antriebsradsystem.\\n</td>\n",
       "      <td>Several men in hard hats are operating a giant pulley system.\\n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                     0  \\\n",
       "0  Zwei junge weiße Männer sind im Freien in der Nähe vieler Büsche.\\n   \n",
       "1    Mehrere Männer mit Schutzhelmen bedienen ein Antriebsradsystem.\\n   \n",
       "\n",
       "                                                                 1  \n",
       "0           Two young, White males are outside near many bushes.\\n  \n",
       "1  Several men in hard hats are operating a giant pulley system.\\n  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-03T05:09:55.302339Z",
     "iopub.status.busy": "2022-04-03T05:09:55.302197Z",
     "iopub.status.idle": "2022-04-03T05:09:55.305857Z",
     "shell.execute_reply": "2022-04-03T05:09:55.305366Z",
     "shell.execute_reply.started": "2022-04-03T05:09:55.302325Z"
    },
    "id": "EOXULalHtAXi",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def tokenizer(data_array, spacy_model, reverse = False):\n",
    "    token_list =[]\n",
    "    disabled = spacy_model.select_pipes(disable= ['tok2vec', 'tagger', \n",
    "                                                  'parser', 'attribute_ruler', \n",
    "                                                  'lemmatizer', 'ner'])\n",
    "    for doc in nlp_en.pipe(data_array, batch_size=1000, n_process=-1):\n",
    "        tokens = [token.text.lower() for token in doc if token.text not in ['\\n']] \n",
    "        if reverse:\n",
    "            tokens.reverse()\n",
    "        token_list.append(tokens)\n",
    "    disabled.restore()\n",
    "    return token_list                         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-03T05:09:55.852022Z",
     "iopub.status.busy": "2022-04-03T05:09:55.851884Z",
     "iopub.status.idle": "2022-04-03T05:09:56.498406Z",
     "shell.execute_reply": "2022-04-03T05:09:56.497873Z",
     "shell.execute_reply.started": "2022-04-03T05:09:55.852008Z"
    },
    "id": "DZb6UUHltAXi",
    "tags": []
   },
   "outputs": [],
   "source": [
    "for split in ['train', 'valid', 'test']:\n",
    "    df[split]['source_tokens'] = tokenizer(df[split].iloc[:,0].values, \n",
    "                                           nlp_de, reverse = True)\n",
    "    df[split]['target_tokens'] = tokenizer(df[split].iloc[:,1].values, nlp_de)\n",
    "    df[split] = df[split][['source_tokens', 'target_tokens']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "execution": {
     "iopub.execute_input": "2022-04-03T05:09:59.830954Z",
     "iopub.status.busy": "2022-04-03T05:09:59.830791Z",
     "iopub.status.idle": "2022-04-03T05:09:59.836722Z",
     "shell.execute_reply": "2022-04-03T05:09:59.836395Z",
     "shell.execute_reply.started": "2022-04-03T05:09:59.830938Z"
    },
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1643995379789,
     "user": {
      "displayName": "Shaannoor Mann",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "02520257695567980696"
     },
     "user_tz": 360
    },
    "id": "fDKpYa7mtAXi",
    "outputId": "75144544-b313-42b2-cbad-cd3d108ea76f",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_tokens</th>\n",
       "      <th>target_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[., büsche, vieler, nähe, der, in, freien, m, i, sind, männer, weiße, junge, zwei]</td>\n",
       "      <td>[two, young, ,, white, males, are, outside, near, many, bushes, .]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[., antriebsradsystem, ein, bedienen, schutzhelmen, mit, männer, mehrere]</td>\n",
       "      <td>[several, men, in, hard, hats, are, operating, a, giant, pulley, system, .]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                        source_tokens  \\\n",
       "0  [., büsche, vieler, nähe, der, in, freien, m, i, sind, männer, weiße, junge, zwei]   \n",
       "1           [., antriebsradsystem, ein, bedienen, schutzhelmen, mit, männer, mehrere]   \n",
       "\n",
       "                                                                 target_tokens  \n",
       "0           [two, young, ,, white, males, are, outside, near, many, bushes, .]  \n",
       "1  [several, men, in, hard, hats, are, operating, a, giant, pulley, system, .]  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2022-03-26T11:42:42.312344Z",
     "iopub.status.busy": "2022-03-26T11:42:42.311841Z",
     "iopub.status.idle": "2022-03-26T11:42:42.314780Z",
     "shell.execute_reply": "2022-03-26T11:42:42.314481Z",
     "shell.execute_reply.started": "2022-03-26T11:42:42.312328Z"
    },
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1643995379790,
     "user": {
      "displayName": "Shaannoor Mann",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "02520257695567980696"
     },
     "user_tz": 360
    },
    "id": "BM1UfGJKtAXj",
    "outputId": "2cba46c8-282a-4c22-c262-580ec4cd091b",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.', 'büsche', 'vieler', 'nähe', 'der', 'in', 'freien', 'm', 'i', 'sind', 'männer', 'weiße', 'junge', 'zwei']\n"
     ]
    }
   ],
   "source": [
    "print(df['train']['source_tokens'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "If-BMrTctAXj"
   },
   "source": [
    "# <font color = 'blue'> Build Vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-03T05:12:29.612463Z",
     "iopub.status.busy": "2022-04-03T05:12:29.612309Z",
     "iopub.status.idle": "2022-04-03T05:12:29.615298Z",
     "shell.execute_reply": "2022-04-03T05:12:29.614966Z",
     "shell.execute_reply.started": "2022-04-03T05:12:29.612450Z"
    },
    "id": "GY9kL2JxtAXj",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from torchtext.vocab import vocab\n",
    "def create_vocab(text, min_freq, specials):\n",
    "    my_counter = Counter()\n",
    "    for line in text:\n",
    "       my_counter.update(line)\n",
    "    my_vocab = vocab(my_counter, min_freq=min_freq)\n",
    "    for i, special in enumerate(specials):\n",
    "        my_vocab.insert_token(special, i)\n",
    "    my_vocab.set_default_index(0)\n",
    "    return my_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-03T05:12:30.160187Z",
     "iopub.status.busy": "2022-04-03T05:12:30.160032Z",
     "iopub.status.idle": "2022-04-03T05:12:30.189206Z",
     "shell.execute_reply": "2022-04-03T05:12:30.188836Z",
     "shell.execute_reply.started": "2022-04-03T05:12:30.160174Z"
    },
    "id": "dcvIJAIHtAXj",
    "tags": []
   },
   "outputs": [],
   "source": [
    "source_vocab = create_vocab(text = df['train']['source_tokens'], \n",
    "                            min_freq=1, \n",
    "                            specials=['<unk>', '<BOS>', '<EOS>', '<PAD>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2022-04-03T05:12:34.416566Z",
     "iopub.status.busy": "2022-04-03T05:12:34.416349Z",
     "iopub.status.idle": "2022-04-03T05:12:34.420032Z",
     "shell.execute_reply": "2022-04-03T05:12:34.419643Z",
     "shell.execute_reply.started": "2022-04-03T05:12:34.416525Z"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1643995379915,
     "user": {
      "displayName": "Shaannoor Mann",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "02520257695567980696"
     },
     "user_tz": 360
    },
    "id": "qtEt9Sh-tAXk",
    "outputId": "51fe0573-13db-4dd8-9bcc-444983e279ab",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(source_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-03T05:12:35.019655Z",
     "iopub.status.busy": "2022-04-03T05:12:35.019181Z",
     "iopub.status.idle": "2022-04-03T05:12:35.022000Z",
     "shell.execute_reply": "2022-04-03T05:12:35.021532Z",
     "shell.execute_reply.started": "2022-04-03T05:12:35.019638Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "execution": {
     "iopub.execute_input": "2022-04-03T05:12:35.623047Z",
     "iopub.status.busy": "2022-04-03T05:12:35.622897Z",
     "iopub.status.idle": "2022-04-03T05:12:35.630146Z",
     "shell.execute_reply": "2022-04-03T05:12:35.629828Z",
     "shell.execute_reply.started": "2022-04-03T05:12:35.623034Z"
    },
    "executionInfo": {
     "elapsed": 135,
     "status": "ok",
     "timestamp": 1643995380047,
     "user": {
      "displayName": "Shaannoor Mann",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "02520257695567980696"
     },
     "user_tz": 360
    },
    "id": "bf9fu5L2tAXk",
    "outputId": "36c7a483-69cd-4144-d3e7-9861f4313257",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "      <th>index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>&lt;unk&gt;</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>&lt;BOS&gt;</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>&lt;EOS&gt;</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>&lt;PAD&gt;</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>.</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>büsche</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>vieler</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>nähe</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>der</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>in</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>freien</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>m</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>i</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>sind</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>männer</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>weiße</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>junge</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>zwei</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>antriebsradsystem</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ein</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>bedienen</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>schutzhelmen</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mit</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mehrere</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               tokens  index\n",
       "8               <unk>      0\n",
       "20              <BOS>      1\n",
       "10              <EOS>      2\n",
       "15              <PAD>      3\n",
       "12                  .      4\n",
       "18             büsche      5\n",
       "21             vieler      6\n",
       "16               nähe      7\n",
       "19                der      8\n",
       "11                 in      9\n",
       "22             freien     10\n",
       "23                  m     11\n",
       "14                  i     12\n",
       "17               sind     13\n",
       "7              männer     14\n",
       "6               weiße     15\n",
       "3               junge     16\n",
       "5                zwei     17\n",
       "4   antriebsradsystem     18\n",
       "13                ein     19\n",
       "9            bedienen     20\n",
       "2        schutzhelmen     21\n",
       "1                 mit     22\n",
       "0             mehrere     23"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(source_vocab.get_stoi().items(), columns=['tokens', 'index']).sort_values(by = ['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2022-04-03T05:12:44.467073Z",
     "iopub.status.busy": "2022-04-03T05:12:44.466925Z",
     "iopub.status.idle": "2022-04-03T05:12:44.470054Z",
     "shell.execute_reply": "2022-04-03T05:12:44.469622Z",
     "shell.execute_reply.started": "2022-04-03T05:12:44.467060Z"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1643995380047,
     "user": {
      "displayName": "Shaannoor Mann",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "02520257695567980696"
     },
     "user_tz": 360
    },
    "id": "8pKCTbN6tAXk",
    "outputId": "07e63922-a91f-40ec-ce96-118c31d2d529",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check index of unknown word - it should be zero\n",
    "source_vocab['abracdabra']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-03T05:12:45.086274Z",
     "iopub.status.busy": "2022-04-03T05:12:45.086132Z",
     "iopub.status.idle": "2022-04-03T05:12:45.116436Z",
     "shell.execute_reply": "2022-04-03T05:12:45.116089Z",
     "shell.execute_reply.started": "2022-04-03T05:12:45.086261Z"
    },
    "id": "qkXg6IratAXk",
    "tags": []
   },
   "outputs": [],
   "source": [
    "target_vocab = create_vocab(df['train']['target_tokens'], 1, ['<unk>', '<BOS>', '<EOS>', '<PAD>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2022-04-03T05:12:45.624981Z",
     "iopub.status.busy": "2022-04-03T05:12:45.624840Z",
     "iopub.status.idle": "2022-04-03T05:12:45.628495Z",
     "shell.execute_reply": "2022-04-03T05:12:45.628101Z",
     "shell.execute_reply.started": "2022-04-03T05:12:45.624968Z"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1643995380202,
     "user": {
      "displayName": "Shaannoor Mann",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "02520257695567980696"
     },
     "user_tz": 360
    },
    "id": "v_Y8C62GtAXk",
    "outputId": "5acd4d1a-89c8-4feb-f9e7-fbe0410de095",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(target_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-03T05:12:46.632174Z",
     "iopub.status.busy": "2022-04-03T05:12:46.632036Z",
     "iopub.status.idle": "2022-04-03T05:12:46.638680Z",
     "shell.execute_reply": "2022-04-03T05:12:46.638359Z",
     "shell.execute_reply.started": "2022-04-03T05:12:46.632161Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "      <th>index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>&lt;unk&gt;</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>&lt;BOS&gt;</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>&lt;EOS&gt;</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>&lt;PAD&gt;</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>two</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>young</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>,</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>white</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>males</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>are</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>outside</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>near</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>many</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>bushes</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>.</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>several</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>men</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>in</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>hard</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hats</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>operating</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>giant</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pulley</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>system</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       tokens  index\n",
       "22      <unk>      0\n",
       "10      <BOS>      1\n",
       "11      <EOS>      2\n",
       "12      <PAD>      3\n",
       "16        two      4\n",
       "14      young      5\n",
       "15          ,      6\n",
       "23      white      7\n",
       "17      males      8\n",
       "20        are      9\n",
       "21    outside     10\n",
       "24       near     11\n",
       "18       many     12\n",
       "9      bushes     13\n",
       "8           .     14\n",
       "6     several     15\n",
       "4         men     16\n",
       "7          in     17\n",
       "5        hard     18\n",
       "2        hats     19\n",
       "19  operating     20\n",
       "1           a     21\n",
       "0       giant     22\n",
       "3      pulley     23\n",
       "13     system     24"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(target_vocab.get_stoi().items(), columns=['tokens', 'index']).sort_values(by = ['index'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "feccYoeWtAXk"
   },
   "source": [
    "# <font color = 'blue'> Create Dataset and Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-03T05:13:40.671678Z",
     "iopub.status.busy": "2022-04-03T05:13:40.671537Z",
     "iopub.status.idle": "2022-04-03T05:13:40.674828Z",
     "shell.execute_reply": "2022-04-03T05:13:40.674540Z",
     "shell.execute_reply.started": "2022-04-03T05:13:40.671664Z"
    },
    "id": "fCMXepKUtAXk",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "class EngGerman(Dataset):\n",
    "    def __init__(self, X1, X2):\n",
    "        self.X1 = X1\n",
    "        self.X2 = X2\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.X1)\n",
    "    \n",
    "    def __getitem__(self, indices):\n",
    "        return (self.X1.iloc[indices] , self.X2.iloc[indices]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-03T05:13:44.892671Z",
     "iopub.status.busy": "2022-04-03T05:13:44.892528Z",
     "iopub.status.idle": "2022-04-03T05:13:44.895964Z",
     "shell.execute_reply": "2022-04-03T05:13:44.895338Z",
     "shell.execute_reply.started": "2022-04-03T05:13:44.892657Z"
    },
    "id": "-Q32VBamtAXl",
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainset = EngGerman(df['train']['source_tokens'], df['train']['target_tokens'])\n",
    "testset = EngGerman(df['test']['source_tokens'], df['test']['target_tokens'])\n",
    "validset = EngGerman(df['valid']['source_tokens'], df['valid']['target_tokens'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2022-04-03T05:13:45.552334Z",
     "iopub.status.busy": "2022-04-03T05:13:45.552184Z",
     "iopub.status.idle": "2022-04-03T05:13:45.556234Z",
     "shell.execute_reply": "2022-04-03T05:13:45.555894Z",
     "shell.execute_reply.started": "2022-04-03T05:13:45.552320Z"
    },
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1643997238474,
     "user": {
      "displayName": "Shaannoor Mann",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "02520257695567980696"
     },
     "user_tz": 360
    },
    "id": "2md5tDSutAXl",
    "outputId": "26f38f06-89a8-43c2-8988-73f214e91b7e",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['.',\n",
       "  'büsche',\n",
       "  'vieler',\n",
       "  'nähe',\n",
       "  'der',\n",
       "  'in',\n",
       "  'freien',\n",
       "  'm',\n",
       "  'i',\n",
       "  'sind',\n",
       "  'männer',\n",
       "  'weiße',\n",
       "  'junge',\n",
       "  'zwei'],\n",
       " ['two',\n",
       "  'young',\n",
       "  ',',\n",
       "  'white',\n",
       "  'males',\n",
       "  'are',\n",
       "  'outside',\n",
       "  'near',\n",
       "  'many',\n",
       "  'bushes',\n",
       "  '.'])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainset.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2022-04-03T05:13:53.692167Z",
     "iopub.status.busy": "2022-04-03T05:13:53.692029Z",
     "iopub.status.idle": "2022-04-03T05:13:53.695368Z",
     "shell.execute_reply": "2022-04-03T05:13:53.695038Z",
     "shell.execute_reply.started": "2022-04-03T05:13:53.692154Z"
    },
    "executionInfo": {
     "elapsed": 141,
     "status": "ok",
     "timestamp": 1643997241933,
     "user": {
      "displayName": "Shaannoor Mann",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "02520257695567980696"
     },
     "user_tz": 360
    },
    "id": "L18xzZrltAXl",
    "outputId": "c90ada94-83bb-4fe3-ca77-8988c01b9199",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 2, 2)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trainset), len(testset), len(validset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = 'green'> Convert words into indices, add index of <BOS> in the beginning and add index of <EOS> at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-03T05:14:15.580343Z",
     "iopub.status.busy": "2022-04-03T05:14:15.580205Z",
     "iopub.status.idle": "2022-04-03T05:14:15.583300Z",
     "shell.execute_reply": "2022-04-03T05:14:15.582757Z",
     "shell.execute_reply.started": "2022-04-03T05:14:15.580330Z"
    },
    "id": "bPg8WslltAXl",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def text_transform (my_vocab, text):\n",
    "     text_numerical = [my_vocab[token] for token in text]\n",
    "     return torch.tensor([source_vocab['<BOS>']] + text_numerical + [source_vocab['<EOS>']])\n",
    "     #return list(source_vocab['<BOS>']) + text_numerical + list(source_vocab['<EOS>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2022-04-03T05:15:57.353990Z",
     "iopub.status.busy": "2022-04-03T05:15:57.353852Z",
     "iopub.status.idle": "2022-04-03T05:15:57.357695Z",
     "shell.execute_reply": "2022-04-03T05:15:57.357455Z",
     "shell.execute_reply.started": "2022-04-03T05:15:57.353976Z"
    },
    "executionInfo": {
     "elapsed": 105,
     "status": "ok",
     "timestamp": 1643997245283,
     "user": {
      "displayName": "Shaannoor Mann",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "02520257695567980696"
     },
     "user_tz": 360
    },
    "id": "bpQKiRHLtAXl",
    "outputId": "5ae6fbd3-f4ad-4726-de6d-0dcdf2d0bca4",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['several', 'men', 'in', 'hard', 'hats', 'are', 'operating', 'a', 'giant', 'pulley', 'system', '.']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([ 1, 15, 16, 17, 18, 19,  9, 20, 21, 22, 23, 24, 14,  2])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = trainset.__getitem__(1)[1]\n",
    "print(text)\n",
    "text_transform(target_vocab, text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-03T05:17:03.789405Z",
     "iopub.status.busy": "2022-04-03T05:17:03.789268Z",
     "iopub.status.idle": "2022-04-03T05:17:03.792112Z",
     "shell.execute_reply": "2022-04-03T05:17:03.791669Z",
     "shell.execute_reply.started": "2022-04-03T05:17:03.789393Z"
    }
   },
   "source": [
    "<font color ='green'> Add  padding to batch of sentences using pad_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-03T05:19:02.902799Z",
     "iopub.status.busy": "2022-04-03T05:19:02.902641Z",
     "iopub.status.idle": "2022-04-03T05:19:02.905337Z",
     "shell.execute_reply": "2022-04-03T05:19:02.905066Z",
     "shell.execute_reply.started": "2022-04-03T05:19:02.902785Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "seq= [torch.tensor([1,2,4]), torch.tensor([3,4,5,6,7])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-03T05:19:40.697465Z",
     "iopub.status.busy": "2022-04-03T05:19:40.697309Z",
     "iopub.status.idle": "2022-04-03T05:19:40.701068Z",
     "shell.execute_reply": "2022-04-03T05:19:40.700693Z",
     "shell.execute_reply.started": "2022-04-03T05:19:40.697451Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  1,   2,   4, -10, -10],\n",
       "        [  3,   4,   5,   6,   7]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "padded_seq = pad_sequence(seq,batch_first=True,padding_value = -10)\n",
    "padded_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-03T05:19:44.048868Z",
     "iopub.status.busy": "2022-04-03T05:19:44.048713Z",
     "iopub.status.idle": "2022-04-03T05:19:44.051727Z",
     "shell.execute_reply": "2022-04-03T05:19:44.051434Z",
     "shell.execute_reply.started": "2022-04-03T05:19:44.048855Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 5])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_seq.shape # batch, seq len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-03T05:19:56.556278Z",
     "iopub.status.busy": "2022-04-03T05:19:56.556123Z",
     "iopub.status.idle": "2022-04-03T05:19:56.558685Z",
     "shell.execute_reply": "2022-04-03T05:19:56.558297Z",
     "shell.execute_reply.started": "2022-04-03T05:19:56.556264Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "padded_seq = pad_sequence(seq,batch_first=False,padding_value = -10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-03T05:19:57.384183Z",
     "iopub.status.busy": "2022-04-03T05:19:57.384028Z",
     "iopub.status.idle": "2022-04-03T05:19:57.387202Z",
     "shell.execute_reply": "2022-04-03T05:19:57.386849Z",
     "shell.execute_reply.started": "2022-04-03T05:19:57.384156Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  1,   3],\n",
       "        [  2,   4],\n",
       "        [  4,   5],\n",
       "        [-10,   6],\n",
       "        [-10,   7]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-03T05:19:58.107806Z",
     "iopub.status.busy": "2022-04-03T05:19:58.107651Z",
     "iopub.status.idle": "2022-04-03T05:19:58.110609Z",
     "shell.execute_reply": "2022-04-03T05:19:58.110268Z",
     "shell.execute_reply.started": "2022-04-03T05:19:58.107793Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 2])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_seq.shape # seq_len, batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-03T05:22:00.766451Z",
     "iopub.status.busy": "2022-04-03T05:22:00.766131Z",
     "iopub.status.idle": "2022-04-03T05:22:00.769322Z",
     "shell.execute_reply": "2022-04-03T05:22:00.768875Z",
     "shell.execute_reply.started": "2022-04-03T05:22:00.766435Z"
    }
   },
   "source": [
    "<font color = 'green'> Creare a function to specify transformations for a batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-03T05:22:14.201860Z",
     "iopub.status.busy": "2022-04-03T05:22:14.201725Z",
     "iopub.status.idle": "2022-04-03T05:22:14.204980Z",
     "shell.execute_reply": "2022-04-03T05:22:14.204563Z",
     "shell.execute_reply.started": "2022-04-03T05:22:14.201847Z"
    },
    "id": "CgKupdZ1Un2-",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def collate_batch(batch):\n",
    "   source_list, target_list = [], []\n",
    "   for (source_text, target_text) in batch:\n",
    "        source_transform = text_transform(source_vocab, source_text)\n",
    "        source_list.append(source_transform)\n",
    "        target_transform =text_transform(target_vocab, target_text)\n",
    "        target_list.append(target_transform)\n",
    "        \n",
    "   source_pad = pad_sequence(source_list, padding_value=3.0)\n",
    "   target_pad = pad_sequence(target_list, padding_value=3.0)\n",
    "   #print(source_list)\n",
    "   return (source_pad, target_pad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-03T05:22:36.506596Z",
     "iopub.status.busy": "2022-04-03T05:22:36.506420Z",
     "iopub.status.idle": "2022-04-03T05:22:36.509464Z",
     "shell.execute_reply": "2022-04-03T05:22:36.509000Z",
     "shell.execute_reply.started": "2022-04-03T05:22:36.506550Z"
    },
    "id": "EqHCA63DUn2_",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "batch_size = 2\n",
    "\n",
    "train_loader = DataLoader(trainset, batch_size=batch_size, shuffle=True, \n",
    "                              collate_fn=collate_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2022-04-03T05:22:37.244138Z",
     "iopub.status.busy": "2022-04-03T05:22:37.243999Z",
     "iopub.status.idle": "2022-04-03T05:22:37.248286Z",
     "shell.execute_reply": "2022-04-03T05:22:37.247997Z",
     "shell.execute_reply.started": "2022-04-03T05:22:37.244125Z"
    },
    "executionInfo": {
     "elapsed": 246,
     "status": "ok",
     "timestamp": 1643996461437,
     "user": {
      "displayName": "Shaannoor Mann",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "02520257695567980696"
     },
     "user_tz": 360
    },
    "id": "-NUpXpJYtAXm",
    "outputId": "51e426c8-a4ff-4898-ba95-27cd06327fab",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1,  1],\n",
      "        [ 4,  4],\n",
      "        [ 5, 18],\n",
      "        [ 6, 19],\n",
      "        [ 7, 20],\n",
      "        [ 8, 21],\n",
      "        [ 9, 22],\n",
      "        [10, 14],\n",
      "        [11, 23],\n",
      "        [12,  2],\n",
      "        [13,  3],\n",
      "        [14,  3],\n",
      "        [15,  3],\n",
      "        [16,  3],\n",
      "        [17,  3],\n",
      "        [ 2,  3]])\n",
      "tensor([[ 1,  1],\n",
      "        [ 4, 15],\n",
      "        [ 5, 16],\n",
      "        [ 6, 17],\n",
      "        [ 7, 18],\n",
      "        [ 8, 19],\n",
      "        [ 9,  9],\n",
      "        [10, 20],\n",
      "        [11, 21],\n",
      "        [12, 22],\n",
      "        [13, 23],\n",
      "        [14, 24],\n",
      "        [ 2, 14],\n",
      "        [ 3,  2]])\n"
     ]
    }
   ],
   "source": [
    "for source, target in train_loader:\n",
    "  print(source)\n",
    "  print(target)\n",
    "  break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-03T05:22:45.595608Z",
     "iopub.status.busy": "2022-04-03T05:22:45.595468Z",
     "iopub.status.idle": "2022-04-03T05:22:45.598670Z",
     "shell.execute_reply": "2022-04-03T05:22:45.598348Z",
     "shell.execute_reply.started": "2022-04-03T05:22:45.595595Z"
    },
    "id": "axyZQ-4z1B-z",
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size = 2\n",
    "\n",
    "train_loader = DataLoader(trainset, batch_size=batch_size, shuffle=True, \n",
    "                              collate_fn=collate_batch)\n",
    "valid_loader = DataLoader(validset, batch_size=batch_size, shuffle=True, \n",
    "                              collate_fn=collate_batch)\n",
    "test_loader = DataLoader(testset, batch_size=batch_size, shuffle=True, \n",
    "                              collate_fn=collate_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color = 'blue'> Breakdown of forward loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color = 'blue'> Get Source and Target sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-03T05:22:49.452327Z",
     "iopub.status.busy": "2022-04-03T05:22:49.452173Z",
     "iopub.status.idle": "2022-04-03T05:22:49.455175Z",
     "shell.execute_reply": "2022-04-03T05:22:49.454839Z",
     "shell.execute_reply.started": "2022-04-03T05:22:49.452314Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "source, target = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-03T05:22:50.218776Z",
     "iopub.status.busy": "2022-04-03T05:22:50.218554Z",
     "iopub.status.idle": "2022-04-03T05:22:50.221835Z",
     "shell.execute_reply": "2022-04-03T05:22:50.221518Z",
     "shell.execute_reply.started": "2022-04-03T05:22:50.218763Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 2])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source.shape\n",
    "# source_len, batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-03T05:23:18.354821Z",
     "iopub.status.busy": "2022-04-03T05:23:18.354679Z",
     "iopub.status.idle": "2022-04-03T05:23:18.357773Z",
     "shell.execute_reply": "2022-04-03T05:23:18.357366Z",
     "shell.execute_reply.started": "2022-04-03T05:23:18.354807Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1,  1],\n",
      "        [ 4,  4],\n",
      "        [18,  5],\n",
      "        [19,  6],\n",
      "        [20,  7],\n",
      "        [21,  8],\n",
      "        [22,  9],\n",
      "        [14, 10],\n",
      "        [23, 11],\n",
      "        [ 2, 12],\n",
      "        [ 3, 13],\n",
      "        [ 3, 14],\n",
      "        [ 3, 15],\n",
      "        [ 3, 16],\n",
      "        [ 3, 17],\n",
      "        [ 3,  2]])\n"
     ]
    }
   ],
   "source": [
    "print(source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-03T05:23:22.545229Z",
     "iopub.status.busy": "2022-04-03T05:23:22.545089Z",
     "iopub.status.idle": "2022-04-03T05:23:22.548108Z",
     "shell.execute_reply": "2022-04-03T05:23:22.547678Z",
     "shell.execute_reply.started": "2022-04-03T05:23:22.545216Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1,  1],\n",
      "        [15,  4],\n",
      "        [16,  5],\n",
      "        [17,  6],\n",
      "        [18,  7],\n",
      "        [19,  8],\n",
      "        [ 9,  9],\n",
      "        [20, 10],\n",
      "        [21, 11],\n",
      "        [22, 12],\n",
      "        [23, 13],\n",
      "        [24, 14],\n",
      "        [14,  2],\n",
      "        [ 2,  3]])\n"
     ]
    }
   ],
   "source": [
    "print(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-03T05:23:29.561883Z",
     "iopub.status.busy": "2022-04-03T05:23:29.561741Z",
     "iopub.status.idle": "2022-04-03T05:23:29.564567Z",
     "shell.execute_reply": "2022-04-03T05:23:29.564308Z",
     "shell.execute_reply.started": "2022-04-03T05:23:29.561869Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "batch_size = target.shape[1]\n",
    "print(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-03T05:23:30.255255Z",
     "iopub.status.busy": "2022-04-03T05:23:30.255098Z",
     "iopub.status.idle": "2022-04-03T05:23:30.257904Z",
     "shell.execute_reply": "2022-04-03T05:23:30.257619Z",
     "shell.execute_reply.started": "2022-04-03T05:23:30.255228Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n"
     ]
    }
   ],
   "source": [
    "trg_len = target.shape[0]\n",
    "print(trg_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-03T05:23:53.742912Z",
     "iopub.status.busy": "2022-04-03T05:23:53.742472Z",
     "iopub.status.idle": "2022-04-03T05:23:53.745664Z",
     "shell.execute_reply": "2022-04-03T05:23:53.745325Z",
     "shell.execute_reply.started": "2022-04-03T05:23:53.742895Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([14, 2, 25])\n"
     ]
    }
   ],
   "source": [
    "# tensors to store decoder output\n",
    "# shape of outputs target length X batch size X vocab size\n",
    "outputs = torch.zeros(trg_len, batch_size, len(target_vocab))\n",
    "print(outputs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color = 'blue'> Encoder Loop\n",
    "<font color = 'green'> So our encoder looks something like this: \n",
    "\n",
    "![](assets/seq2seq2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = 'green'> \n",
    "We will first pass the input through an embedding layer. Initially, the word is represented by a vector of size of vocab (one hot encoding). We do a matrix multiplication of onehot vector with the embedding matrix. The dimension of the matrix will be (vocab_size , emn_dim). So this will convert the word vector from vocab_size to emd_dim size. The embedding matrix is a learnable parameter. We do not create one-hot vectors because multiplying one-hot vector with matrix is equivalent to choosing the row where the value of vector was one. For example Let use assume that vocab size is 6 and emb_dim is 3. One hot vector for fourth word in vocab is is [0,0,0,1,0,0] and we do a matrix multiplication of this vector wih matrix of size(6,3)we will essentially just pick 4th row from the matrix. hat is why the input to out model are indexes of the words. \n",
    "\n",
    "\n",
    "nn.Embedding layer will initilaize the weight matrix randomly. The matrix will be updated during backward pass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-03T05:27:17.887819Z",
     "iopub.status.busy": "2022-04-03T05:27:17.887677Z",
     "iopub.status.idle": "2022-04-03T05:27:17.891116Z",
     "shell.execute_reply": "2022-04-03T05:27:17.890653Z",
     "shell.execute_reply.started": "2022-04-03T05:27:17.887805Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "input_dim = len(source_vocab) # each words is represented by vector of vocab size\n",
    "emb_dim = 5 # we get a vector which will represent the word with a vector of size 5 - usually this in range from 100 to 500.\n",
    "\n",
    "source_embedding = nn.Embedding(input_dim, emb_dim, padding_idx=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color = 'blue'>  Embedding Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-03T05:27:26.137801Z",
     "iopub.status.busy": "2022-04-03T05:27:26.137659Z",
     "iopub.status.idle": "2022-04-03T05:27:26.140919Z",
     "shell.execute_reply": "2022-04-03T05:27:26.140611Z",
     "shell.execute_reply.started": "2022-04-03T05:27:26.137787Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(24, 5, padding_idx=3)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-03T05:27:41.539373Z",
     "iopub.status.busy": "2022-04-03T05:27:41.539210Z",
     "iopub.status.idle": "2022-04-03T05:27:41.544601Z",
     "shell.execute_reply": "2022-04-03T05:27:41.544235Z",
     "shell.execute_reply.started": "2022-04-03T05:27:41.539344Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.3144, -0.4963,  0.1235, -0.1510, -1.3892],\n",
       "        [-0.6208, -0.0242, -1.0402,  1.4635, -0.7477],\n",
       "        [ 1.7456, -1.2779, -1.0257,  1.7473,  0.8090],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.9717, -0.5150,  1.4255,  0.7987, -2.5273],\n",
       "        [ 1.4778, -0.1696, -0.9919, -1.4569,  0.2563],\n",
       "        [-0.4030,  0.4195,  0.7667,  0.0190,  0.0220],\n",
       "        [ 1.1532, -0.3393,  0.1559,  0.8966, -0.2968],\n",
       "        [-0.6857, -0.0496, -1.2485, -0.8509, -0.7690],\n",
       "        [-1.5606, -0.5309,  0.2178, -0.2833, -0.5660],\n",
       "        [ 0.3566, -0.4535, -0.2971, -1.5380, -1.0248],\n",
       "        [-0.3781,  0.3910,  0.5158, -1.0042,  0.9860],\n",
       "        [ 1.1334,  0.8504,  1.0534,  0.3692, -0.0552],\n",
       "        [-0.6125,  0.7500, -0.7346,  0.4622,  1.1759],\n",
       "        [ 0.2145,  0.5362,  0.1365, -2.3332,  1.5308],\n",
       "        [ 0.2680,  0.4505, -0.2725, -1.7399,  0.1299],\n",
       "        [-0.5630, -0.2829,  0.0731, -1.3880, -0.2678],\n",
       "        [-0.1254, -1.5038, -0.3287,  0.4360, -1.4770],\n",
       "        [-1.2222, -0.2746, -0.3450, -0.7162,  0.5781],\n",
       "        [ 0.3805, -1.4538, -2.6740,  1.5984,  0.8021],\n",
       "        [-0.3511, -0.0670, -0.0534, -0.8315, -0.2632],\n",
       "        [-0.5432, -1.6406,  0.9295,  1.2907,  0.2612],\n",
       "        [-0.5862, -1.5105, -2.0155,  0.6964, -0.6676],\n",
       "        [-0.8424,  0.5289, -0.5447,  0.8097,  1.1226]], requires_grad=True)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_embedding.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-03T05:27:59.225569Z",
     "iopub.status.busy": "2022-04-03T05:27:59.225126Z",
     "iopub.status.idle": "2022-04-03T05:27:59.227684Z",
     "shell.execute_reply": "2022-04-03T05:27:59.227217Z",
     "shell.execute_reply.started": "2022-04-03T05:27:59.225552Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "embedding_output = source_embedding(source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-03T05:28:24.549006Z",
     "iopub.status.busy": "2022-04-03T05:28:24.548868Z",
     "iopub.status.idle": "2022-04-03T05:28:24.552845Z",
     "shell.execute_reply": "2022-04-03T05:28:24.552576Z",
     "shell.execute_reply.started": "2022-04-03T05:28:24.548993Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1,  1],\n",
       "        [ 4,  4],\n",
       "        [18,  5],\n",
       "        [19,  6],\n",
       "        [20,  7],\n",
       "        [21,  8],\n",
       "        [22,  9],\n",
       "        [14, 10],\n",
       "        [23, 11],\n",
       "        [ 2, 12],\n",
       "        [ 3, 13],\n",
       "        [ 3, 14],\n",
       "        [ 3, 15],\n",
       "        [ 3, 16],\n",
       "        [ 3, 17],\n",
       "        [ 3,  2]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source\n",
    "# source_len, batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = 'green'> \n",
    "We can see below that embedding_output is simply the corresponding rows from embedding matrix. In a way we can say that a word in a matrxi represent a vector for word which the network will learn. Usually the matrix is initialized randomly but we can use pretrained embeddings like word2vec to initilaize the matrix as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-03T05:29:04.127554Z",
     "iopub.status.busy": "2022-04-03T05:29:04.127383Z",
     "iopub.status.idle": "2022-04-03T05:29:04.132071Z",
     "shell.execute_reply": "2022-04-03T05:29:04.131702Z",
     "shell.execute_reply.started": "2022-04-03T05:29:04.127527Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.6208, -0.0242, -1.0402,  1.4635, -0.7477],\n",
       "         [-0.6208, -0.0242, -1.0402,  1.4635, -0.7477]],\n",
       "\n",
       "        [[ 0.9717, -0.5150,  1.4255,  0.7987, -2.5273],\n",
       "         [ 0.9717, -0.5150,  1.4255,  0.7987, -2.5273]],\n",
       "\n",
       "        [[-1.2222, -0.2746, -0.3450, -0.7162,  0.5781],\n",
       "         [ 1.4778, -0.1696, -0.9919, -1.4569,  0.2563]],\n",
       "\n",
       "        [[ 0.3805, -1.4538, -2.6740,  1.5984,  0.8021],\n",
       "         [-0.4030,  0.4195,  0.7667,  0.0190,  0.0220]],\n",
       "\n",
       "        [[-0.3511, -0.0670, -0.0534, -0.8315, -0.2632],\n",
       "         [ 1.1532, -0.3393,  0.1559,  0.8966, -0.2968]],\n",
       "\n",
       "        [[-0.5432, -1.6406,  0.9295,  1.2907,  0.2612],\n",
       "         [-0.6857, -0.0496, -1.2485, -0.8509, -0.7690]],\n",
       "\n",
       "        [[-0.5862, -1.5105, -2.0155,  0.6964, -0.6676],\n",
       "         [-1.5606, -0.5309,  0.2178, -0.2833, -0.5660]],\n",
       "\n",
       "        [[ 0.2145,  0.5362,  0.1365, -2.3332,  1.5308],\n",
       "         [ 0.3566, -0.4535, -0.2971, -1.5380, -1.0248]],\n",
       "\n",
       "        [[-0.8424,  0.5289, -0.5447,  0.8097,  1.1226],\n",
       "         [-0.3781,  0.3910,  0.5158, -1.0042,  0.9860]],\n",
       "\n",
       "        [[ 1.7456, -1.2779, -1.0257,  1.7473,  0.8090],\n",
       "         [ 1.1334,  0.8504,  1.0534,  0.3692, -0.0552]],\n",
       "\n",
       "        [[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "         [-0.6125,  0.7500, -0.7346,  0.4622,  1.1759]],\n",
       "\n",
       "        [[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.2145,  0.5362,  0.1365, -2.3332,  1.5308]],\n",
       "\n",
       "        [[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.2680,  0.4505, -0.2725, -1.7399,  0.1299]],\n",
       "\n",
       "        [[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "         [-0.5630, -0.2829,  0.0731, -1.3880, -0.2678]],\n",
       "\n",
       "        [[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "         [-0.1254, -1.5038, -0.3287,  0.4360, -1.4770]],\n",
       "\n",
       "        [[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "         [ 1.7456, -1.2779, -1.0257,  1.7473,  0.8090]]],\n",
       "       grad_fn=<EmbeddingBackward0>)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-03T05:29:10.668031Z",
     "iopub.status.busy": "2022-04-03T05:29:10.667875Z",
     "iopub.status.idle": "2022-04-03T05:29:10.671005Z",
     "shell.execute_reply": "2022-04-03T05:29:10.670582Z",
     "shell.execute_reply.started": "2022-04-03T05:29:10.668018Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 2, 5])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_output.shape # sequence_len , batch , embed_dim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-05T04:46:12.178403Z",
     "iopub.status.busy": "2022-02-05T04:46:12.178264Z",
     "iopub.status.idle": "2022-02-05T04:46:12.181186Z",
     "shell.execute_reply": "2022-02-05T04:46:12.180815Z",
     "shell.execute_reply.started": "2022-02-05T04:46:12.178389Z"
    }
   },
   "source": [
    "<font color = 'green'> \n",
    "We will pass the embedding_output through a dropout layer. The dropout layer has no learnable parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color = 'blue'>  Dropout Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-03T05:42:33.961638Z",
     "iopub.status.busy": "2022-04-03T05:42:33.961494Z",
     "iopub.status.idle": "2022-04-03T05:42:33.964168Z",
     "shell.execute_reply": "2022-04-03T05:42:33.963732Z",
     "shell.execute_reply.started": "2022-04-03T05:42:33.961624Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "encoder_dropout = nn.Dropout(p=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-03T05:42:34.373963Z",
     "iopub.status.busy": "2022-04-03T05:42:34.373346Z",
     "iopub.status.idle": "2022-04-03T05:42:34.385553Z",
     "shell.execute_reply": "2022-04-03T05:42:34.384938Z",
     "shell.execute_reply.started": "2022-04-03T05:42:34.373946Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "encoder_dropout_output = encoder_dropout(embedding_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see the dropout layer randomly makes 50% of neurons zero and divided everything else by 0.5 i.e multiplies by 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-03T05:42:35.379488Z",
     "iopub.status.busy": "2022-04-03T05:42:35.379348Z",
     "iopub.status.idle": "2022-04-03T05:42:35.383877Z",
     "shell.execute_reply": "2022-04-03T05:42:35.383552Z",
     "shell.execute_reply.started": "2022-04-03T05:42:35.379475Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.2415, -0.0483, -0.0000,  2.9269, -1.4953],\n",
       "         [-0.0000, -0.0000, -2.0805,  0.0000, -1.4953]],\n",
       "\n",
       "        [[ 0.0000, -0.0000,  2.8511,  1.5974, -0.0000],\n",
       "         [ 1.9434, -1.0300,  2.8511,  0.0000, -0.0000]],\n",
       "\n",
       "        [[-0.0000, -0.5493, -0.6900, -0.0000,  1.1562],\n",
       "         [ 2.9556, -0.3392, -1.9837, -2.9138,  0.5126]],\n",
       "\n",
       "        [[ 0.0000, -0.0000, -5.3480,  3.1967,  1.6043],\n",
       "         [-0.8061,  0.8391,  1.5334,  0.0381,  0.0000]],\n",
       "\n",
       "        [[-0.7023, -0.1340, -0.0000, -1.6631, -0.0000],\n",
       "         [ 2.3064, -0.6787,  0.3118,  0.0000, -0.5936]],\n",
       "\n",
       "        [[-0.0000, -0.0000,  0.0000,  0.0000,  0.5224],\n",
       "         [-0.0000, -0.0993, -0.0000, -1.7017, -0.0000]],\n",
       "\n",
       "        [[-0.0000, -0.0000, -0.0000,  1.3927, -0.0000],\n",
       "         [-0.0000, -0.0000,  0.4355, -0.5667, -0.0000]],\n",
       "\n",
       "        [[ 0.4289,  1.0724,  0.2730, -4.6663,  3.0616],\n",
       "         [ 0.0000, -0.9070, -0.0000, -0.0000, -2.0497]],\n",
       "\n",
       "        [[-1.6849,  0.0000, -0.0000,  0.0000,  0.0000],\n",
       "         [-0.0000,  0.7820,  0.0000, -2.0085,  0.0000]],\n",
       "\n",
       "        [[ 3.4911, -0.0000, -0.0000,  3.4947,  1.6179],\n",
       "         [ 2.2667,  0.0000,  0.0000,  0.0000, -0.0000]],\n",
       "\n",
       "        [[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "         [-0.0000,  1.5000, -1.4692,  0.0000,  2.3519]],\n",
       "\n",
       "        [[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.2730, -0.0000,  3.0616]],\n",
       "\n",
       "        [[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.5360,  0.9010, -0.0000, -0.0000,  0.2599]],\n",
       "\n",
       "        [[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "         [-1.1260, -0.5659,  0.0000, -2.7761, -0.0000]],\n",
       "\n",
       "        [[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "         [-0.0000, -3.0076, -0.0000,  0.8720, -2.9541]],\n",
       "\n",
       "        [[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000, -0.0000, -2.0514,  0.0000,  0.0000]]],\n",
       "       grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_dropout_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oN2xhF4U6J6Q"
   },
   "source": [
    "### <font color = 'blue'> LSTM Layer\n",
    "\n",
    "<img src =\"https://drive.google.com/uc?export=view&id=1R9q3bdONSRy57UjhXyznOSpq-1o5brmD\" width = 500 >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-20T04:30:31.250138Z",
     "start_time": "2021-04-20T04:30:31.247687Z"
    },
    "id": "CnhN76G5T8gf"
   },
   "source": [
    "<font size =4, color = 'green'> nn.LSTM - Parameters\n",
    "<br>\n",
    "<font size =4, color = 'green'>nn.LSTM( input_size, hidden_size, num_layers, non-linearity, bias, dropout, bidirectional, batch_first)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cC37fIldT8gf"
   },
   "source": [
    "<font color = 'green'>\n",
    "    \n",
    "- input_size – The number of expected features in the input  (embedding size)\n",
    "\n",
    "- hidden_size – The number of features in the hidden state h\n",
    "\n",
    "- num_layers – Number of recurrent layers. E.g., setting num_layers=2 would mean stacking two RNNs together to form a stacked RNN, with the second RNN taking in outputs of the first RNN and computing the final results. Default: 1\n",
    "\n",
    "- bias – If False, then the layer does not use bias weights b_ih and b_hh. Default: True\n",
    "\n",
    "- batch_first – If True, then the input and output tensors are provided as (batch, seq, feature). Default: False. Recommended to chnage this to batch_first.\n",
    "\n",
    "- dropout – If non-zero, introduces a Dropout layer on the outputs of each RNN layer except the last layer, with dropout probability equal to dropout. Default: 0\n",
    "\n",
    "- bidirectional – If True, becomes a bidirectional RNN. Default: False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dBwBFAkTT8gg"
   },
   "source": [
    "<font size =4, color = 'green'> LSTM layer needs three inputs -\n",
    "\n",
    "<font color = 'green'> \n",
    "1. input  (if batch_first = True then then the shape should be - Batch size, Sequence Length , input size\n",
    " <br><br> In our case - sequence length will be number of tokens in a sentence and input size will be size of embedding.  <br><br> \n",
    "\n",
    "2. h0 (initial hidden state) - (num_layers * num_directions, batch size, hidden_size)\n",
    "3. c0 (initial hidden state) - (num_layers * num_directions, batch size, hidden_size)\n",
    "<br><br>  By deafult both h0 and c0 are initilaized as tensors of zeros. \n",
    "\n",
    "  batch_first does not apply to h0 and c0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hM1CWw5iT8gg"
   },
   "source": [
    "<font size =4, color = 'green'>Output from LSTM layers (three outputs) \n",
    "    \n",
    "<font color = 'green'> \n",
    "    \n",
    "1. output of shape (seq_len, batch, num_directions * hidden_size): tensor containing the output features (h_t) from the last layer of the RNN, for each t.\n",
    "<br><br> if batch_first = True <br><br> \n",
    "Batch size X Sequence Length X num_directions * Hidden size <br><br> \n",
    "\n",
    "2. (h_n and c_n) of shape (num_layers * num_directions, batch, hidden_size): tensor containing the hidden state for t = seq_len.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z6fJLxznT8gg"
   },
   "source": [
    "<font size =4, color = 'green'> Shape of weight metrices\n",
    "    \n",
    "<font color = 'green'> \n",
    "    \n",
    "- LSTM.weight_ih_l[k] – the learnable input-hidden weights of the k-th layer, of shape ( **4*hidden_size**, input_size) for k = 0. Otherwise, the shape is (**4*hidden_size**, num_directions * hidden_size) <br><br>\n",
    "\n",
    "- LSTM.weight_hh_l[k] – the learnable hidden-hidden weights of the k-th layer, of shape (**4*hidden_size**, hidden_size) <br><br>\n",
    "\n",
    "- LSTM.bias_ih_l[k] – the learnable input-hidden bias of the k-th layer, of shape (**4*hidden_size**) <br><br>\n",
    "\n",
    "- LSTM.bias_hh_l[k] – the learnable hiddn-hidden bias of the k-th layer, of shape (**4*hidden_size**) <br><br>\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-03T05:41:58.043436Z",
     "iopub.status.busy": "2022-04-03T05:41:58.043295Z",
     "iopub.status.idle": "2022-04-03T05:41:58.046416Z",
     "shell.execute_reply": "2022-04-03T05:41:58.046150Z",
     "shell.execute_reply.started": "2022-04-03T05:41:58.043422Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "hid_dim = 3 # size of vector of each word from LSTM layer\n",
    "n_layers = 2\n",
    "encoder_lstm_layer = nn.LSTM(emb_dim, hid_dim, n_layers, dropout = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-03T05:42:00.894254Z",
     "iopub.status.busy": "2022-04-03T05:42:00.893711Z",
     "iopub.status.idle": "2022-04-03T05:42:00.897151Z",
     "shell.execute_reply": "2022-04-03T05:42:00.896830Z",
     "shell.execute_reply.started": "2022-04-03T05:42:00.894237Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTM(5, 3, num_layers=2, dropout=0.3)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_lstm_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-03T05:42:02.694134Z",
     "iopub.status.busy": "2022-04-03T05:42:02.693936Z",
     "iopub.status.idle": "2022-04-03T05:42:02.698201Z",
     "shell.execute_reply": "2022-04-03T05:42:02.697882Z",
     "shell.execute_reply.started": "2022-04-03T05:42:02.694102Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight_ih_l0 torch.Size([12, 5])\n",
      "weight_hh_l0 torch.Size([12, 3])\n",
      "bias_ih_l0 torch.Size([12])\n",
      "bias_hh_l0 torch.Size([12])\n",
      "weight_ih_l1 torch.Size([12, 3])\n",
      "weight_hh_l1 torch.Size([12, 3])\n",
      "bias_ih_l1 torch.Size([12])\n",
      "bias_hh_l1 torch.Size([12])\n"
     ]
    }
   ],
   "source": [
    "for name, param in encoder_lstm_layer.named_parameters():\n",
    "    print(name, param.data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-03T05:42:42.757052Z",
     "iopub.status.busy": "2022-04-03T05:42:42.756869Z",
     "iopub.status.idle": "2022-04-03T05:42:42.759808Z",
     "shell.execute_reply": "2022-04-03T05:42:42.759539Z",
     "shell.execute_reply.started": "2022-04-03T05:42:42.757037Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 2, 5])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_dropout_output.shape \n",
    "# [src len, batch size, emb dim]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-03T05:43:13.506096Z",
     "iopub.status.busy": "2022-04-03T05:43:13.505956Z",
     "iopub.status.idle": "2022-04-03T05:43:13.508748Z",
     "shell.execute_reply": "2022-04-03T05:43:13.508502Z",
     "shell.execute_reply.started": "2022-04-03T05:43:13.506082Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "h0 = torch.zeros(2,2,3) # layers , batch_size, hidden_size\n",
    "c0 = torch.zeros(2,2,3) # layers , batch_size, hidden_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-03T05:44:47.619892Z",
     "iopub.status.busy": "2022-04-03T05:44:47.619752Z",
     "iopub.status.idle": "2022-04-03T05:44:47.634957Z",
     "shell.execute_reply": "2022-04-03T05:44:47.634470Z",
     "shell.execute_reply.started": "2022-04-03T05:44:47.619878Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# encoder_dropout_output = [src len, batch size, emb dim]\n",
    "\n",
    "encoder_outputs, (encoder_hidden, encoder_cell) = encoder_lstm_layer(encoder_dropout_output, (h0, c0))\n",
    "\n",
    "#outputs = [src len, batch size, hid dim ] -->  all sequences from last layer\n",
    "#hidden = [n layers , batch size, hid dim] --> last sequence from all the layers\n",
    "#cell = [n layers , batch size, hid dim] --> last sequence from all the layer\n",
    "\n",
    "#outputs are always from the top hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-03T05:44:48.298506Z",
     "iopub.status.busy": "2022-04-03T05:44:48.298356Z",
     "iopub.status.idle": "2022-04-03T05:44:48.301488Z",
     "shell.execute_reply": "2022-04-03T05:44:48.301227Z",
     "shell.execute_reply.started": "2022-04-03T05:44:48.298492Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([16, 2, 3]), torch.Size([2, 2, 3]), torch.Size([2, 2, 3]))"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_outputs.shape, encoder_hidden.shape, encoder_cell.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7esX6rp0Un3A"
   },
   "source": [
    "## <font color ='blue'> Decoder\n",
    "\n",
    "<font color ='green'>\n",
    "    \n",
    "Next, we'll build our decoder, which will also be a 2-layer (4 in the paper) LSTM.\n",
    "\n",
    "![](assets/seq2seq3.png)\n",
    "\n",
    "The `Decoder` class does a single step of decoding, i.e. it ouputs single token per time-step. The first layer will receive a hidden and cell state from the previous time-step, $(s_{t-1}^1, c_{t-1}^1)$, and feeds it through the LSTM with the current embedded token, $y_t$, to produce a new hidden and cell state, $(s_t^1, c_t^1)$. The subsequent layers will use the hidden state from the layer below, $s_t^{l-1}$, and the previous hidden and cell states from their layer, $(s_{t-1}^l, c_{t-1}^l)$. This provides equations very similar to those in the encoder.\n",
    "\n",
    "$$\\begin{align*}\n",
    "(s_t^1, c_t^1) = \\text{DecoderLSTM}^1(d(y_t), (s_{t-1}^1, c_{t-1}^1))\\\\\n",
    "(s_t^2, c_t^2) = \\text{DecoderLSTM}^2(s_t^1, (s_{t-1}^2, c_{t-1}^2))\n",
    "\\end{align*}$$\n",
    "\n",
    "Remember that the initial hidden and cell states to our decoder are our context vectors, which are the final hidden and cell states of our encoder from the same layer, i.e. $(s_0^l,c_0^l)=z^l=(h_T^l,c_T^l)$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-03T05:50:17.880528Z",
     "iopub.status.busy": "2022-04-03T05:50:17.880386Z",
     "iopub.status.idle": "2022-04-03T05:50:17.883152Z",
     "shell.execute_reply": "2022-04-03T05:50:17.882677Z",
     "shell.execute_reply.started": "2022-04-03T05:50:17.880514Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#first input to the decoder is the <sos> tokens\n",
    "input_de = target[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-03T05:50:55.849101Z",
     "iopub.status.busy": "2022-04-03T05:50:55.848964Z",
     "iopub.status.idle": "2022-04-03T05:50:55.851828Z",
     "shell.execute_reply": "2022-04-03T05:50:55.851544Z",
     "shell.execute_reply.started": "2022-04-03T05:50:55.849088Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_de.shape\n",
    "# batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-03T05:51:05.270016Z",
     "iopub.status.busy": "2022-04-03T05:51:05.269895Z",
     "iopub.status.idle": "2022-04-03T05:51:05.273438Z",
     "shell.execute_reply": "2022-04-03T05:51:05.273180Z",
     "shell.execute_reply.started": "2022-04-03T05:51:05.270003Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_de\n",
    "# batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-03T05:51:50.644936Z",
     "iopub.status.busy": "2022-04-03T05:51:50.644799Z",
     "iopub.status.idle": "2022-04-03T05:51:50.648487Z",
     "shell.execute_reply": "2022-04-03T05:51:50.648172Z",
     "shell.execute_reply.started": "2022-04-03T05:51:50.644923Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1]])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_de = input_de.unsqueeze(0)\n",
    "input_de\n",
    "# 1, batch_sise\n",
    "# 1 here represents the sequence length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-03T05:52:24.202385Z",
     "iopub.status.busy": "2022-04-03T05:52:24.202245Z",
     "iopub.status.idle": "2022-04-03T05:52:24.205517Z",
     "shell.execute_reply": "2022-04-03T05:52:24.205080Z",
     "shell.execute_reply.started": "2022-04-03T05:52:24.202371Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_de.shape # [1, batch size] - since we have  one word at a time seq length is 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-03T05:53:59.108741Z",
     "iopub.status.busy": "2022-04-03T05:53:59.108603Z",
     "iopub.status.idle": "2022-04-03T05:53:59.112618Z",
     "shell.execute_reply": "2022-04-03T05:53:59.112142Z",
     "shell.execute_reply.started": "2022-04-03T05:53:59.108728Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "output_dim = len(target_vocab)\n",
    "emb_dim = 5\n",
    "n_layers = 2\n",
    "hid_dim=3\n",
    "\n",
    "decoder_embedding = nn.Embedding(output_dim, emb_dim)\n",
    "decoder_dropout = nn.Dropout(p=0.5)\n",
    "decoder_lstm = nn.LSTM(emb_dim, hid_dim, n_layers, dropout = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-03T05:53:59.773521Z",
     "iopub.status.busy": "2022-04-03T05:53:59.773376Z",
     "iopub.status.idle": "2022-04-03T05:53:59.776448Z",
     "shell.execute_reply": "2022-04-03T05:53:59.775981Z",
     "shell.execute_reply.started": "2022-04-03T05:53:59.773485Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dec_output1, (dec_hidden1, dec_cell1)= decoder_lstm(\n",
    "                          decoder_dropout(decoder_embedding(input_de)),\n",
    "                          (encoder_hidden, encoder_cell))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-03T05:56:21.854994Z",
     "iopub.status.busy": "2022-04-03T05:56:21.854855Z",
     "iopub.status.idle": "2022-04-03T05:56:21.858059Z",
     "shell.execute_reply": "2022-04-03T05:56:21.857800Z",
     "shell.execute_reply.started": "2022-04-03T05:56:21.854980Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2, 3])\n",
      "torch.Size([2, 2, 3])\n",
      "torch.Size([2, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "print(dec_output1.shape) # seq_len, batch_size, hidden_dim\n",
    "print(dec_hidden1.shape) # num_layers, batch_size, hidden_dim\n",
    "print(dec_cell1.shape)  # num_layers, batch_size, hidden_dim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color ='green'>\n",
    "For deocder we are passing one word at a time. We are intrested in the output from the last layer. We can use the dec_output for this OR we can extract last  element of hidden cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-03T05:57:34.202744Z",
     "iopub.status.busy": "2022-04-03T05:57:34.202548Z",
     "iopub.status.idle": "2022-04-03T05:57:34.206218Z",
     "shell.execute_reply": "2022-04-03T05:57:34.205925Z",
     "shell.execute_reply.started": "2022-04-03T05:57:34.202731Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.1206,  0.2369, -0.1888],\n",
       "         [ 0.1018,  0.2435, -0.1666]]], grad_fn=<StackBackward0>)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dec_output1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-03T05:57:35.208024Z",
     "iopub.status.busy": "2022-04-03T05:57:35.207888Z",
     "iopub.status.idle": "2022-04-03T05:57:35.211741Z",
     "shell.execute_reply": "2022-04-03T05:57:35.211406Z",
     "shell.execute_reply.started": "2022-04-03T05:57:35.208011Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1206,  0.2369, -0.1888],\n",
       "        [ 0.1018,  0.2435, -0.1666]], grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dec_hidden1[-1,:,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color ='green'>\n",
    "Since we need to estimate probbaility we will need to change the dimension of the token back to length of the vocab size. We can then use the softmax to get probbailities. This will give us the predicted probabilities. The prediction will be the word corresponding to maximum probbaility. Since we know the actual word we can then calculate the loss. The actual values wil be one hot encoding and predictd values will be probbailities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color ='green'>\n",
    "We will use the nn.linear layer to change the output from shape (2,3) to shape (2,len(target_vocab)). The nn.Linear layer will initilaize a weight matrix of the shape (vocab_size, hid_dim). It then does the follwoing transformation : $y = xW^T + b$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-03T05:59:04.523744Z",
     "iopub.status.busy": "2022-04-03T05:59:04.523393Z",
     "iopub.status.idle": "2022-04-03T05:59:04.526106Z",
     "shell.execute_reply": "2022-04-03T05:59:04.525801Z",
     "shell.execute_reply.started": "2022-04-03T05:59:04.523728Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "decoder_linear = nn.Linear(in_features=3, out_features=len(target_vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-03T05:59:05.123176Z",
     "iopub.status.busy": "2022-04-03T05:59:05.122772Z",
     "iopub.status.idle": "2022-04-03T05:59:05.125819Z",
     "shell.execute_reply": "2022-04-03T05:59:05.125519Z",
     "shell.execute_reply.started": "2022-04-03T05:59:05.123159Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight torch.Size([25, 3])\n",
      "bias torch.Size([25])\n"
     ]
    }
   ],
   "source": [
    "for name, param in decoder_linear.named_parameters():\n",
    "    print(name, param.data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-03T05:59:10.264914Z",
     "iopub.status.busy": "2022-04-03T05:59:10.264759Z",
     "iopub.status.idle": "2022-04-03T05:59:10.267720Z",
     "shell.execute_reply": "2022-04-03T05:59:10.267441Z",
     "shell.execute_reply.started": "2022-04-03T05:59:10.264900Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2, 3])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dec_output1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear layer will need two dimenional input. We will squeeze out the redundant dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-03T05:59:18.132670Z",
     "iopub.status.busy": "2022-04-03T05:59:18.132515Z",
     "iopub.status.idle": "2022-04-03T05:59:18.135025Z",
     "shell.execute_reply": "2022-04-03T05:59:18.134663Z",
     "shell.execute_reply.started": "2022-04-03T05:59:18.132657Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dec_output1 = dec_output1.squeeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-03T05:59:18.835194Z",
     "iopub.status.busy": "2022-04-03T05:59:18.834992Z",
     "iopub.status.idle": "2022-04-03T05:59:18.838152Z",
     "shell.execute_reply": "2022-04-03T05:59:18.837810Z",
     "shell.execute_reply.started": "2022-04-03T05:59:18.835165Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dec_output1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color ='green'>\n",
    "So the shape is (2,3). We will multiply it with a matrix of (3, 25) (we are taking the transpose of the weight matrix to get out put of 2, 25 ---> so word in each batch is converted into vector of vocab size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-03T05:59:40.065487Z",
     "iopub.status.busy": "2022-04-03T05:59:40.064959Z",
     "iopub.status.idle": "2022-04-03T05:59:40.067417Z",
     "shell.execute_reply": "2022-04-03T05:59:40.067104Z",
     "shell.execute_reply.started": "2022-04-03T05:59:40.065471Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "prediction1 = decoder_linear(dec_output1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-03T05:59:40.663436Z",
     "iopub.status.busy": "2022-04-03T05:59:40.663311Z",
     "iopub.status.idle": "2022-04-03T05:59:40.667053Z",
     "shell.execute_reply": "2022-04-03T05:59:40.666703Z",
     "shell.execute_reply.started": "2022-04-03T05:59:40.663422Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.3964, -0.1926,  0.3159,  0.4407, -0.6102,  0.0711, -0.2346, -0.1060,\n",
       "          0.4961, -0.1705, -0.3661,  0.1079,  0.0828, -0.2413, -0.1515, -0.5287,\n",
       "          0.5211, -0.4508,  0.3556, -0.4582, -0.2168, -0.2761,  0.6901, -0.1194,\n",
       "         -0.2217],\n",
       "        [ 0.4069, -0.2067,  0.3201,  0.4436, -0.6200,  0.0686, -0.2229, -0.1199,\n",
       "          0.4930, -0.1723, -0.3642,  0.0936,  0.0753, -0.2529, -0.1455, -0.5467,\n",
       "          0.5041, -0.4407,  0.3378, -0.4463, -0.2275, -0.2581,  0.6775, -0.1331,\n",
       "         -0.2200]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-03T05:59:52.573629Z",
     "iopub.status.busy": "2022-04-03T05:59:52.573491Z",
     "iopub.status.idle": "2022-04-03T05:59:52.576560Z",
     "shell.execute_reply": "2022-04-03T05:59:52.576232Z",
     "shell.execute_reply.started": "2022-04-03T05:59:52.573616Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 25])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color ='green'> Update the output based on prediction. Once we update output for all the words, we can use that to calculate batch loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-03T06:13:07.823930Z",
     "iopub.status.busy": "2022-04-03T06:13:07.823660Z",
     "iopub.status.idle": "2022-04-03T06:13:07.826206Z",
     "shell.execute_reply": "2022-04-03T06:13:07.825894Z",
     "shell.execute_reply.started": "2022-04-03T06:13:07.823900Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "outputs[1] = prediction1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-03T06:13:13.181224Z",
     "iopub.status.busy": "2022-04-03T06:13:13.181012Z",
     "iopub.status.idle": "2022-04-03T06:13:13.184478Z",
     "shell.execute_reply": "2022-04-03T06:13:13.184153Z",
     "shell.execute_reply.started": "2022-04-03T06:13:13.181193Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([14, 2, 25])"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.shape\n",
    "# seq_len, batch_size, vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-03T06:14:11.874944Z",
     "iopub.status.busy": "2022-04-03T06:14:11.874796Z",
     "iopub.status.idle": "2022-04-03T06:14:11.878785Z",
     "shell.execute_reply": "2022-04-03T06:14:11.878450Z",
     "shell.execute_reply.started": "2022-04-03T06:14:11.874930Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        [[ 0.3964, -0.1926,  0.3159,  0.4407, -0.6102,  0.0711, -0.2346,\n",
       "          -0.1060,  0.4961, -0.1705, -0.3661,  0.1079,  0.0828, -0.2413,\n",
       "          -0.1515, -0.5287,  0.5211, -0.4508,  0.3556, -0.4582, -0.2168,\n",
       "          -0.2761,  0.6901, -0.1194, -0.2217],\n",
       "         [ 0.4069, -0.2067,  0.3201,  0.4436, -0.6200,  0.0686, -0.2229,\n",
       "          -0.1199,  0.4930, -0.1723, -0.3642,  0.0936,  0.0753, -0.2529,\n",
       "          -0.1455, -0.5467,  0.5041, -0.4407,  0.3378, -0.4463, -0.2275,\n",
       "          -0.2581,  0.6775, -0.1331, -0.2200]],\n",
       "\n",
       "        [[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000]]], grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs[0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color ='green'>\n",
    "    \n",
    "So the predicted word is the word corresponding to index of max value. As we can see below , in our example the word corresponding to index 22 is the predicted word for both the sentences in the batch. The actual word correspond to index 15 and 4 for two sentences. We can use the predicted words as an input for next sequence or we can use the actual word as input to the next sequence. We will then repeat the whole process of the decoder section.\n",
    "Then we will get the second predicted word. We will continue till we reach the last word in the sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-03T06:24:04.067031Z",
     "iopub.status.busy": "2022-04-03T06:24:04.066890Z",
     "iopub.status.idle": "2022-04-03T06:24:04.070471Z",
     "shell.execute_reply": "2022-04-03T06:24:04.070218Z",
     "shell.execute_reply.started": "2022-04-03T06:24:04.067017Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([22, 22])"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top1 = prediction1.argmax(1) \n",
    "top1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-03T06:24:04.778984Z",
     "iopub.status.busy": "2022-04-03T06:24:04.778843Z",
     "iopub.status.idle": "2022-04-03T06:24:04.782314Z",
     "shell.execute_reply": "2022-04-03T06:24:04.782047Z",
     "shell.execute_reply.started": "2022-04-03T06:24:04.778971Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([15,  4])"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual1 = target[1]\n",
    "actual1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-03T06:24:05.738088Z",
     "iopub.status.busy": "2022-04-03T06:24:05.737965Z",
     "iopub.status.idle": "2022-04-03T06:24:05.740521Z",
     "shell.execute_reply": "2022-04-03T06:24:05.740238Z",
     "shell.execute_reply.started": "2022-04-03T06:24:05.738075Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "teacher_forcing_ratio = 0.5\n",
    "teacher_forcing = random.random() < teacher_forcing_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-03T06:24:06.339445Z",
     "iopub.status.busy": "2022-04-03T06:24:06.339302Z",
     "iopub.status.idle": "2022-04-03T06:24:06.342447Z",
     "shell.execute_reply": "2022-04-03T06:24:06.342173Z",
     "shell.execute_reply.started": "2022-04-03T06:24:06.339431Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teacher_forcing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color ='green'>\n",
    "During training - we will randomly sometimes used the actual word (teacher forcing) and sometimes use the predicted word as input to next sequence. If we use teacher_forcing_ratio =1 then we will always use the actual word as input to next sequence. During inference we will set teacher_forcing_ratio = 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-06T18:12:44.177087Z",
     "iopub.status.busy": "2022-02-06T18:12:44.176931Z",
     "iopub.status.idle": "2022-02-06T18:12:44.180192Z",
     "shell.execute_reply": "2022-02-06T18:12:44.179704Z",
     "shell.execute_reply.started": "2022-02-06T18:12:44.177060Z"
    }
   },
   "source": [
    "<font color ='green'>\n",
    "Final note - We will ignore the loss corresponding to PAD tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-03T06:24:22.943539Z",
     "iopub.status.busy": "2022-04-03T06:24:22.943400Z",
     "iopub.status.idle": "2022-04-03T06:24:22.945993Z",
     "shell.execute_reply": "2022-04-03T06:24:22.945608Z",
     "shell.execute_reply.started": "2022-04-03T06:24:22.943525Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if teacher_forcing:\n",
    "    input_de = actual1\n",
    "else:\n",
    "    input_de = top1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-03T06:24:24.295564Z",
     "iopub.status.busy": "2022-04-03T06:24:24.295409Z",
     "iopub.status.idle": "2022-04-03T06:24:24.299127Z",
     "shell.execute_reply": "2022-04-03T06:24:24.298605Z",
     "shell.execute_reply.started": "2022-04-03T06:24:24.295550Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([22, 22])"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_de"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "1 - small example forward only.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "pt10",
   "language": "python",
   "name": "pt10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
