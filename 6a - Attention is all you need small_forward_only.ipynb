{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color = 'blue'> Attention is All You Need - Small example forward loop only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = 4, color ='green'>\n",
    "    \n",
    "The differences between the implementation in this notebook and the paper are:\n",
    "- Learned positional encoding instead of a static one\n",
    "- Standard Adam optimizer with a static learning rate instead of one with warm-up and cool-down steps\n",
    "- Label Smoothing\n",
    "- Weight sharing between embedding layer and final Linear layer before softmax\n",
    "- BPE for tokenization\n",
    "- Effcient Batching (make sure we have to do minimum padding)\n",
    "- Multiple GPU training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-27T08:35:50.289004Z",
     "iopub.status.busy": "2022-02-27T08:35:50.288736Z",
     "iopub.status.idle": "2022-02-27T08:35:50.291235Z",
     "shell.execute_reply": "2022-02-27T08:35:50.290917Z",
     "shell.execute_reply.started": "2022-02-27T08:35:50.288989Z"
    }
   },
   "source": [
    "# <font color = 'blue'> Import Libraries\n",
    "As always, let's import all the required modules and set the random seeds for reproducability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T16:50:51.756321Z",
     "iopub.status.busy": "2022-04-02T16:50:51.756073Z",
     "iopub.status.idle": "2022-04-02T16:50:53.729376Z",
     "shell.execute_reply": "2022-04-02T16:50:53.728794Z",
     "shell.execute_reply.started": "2022-04-02T16:50:51.756256Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "import torchtext \n",
    "from torchtext.datasets import Multi30k\n",
    "from torchtext.vocab import vocab\n",
    "#from torchtext.legacy.data import Field, BucketIterator\n",
    "\n",
    "import spacy\n",
    "import numpy as np\n",
    "from collections import Counter, OrderedDict\n",
    "\n",
    "import random\n",
    "import math\n",
    "import time\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T16:50:53.730271Z",
     "iopub.status.busy": "2022-04-02T16:50:53.730175Z",
     "iopub.status.idle": "2022-04-02T16:50:53.733701Z",
     "shell.execute_reply": "2022-04-02T16:50:53.733326Z",
     "shell.execute_reply.started": "2022-04-02T16:50:53.730259Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "SEED = 1234\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T16:50:53.734253Z",
     "iopub.status.busy": "2022-04-02T16:50:53.734159Z",
     "iopub.status.idle": "2022-04-02T16:50:53.742259Z",
     "shell.execute_reply": "2022-04-02T16:50:53.741842Z",
     "shell.execute_reply.started": "2022-04-02T16:50:53.734240Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('0.11.0', '1.10.0', True, '3.2.4')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torchtext.__version__, torch.__version__, torch.cuda.is_available(), spacy.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color = 'blue'>  Preparing the Data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T16:50:55.233775Z",
     "iopub.status.busy": "2022-04-02T16:50:55.233631Z",
     "iopub.status.idle": "2022-04-02T16:50:55.236197Z",
     "shell.execute_reply": "2022-04-02T16:50:55.235887Z",
     "shell.execute_reply.started": "2022-04-02T16:50:55.233761Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_folder = Path('/home/harpreet/Insync/google_drive_shaannoor/Data/NLP')\n",
    "project_folder = Path('/home/harpreet/Insync/google_drive_harpreet/Research/NLP/pytorch-seq2seq')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T16:50:55.764847Z",
     "iopub.status.busy": "2022-04-02T16:50:55.764629Z",
     "iopub.status.idle": "2022-04-02T16:50:55.768031Z",
     "shell.execute_reply": "2022-04-02T16:50:55.767645Z",
     "shell.execute_reply.started": "2022-04-02T16:50:55.764833Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('0.11.0', '1.10.0', True, '3.2.4')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torchtext.__version__, torch.__version__, torch.cuda.is_available(), spacy.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll then create our tokenizers as before."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color = 'blue'> Load tokenized data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T16:51:00.907715Z",
     "iopub.status.busy": "2022-04-02T16:51:00.907565Z",
     "iopub.status.idle": "2022-04-02T16:51:01.038666Z",
     "shell.execute_reply": "2022-04-02T16:51:01.038270Z",
     "shell.execute_reply.started": "2022-04-02T16:51:00.907701Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_pickle(project_folder/'df_train_en_de.pickel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T16:51:01.200757Z",
     "iopub.status.busy": "2022-04-02T16:51:01.200632Z",
     "iopub.status.idle": "2022-04-02T16:51:01.215140Z",
     "shell.execute_reply": "2022-04-02T16:51:01.214865Z",
     "shell.execute_reply.started": "2022-04-02T16:51:01.200743Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_tokens</th>\n",
       "      <th>target_tokens</th>\n",
       "      <th>source_tokens_reverse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[zwei, junge, weiße, männer, sind, i, m, freie...</td>\n",
       "      <td>[two, young, ,, white, males, are, outside, ne...</td>\n",
       "      <td>[., büsche, vieler, nähe, der, in, freien, m, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[mehrere, männer, mit, schutzhelmen, bedienen,...</td>\n",
       "      <td>[several, men, in, hard, hats, are, operating,...</td>\n",
       "      <td>[., antriebsradsystem, ein, bedienen, schutzhe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[ein, kleines, mädchen, klettert, in, ein, spi...</td>\n",
       "      <td>[a, little, girl, climbing, into, a, wooden, p...</td>\n",
       "      <td>[., holz, aus, spielhaus, ein, in, klettert, m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[ein, mann, in, einem, blauen, hemd, steht, au...</td>\n",
       "      <td>[a, man, in, a, blue, shirt, is, standing, on,...</td>\n",
       "      <td>[., fenster, ein, putzt, und, leiter, einer, a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[zwei, männer, stehen, am, herd, und, bereiten...</td>\n",
       "      <td>[two, men, are, at, the, stove, preparing, foo...</td>\n",
       "      <td>[., zu, essen, bereiten, und, herd, am, stehen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28995</th>\n",
       "      <td>[., wand, verschnörkelten, einer, hinter, schr...</td>\n",
       "      <td>[a, woman, behind, a, scrolled, wall, is, writ...</td>\n",
       "      <td>[eine, frau, schreibt, hinter, einer, verschnö...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28996</th>\n",
       "      <td>[., kletterwand, einer, an, übt, bergsteiger, ...</td>\n",
       "      <td>[a, rock, climber, practices, on, a, rock, cli...</td>\n",
       "      <td>[ein, bergsteiger, übt, an, einer, kletterwand...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28997</th>\n",
       "      <td>[., hauses, einem, vor, straße, einer, auf, ar...</td>\n",
       "      <td>[two, male, construction, workers, are, workin...</td>\n",
       "      <td>[zwei, bauarbeiter, arbeiten, auf, einer, stra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28998</th>\n",
       "      <td>[., fassade, einer, vor, wagen, einem, mit, ju...</td>\n",
       "      <td>[an, elderly, man, sits, outside, a, storefron...</td>\n",
       "      <td>[ein, älterer, mann, sitzt, mit, einem, jungen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28999</th>\n",
       "      <td>[., hintergrund, m, i, bergen, und, nebel, mit...</td>\n",
       "      <td>[a, man, in, shorts, and, a, hawaiian, shirt, ...</td>\n",
       "      <td>[ein, mann, in, shorts, und, hawaiihemd, lehnt...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>29000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           source_tokens  \\\n",
       "0      [zwei, junge, weiße, männer, sind, i, m, freie...   \n",
       "1      [mehrere, männer, mit, schutzhelmen, bedienen,...   \n",
       "2      [ein, kleines, mädchen, klettert, in, ein, spi...   \n",
       "3      [ein, mann, in, einem, blauen, hemd, steht, au...   \n",
       "4      [zwei, männer, stehen, am, herd, und, bereiten...   \n",
       "...                                                  ...   \n",
       "28995  [., wand, verschnörkelten, einer, hinter, schr...   \n",
       "28996  [., kletterwand, einer, an, übt, bergsteiger, ...   \n",
       "28997  [., hauses, einem, vor, straße, einer, auf, ar...   \n",
       "28998  [., fassade, einer, vor, wagen, einem, mit, ju...   \n",
       "28999  [., hintergrund, m, i, bergen, und, nebel, mit...   \n",
       "\n",
       "                                           target_tokens  \\\n",
       "0      [two, young, ,, white, males, are, outside, ne...   \n",
       "1      [several, men, in, hard, hats, are, operating,...   \n",
       "2      [a, little, girl, climbing, into, a, wooden, p...   \n",
       "3      [a, man, in, a, blue, shirt, is, standing, on,...   \n",
       "4      [two, men, are, at, the, stove, preparing, foo...   \n",
       "...                                                  ...   \n",
       "28995  [a, woman, behind, a, scrolled, wall, is, writ...   \n",
       "28996  [a, rock, climber, practices, on, a, rock, cli...   \n",
       "28997  [two, male, construction, workers, are, workin...   \n",
       "28998  [an, elderly, man, sits, outside, a, storefron...   \n",
       "28999  [a, man, in, shorts, and, a, hawaiian, shirt, ...   \n",
       "\n",
       "                                   source_tokens_reverse  \n",
       "0      [., büsche, vieler, nähe, der, in, freien, m, ...  \n",
       "1      [., antriebsradsystem, ein, bedienen, schutzhe...  \n",
       "2      [., holz, aus, spielhaus, ein, in, klettert, m...  \n",
       "3      [., fenster, ein, putzt, und, leiter, einer, a...  \n",
       "4      [., zu, essen, bereiten, und, herd, am, stehen...  \n",
       "...                                                  ...  \n",
       "28995  [eine, frau, schreibt, hinter, einer, verschnö...  \n",
       "28996  [ein, bergsteiger, übt, an, einer, kletterwand...  \n",
       "28997  [zwei, bauarbeiter, arbeiten, auf, einer, stra...  \n",
       "28998  [ein, älterer, mann, sitzt, mit, einem, jungen...  \n",
       "28999  [ein, mann, in, shorts, und, hawaiihemd, lehnt...  \n",
       "\n",
       "[29000 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color = 'blue'> Small subset of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T16:51:02.058726Z",
     "iopub.status.busy": "2022-04-02T16:51:02.058526Z",
     "iopub.status.idle": "2022-04-02T16:51:02.061141Z",
     "shell.execute_reply": "2022-04-02T16:51:02.060863Z",
     "shell.execute_reply.started": "2022-04-02T16:51:02.058712Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_train_small= df_train[0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T16:51:02.347204Z",
     "iopub.status.busy": "2022-04-02T16:51:02.347055Z",
     "iopub.status.idle": "2022-04-02T16:51:02.354582Z",
     "shell.execute_reply": "2022-04-02T16:51:02.354203Z",
     "shell.execute_reply.started": "2022-04-02T16:51:02.347191Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_tokens</th>\n",
       "      <th>target_tokens</th>\n",
       "      <th>source_tokens_reverse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[zwei, junge, weiße, männer, sind, i, m, freie...</td>\n",
       "      <td>[two, young, ,, white, males, are, outside, ne...</td>\n",
       "      <td>[., büsche, vieler, nähe, der, in, freien, m, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[mehrere, männer, mit, schutzhelmen, bedienen,...</td>\n",
       "      <td>[several, men, in, hard, hats, are, operating,...</td>\n",
       "      <td>[., antriebsradsystem, ein, bedienen, schutzhe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[ein, kleines, mädchen, klettert, in, ein, spi...</td>\n",
       "      <td>[a, little, girl, climbing, into, a, wooden, p...</td>\n",
       "      <td>[., holz, aus, spielhaus, ein, in, klettert, m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[ein, mann, in, einem, blauen, hemd, steht, au...</td>\n",
       "      <td>[a, man, in, a, blue, shirt, is, standing, on,...</td>\n",
       "      <td>[., fenster, ein, putzt, und, leiter, einer, a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       source_tokens  \\\n",
       "0  [zwei, junge, weiße, männer, sind, i, m, freie...   \n",
       "1  [mehrere, männer, mit, schutzhelmen, bedienen,...   \n",
       "2  [ein, kleines, mädchen, klettert, in, ein, spi...   \n",
       "3  [ein, mann, in, einem, blauen, hemd, steht, au...   \n",
       "\n",
       "                                       target_tokens  \\\n",
       "0  [two, young, ,, white, males, are, outside, ne...   \n",
       "1  [several, men, in, hard, hats, are, operating,...   \n",
       "2  [a, little, girl, climbing, into, a, wooden, p...   \n",
       "3  [a, man, in, a, blue, shirt, is, standing, on,...   \n",
       "\n",
       "                               source_tokens_reverse  \n",
       "0  [., büsche, vieler, nähe, der, in, freien, m, ...  \n",
       "1  [., antriebsradsystem, ein, bedienen, schutzhe...  \n",
       "2  [., holz, aus, spielhaus, ein, in, klettert, m...  \n",
       "3  [., fenster, ein, putzt, und, leiter, einer, a...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T16:51:02.572982Z",
     "iopub.status.busy": "2022-04-02T16:51:02.572800Z",
     "iopub.status.idle": "2022-04-02T16:51:02.577913Z",
     "shell.execute_reply": "2022-04-02T16:51:02.577619Z",
     "shell.execute_reply.started": "2022-04-02T16:51:02.572968Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_train_small= df_train_small.drop(columns=['source_tokens_reverse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T16:51:06.100747Z",
     "iopub.status.busy": "2022-04-02T16:51:06.100565Z",
     "iopub.status.idle": "2022-04-02T16:51:06.106707Z",
     "shell.execute_reply": "2022-04-02T16:51:06.106359Z",
     "shell.execute_reply.started": "2022-04-02T16:51:06.100733Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_tokens</th>\n",
       "      <th>target_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[zwei, junge, weiße, männer, sind, i, m, freie...</td>\n",
       "      <td>[two, young, ,, white, males, are, outside, ne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[mehrere, männer, mit, schutzhelmen, bedienen,...</td>\n",
       "      <td>[several, men, in, hard, hats, are, operating,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[ein, kleines, mädchen, klettert, in, ein, spi...</td>\n",
       "      <td>[a, little, girl, climbing, into, a, wooden, p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[ein, mann, in, einem, blauen, hemd, steht, au...</td>\n",
       "      <td>[a, man, in, a, blue, shirt, is, standing, on,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       source_tokens  \\\n",
       "0  [zwei, junge, weiße, männer, sind, i, m, freie...   \n",
       "1  [mehrere, männer, mit, schutzhelmen, bedienen,...   \n",
       "2  [ein, kleines, mädchen, klettert, in, ein, spi...   \n",
       "3  [ein, mann, in, einem, blauen, hemd, steht, au...   \n",
       "\n",
       "                                       target_tokens  \n",
       "0  [two, young, ,, white, males, are, outside, ne...  \n",
       "1  [several, men, in, hard, hats, are, operating,...  \n",
       "2  [a, little, girl, climbing, into, a, wooden, p...  \n",
       "3  [a, man, in, a, blue, shirt, is, standing, on,...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_small"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "If-BMrTctAXj"
   },
   "source": [
    "## <font color = 'blue'> Build Vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T16:51:06.486272Z",
     "iopub.status.busy": "2022-04-02T16:51:06.486101Z",
     "iopub.status.idle": "2022-04-02T16:51:06.489301Z",
     "shell.execute_reply": "2022-04-02T16:51:06.488925Z",
     "shell.execute_reply.started": "2022-04-02T16:51:06.486258Z"
    },
    "executionInfo": {
     "elapsed": 309,
     "status": "ok",
     "timestamp": 1644562027083,
     "user": {
      "displayName": "Shaannoor Mann",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "02520257695567980696"
     },
     "user_tz": 360
    },
    "id": "GY9kL2JxtAXj",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_vocab(text, min_freq, specials):\n",
    "    my_counter = Counter()\n",
    "    for line in text:\n",
    "       my_counter.update(line)\n",
    "    my_vocab = vocab(my_counter, min_freq=min_freq)\n",
    "    for i, special in enumerate(specials):\n",
    "        my_vocab.insert_token(special, i)\n",
    "    my_vocab.set_default_index(0)\n",
    "    return my_vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create source vocab, We will add four special tokens - ```['<unk>', '<BOS>', '<EOS>', '<PAD>']```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-06T18:47:09.646766Z",
     "iopub.status.busy": "2022-03-06T18:47:09.646608Z",
     "iopub.status.idle": "2022-03-06T18:47:09.649209Z",
     "shell.execute_reply": "2022-03-06T18:47:09.648843Z",
     "shell.execute_reply.started": "2022-03-06T18:47:09.646752Z"
    }
   },
   "source": [
    "### <font color = 'blue'> Source Vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T16:51:08.372209Z",
     "iopub.status.busy": "2022-04-02T16:51:08.372033Z",
     "iopub.status.idle": "2022-04-02T16:51:08.402753Z",
     "shell.execute_reply": "2022-04-02T16:51:08.402250Z",
     "shell.execute_reply.started": "2022-04-02T16:51:08.372194Z"
    },
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1644562028109,
     "user": {
      "displayName": "Shaannoor Mann",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "02520257695567980696"
     },
     "user_tz": 360
    },
    "id": "dcvIJAIHtAXj",
    "tags": []
   },
   "outputs": [],
   "source": [
    "source_vocab = create_vocab(df_train_small['source_tokens'], 1, ['<unk>', '<BOS>', '<EOS>', '<PAD>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2022-04-02T16:51:08.603481Z",
     "iopub.status.busy": "2022-04-02T16:51:08.603297Z",
     "iopub.status.idle": "2022-04-02T16:51:08.606265Z",
     "shell.execute_reply": "2022-04-02T16:51:08.606005Z",
     "shell.execute_reply.started": "2022-04-02T16:51:08.603467Z"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1644562029061,
     "user": {
      "displayName": "Shaannoor Mann",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "02520257695567980696"
     },
     "user_tz": 360
    },
    "id": "qtEt9Sh-tAXk",
    "outputId": "1764add1-bf7a-4c9f-f38c-efff19b32b07",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(source_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "execution": {
     "iopub.execute_input": "2022-04-02T16:51:15.139183Z",
     "iopub.status.busy": "2022-04-02T16:51:15.138999Z",
     "iopub.status.idle": "2022-04-02T16:51:15.145802Z",
     "shell.execute_reply": "2022-04-02T16:51:15.145414Z",
     "shell.execute_reply.started": "2022-04-02T16:51:15.139169Z"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1644562030020,
     "user": {
      "displayName": "Shaannoor Mann",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "02520257695567980696"
     },
     "user_tz": 360
    },
    "id": "bf9fu5L2tAXk",
    "outputId": "35252b98-1fff-4186-8274-aadae1b1b0b4",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "      <th>index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>&lt;unk&gt;</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>&lt;BOS&gt;</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>&lt;EOS&gt;</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>&lt;PAD&gt;</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>zwei</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>junge</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>weiße</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>männer</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>sind</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>i</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    tokens  index\n",
       "28   <unk>      0\n",
       "34   <BOS>      1\n",
       "23   <EOS>      2\n",
       "19   <PAD>      3\n",
       "17    zwei      4\n",
       "27   junge      5\n",
       "14   weiße      6\n",
       "12  männer      7\n",
       "16    sind      8\n",
       "7        i      9"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(source_vocab.get_stoi().items(), columns=['tokens', 'index']).sort_values(by = ['index'])[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2022-04-02T16:51:15.337508Z",
     "iopub.status.busy": "2022-04-02T16:51:15.337368Z",
     "iopub.status.idle": "2022-04-02T16:51:15.340408Z",
     "shell.execute_reply": "2022-04-02T16:51:15.340142Z",
     "shell.execute_reply.started": "2022-04-02T16:51:15.337494Z"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1644562031101,
     "user": {
      "displayName": "Shaannoor Mann",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "02520257695567980696"
     },
     "user_tz": 360
    },
    "id": "8pKCTbN6tAXk",
    "outputId": "fd7c0bbb-562a-4313-fcb7-16a486abe4fd",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check index of unknown word - it should be zero\n",
    "source_vocab['abracdabra']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color = 'blue'> Target Vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T16:51:15.946186Z",
     "iopub.status.busy": "2022-04-02T16:51:15.946044Z",
     "iopub.status.idle": "2022-04-02T16:51:15.976956Z",
     "shell.execute_reply": "2022-04-02T16:51:15.976628Z",
     "shell.execute_reply.started": "2022-04-02T16:51:15.946173Z"
    },
    "executionInfo": {
     "elapsed": 637,
     "status": "ok",
     "timestamp": 1644562032737,
     "user": {
      "displayName": "Shaannoor Mann",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "02520257695567980696"
     },
     "user_tz": 360
    },
    "id": "qkXg6IratAXk",
    "tags": []
   },
   "outputs": [],
   "source": [
    "target_vocab = create_vocab(df_train_small['target_tokens'], 1, ['<unk>', '<BOS>', '<EOS>', '<PAD>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2022-04-02T16:51:16.114712Z",
     "iopub.status.busy": "2022-04-02T16:51:16.114529Z",
     "iopub.status.idle": "2022-04-02T16:51:16.117810Z",
     "shell.execute_reply": "2022-04-02T16:51:16.117501Z",
     "shell.execute_reply.started": "2022-04-02T16:51:16.114698Z"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1644562033264,
     "user": {
      "displayName": "Shaannoor Mann",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "02520257695567980696"
     },
     "user_tz": 360
    },
    "id": "v_Y8C62GtAXk",
    "outputId": "e8c4cb40-b386-43c9-9f34-887f5f5c4ed1",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(target_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "feccYoeWtAXk"
   },
   "source": [
    "## <font color = 'blue'> Create Dataset and Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T16:51:16.430075Z",
     "iopub.status.busy": "2022-04-02T16:51:16.429881Z",
     "iopub.status.idle": "2022-04-02T16:51:16.433561Z",
     "shell.execute_reply": "2022-04-02T16:51:16.433084Z",
     "shell.execute_reply.started": "2022-04-02T16:51:16.430055Z"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1644562046437,
     "user": {
      "displayName": "Shaannoor Mann",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "02520257695567980696"
     },
     "user_tz": 360
    },
    "id": "fCMXepKUtAXk",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class EngGerman(Dataset):\n",
    "    def __init__(self, X1, X2):\n",
    "        self.X1 = X1\n",
    "        self.X2 = X2\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.X1)\n",
    "    \n",
    "    def __getitem__(self, indices):\n",
    "        return (self.X1.iloc[indices] , self.X2.iloc[indices]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T16:51:16.585886Z",
     "iopub.status.busy": "2022-04-02T16:51:16.585760Z",
     "iopub.status.idle": "2022-04-02T16:51:16.588539Z",
     "shell.execute_reply": "2022-04-02T16:51:16.588135Z",
     "shell.execute_reply.started": "2022-04-02T16:51:16.585872Z"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1644562047576,
     "user": {
      "displayName": "Shaannoor Mann",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "02520257695567980696"
     },
     "user_tz": 360
    },
    "id": "-Q32VBamtAXl",
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainset = EngGerman(df_train_small['source_tokens'], df_train['target_tokens'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2022-04-02T16:51:16.770870Z",
     "iopub.status.busy": "2022-04-02T16:51:16.770752Z",
     "iopub.status.idle": "2022-04-02T16:51:16.774135Z",
     "shell.execute_reply": "2022-04-02T16:51:16.773768Z",
     "shell.execute_reply.started": "2022-04-02T16:51:16.770857Z"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1644562048806,
     "user": {
      "displayName": "Shaannoor Mann",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "02520257695567980696"
     },
     "user_tz": 360
    },
    "id": "2md5tDSutAXl",
    "outputId": "e43ad22f-28f2-4edc-ca70-25d8c38e53db",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['zwei',\n",
       "  'junge',\n",
       "  'weiße',\n",
       "  'männer',\n",
       "  'sind',\n",
       "  'i',\n",
       "  'm',\n",
       "  'freien',\n",
       "  'in',\n",
       "  'der',\n",
       "  'nähe',\n",
       "  'vieler',\n",
       "  'büsche',\n",
       "  '.'],\n",
       " ['two',\n",
       "  'young',\n",
       "  ',',\n",
       "  'white',\n",
       "  'males',\n",
       "  'are',\n",
       "  'outside',\n",
       "  'near',\n",
       "  'many',\n",
       "  'bushes',\n",
       "  '.'])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = 'green'> **Function to replace words woth their index. Also add tokens BOS and EOS for beginning and end of sentences**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T16:51:17.083125Z",
     "iopub.status.busy": "2022-04-02T16:51:17.082739Z",
     "iopub.status.idle": "2022-04-02T16:51:17.086107Z",
     "shell.execute_reply": "2022-04-02T16:51:17.085652Z",
     "shell.execute_reply.started": "2022-04-02T16:51:17.083094Z"
    },
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1644562051382,
     "user": {
      "displayName": "Shaannoor Mann",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "02520257695567980696"
     },
     "user_tz": 360
    },
    "id": "bPg8WslltAXl",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def text_transform (my_vocab, text):\n",
    "     text_numerical = [my_vocab[token] for token in text]\n",
    "     return torch.tensor([my_vocab['<BOS>']] + text_numerical + [my_vocab['<EOS>']])\n",
    "     #return list(my_vocab['<BOS>']) + text_numerical + list(my_vocab['<EOS>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2022-04-02T16:51:17.264424Z",
     "iopub.status.busy": "2022-04-02T16:51:17.264283Z",
     "iopub.status.idle": "2022-04-02T16:51:17.276513Z",
     "shell.execute_reply": "2022-04-02T16:51:17.276137Z",
     "shell.execute_reply.started": "2022-04-02T16:51:17.264410Z"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1644562052563,
     "user": {
      "displayName": "Shaannoor Mann",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "02520257695567980696"
     },
     "user_tz": 360
    },
    "id": "bpQKiRHLtAXl",
    "outputId": "d949e909-118d-49b6-dfcd-0e54a4790b7a",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['two', 'young', ',', 'white', 'males', 'are', 'outside', 'near', 'many', 'bushes', '.']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([ 1,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14,  2])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = trainset[0][1]\n",
    "print(text)\n",
    "text_transform(target_vocab, text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T16:51:17.424804Z",
     "iopub.status.busy": "2022-04-02T16:51:17.424664Z",
     "iopub.status.idle": "2022-04-02T16:51:17.429213Z",
     "shell.execute_reply": "2022-04-02T16:51:17.428819Z",
     "shell.execute_reply.started": "2022-04-02T16:51:17.424791Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['several', 'men', 'in', 'hard', 'hats', 'are', 'operating', 'a', 'giant', 'pulley', 'system', '.']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([ 1, 15, 16, 17, 18, 19,  9, 20, 21, 22, 23, 24, 14,  2])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = trainset[1][1]\n",
    "print(text)\n",
    "text_transform(target_vocab, text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = 'green'> Create a function that will be use by dataloaders to group obsevations. We will first use transform function to add eos and bos tokens and replace words with indexes. Finally we will add pad tokens for smaller sentences in a batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T16:51:17.745287Z",
     "iopub.status.busy": "2022-04-02T16:51:17.745126Z",
     "iopub.status.idle": "2022-04-02T16:51:17.748640Z",
     "shell.execute_reply": "2022-04-02T16:51:17.748304Z",
     "shell.execute_reply.started": "2022-04-02T16:51:17.745271Z"
    },
    "executionInfo": {
     "elapsed": 452,
     "status": "ok",
     "timestamp": 1644562054119,
     "user": {
      "displayName": "Shaannoor Mann",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "02520257695567980696"
     },
     "user_tz": 360
    },
    "id": "CgKupdZ1Un2-",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def collate_batch(batch):\n",
    "   source_list, target_list = [], []\n",
    "   for (source_text, target_text) in batch:\n",
    "        source_transform = text_transform(source_vocab, source_text)\n",
    "        source_list.append(source_transform)\n",
    "        target_transform =text_transform(target_vocab, target_text)\n",
    "        target_list.append(target_transform)\n",
    "        \n",
    "   source_pad = pad_sequence(source_list, padding_value=3.0, batch_first = True)\n",
    "   target_pad = pad_sequence(target_list, padding_value=3.0, batch_first = True)\n",
    "   #print(source_list)\n",
    "   return (source_pad, target_pad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T16:51:17.908741Z",
     "iopub.status.busy": "2022-04-02T16:51:17.908601Z",
     "iopub.status.idle": "2022-04-02T16:51:17.911932Z",
     "shell.execute_reply": "2022-04-02T16:51:17.911538Z",
     "shell.execute_reply.started": "2022-04-02T16:51:17.908727Z"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1644562055245,
     "user": {
      "displayName": "Shaannoor Mann",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "02520257695567980696"
     },
     "user_tz": 360
    },
    "id": "EqHCA63DUn2_",
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "batch_size = 2\n",
    "\n",
    "train_loader = DataLoader(trainset, batch_size=batch_size, shuffle=True, \n",
    "                              collate_fn=collate_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2022-04-02T16:51:18.080452Z",
     "iopub.status.busy": "2022-04-02T16:51:18.080312Z",
     "iopub.status.idle": "2022-04-02T16:51:18.111249Z",
     "shell.execute_reply": "2022-04-02T16:51:18.110815Z",
     "shell.execute_reply.started": "2022-04-02T16:51:18.080438Z"
    },
    "executionInfo": {
     "elapsed": 321,
     "status": "ok",
     "timestamp": 1644562056795,
     "user": {
      "displayName": "Shaannoor Mann",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "02520257695567980696"
     },
     "user_tz": 360
    },
    "id": "-NUpXpJYtAXm",
    "outputId": "fffcd026-2cb5-4d9a-b657-d0f15136ff02",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch number: 0\n",
      "source\n",
      "tensor([[ 1, 22, 30, 12, 31, 32, 33, 34, 35, 36, 37, 38, 39, 22, 40, 17,  2],\n",
      "        [ 1,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,  2,  3]])\n",
      "target\n",
      "tensor([[ 1, 21, 31, 17, 21, 32, 33, 34, 35, 36, 21, 37, 38, 21, 39, 14,  2],\n",
      "        [ 1,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14,  2,  3,  3,  3,  3]])\n",
      "batch number: 1\n",
      "source\n",
      "tensor([[ 1, 22, 24, 25, 26, 12, 22, 27, 28, 29, 17,  2],\n",
      "        [ 1, 18,  7, 19, 20, 21, 22, 23, 17,  2,  3,  3]])\n",
      "target\n",
      "tensor([[ 1, 21, 25, 26, 27, 28, 21, 29, 30, 14,  2,  3,  3,  3],\n",
      "        [ 1, 15, 16, 17, 18, 19,  9, 20, 21, 22, 23, 24, 14,  2]])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(40)\n",
    "for i, (source, target) in enumerate(train_loader):\n",
    "   \n",
    "  print('batch number:' ,i)\n",
    "  print('source')  \n",
    "  print(source)\n",
    "  print('target')  \n",
    "  print(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T16:51:18.264726Z",
     "iopub.status.busy": "2022-04-02T16:51:18.264601Z",
     "iopub.status.idle": "2022-04-02T16:51:18.268006Z",
     "shell.execute_reply": "2022-04-02T16:51:18.267662Z",
     "shell.execute_reply.started": "2022-04-02T16:51:18.264713Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "#device = torch.device('cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = 3, color = 'green'> **We will be using the second batch for our example.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T16:51:18.913682Z",
     "iopub.status.busy": "2022-04-02T16:51:18.913520Z",
     "iopub.status.idle": "2022-04-02T16:51:21.147765Z",
     "shell.execute_reply": "2022-04-02T16:51:21.147314Z",
     "shell.execute_reply.started": "2022-04-02T16:51:18.913655Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1, 22, 24, 25, 26, 12, 22, 27, 28, 29, 17,  2],\n",
      "        [ 1, 18,  7, 19, 20, 21, 22, 23, 17,  2,  3,  3]], device='cuda:0')\n",
      "torch.Size([2, 12])\n"
     ]
    }
   ],
   "source": [
    "src = source.clone().to(device)\n",
    "print(src)\n",
    "print(src.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T16:51:21.148652Z",
     "iopub.status.busy": "2022-04-02T16:51:21.148539Z",
     "iopub.status.idle": "2022-04-02T16:51:21.151591Z",
     "shell.execute_reply": "2022-04-02T16:51:21.151338Z",
     "shell.execute_reply.started": "2022-04-02T16:51:21.148639Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1, 21, 25, 26, 27, 28, 21, 29, 30, 14,  2,  3,  3,  3],\n",
      "        [ 1, 15, 16, 17, 18, 19,  9, 20, 21, 22, 23, 24, 14,  2]],\n",
      "       device='cuda:0')\n",
      "torch.Size([2, 14])\n"
     ]
    }
   ],
   "source": [
    "trg= target.clone().to(device)\n",
    "print(trg)\n",
    "print(trg.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-11T13:26:07.222652Z",
     "iopub.status.busy": "2022-03-11T13:26:07.222501Z",
     "iopub.status.idle": "2022-03-11T13:26:07.225428Z",
     "shell.execute_reply": "2022-03-11T13:26:07.225096Z",
     "shell.execute_reply.started": "2022-03-11T13:26:07.222637Z"
    },
    "tags": []
   },
   "source": [
    "- <font size = 3, color = 'green'> First token will have index 1 - corresponding to < BOS > token\n",
    "- <font size = 3, color = 'green'> In target last token in first senence have index 3 - corresponding to < PAD >\n",
    "- <font size = 3, color = 'green'> In target last token in second senence have index 2 - corresponding to < EOS >\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T16:51:21.152122Z",
     "iopub.status.busy": "2022-04-02T16:51:21.152012Z",
     "iopub.status.idle": "2022-04-02T16:51:21.154840Z",
     "shell.execute_reply": "2022-04-02T16:51:21.154576Z",
     "shell.execute_reply.started": "2022-04-02T16:51:21.152110Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(src[0][0]) # first token will have index 1 - corresponding to '<BOS>'\n",
    "print(trg[0][-1]) # In target last token in first senence have index 3 - corresponding to '<PAD>'\n",
    "print(trg[1][-1]) # In target last token in second senence have index 2 - corresponding to '<EOS>'\n",
    "# batch_size, src_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T16:51:21.155608Z",
     "iopub.status.busy": "2022-04-02T16:51:21.155486Z",
     "iopub.status.idle": "2022-04-02T16:51:21.158625Z",
     "shell.execute_reply": "2022-04-02T16:51:21.158323Z",
     "shell.execute_reply.started": "2022-04-02T16:51:21.155568Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "print(src.device)\n",
    "print(trg.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = 'green'> **INPUT, LABEL, OUTPUT FOR DECODER** <br>\n",
    "Original Sequence: $trg = [sos, x_1, x_2, x_3, eos]$ <br>\n",
    "Input to Model: $trg[:-1][sos, x_1, x_2, x_3]$  <br>\n",
    "Predicted Values: $[y_1, y_2, y_3, eos]$<br>\n",
    "Lable or True y : $trg[1:] = [x_1, x_2, x_3, eos]$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = 3, color = 'green'> **ISSUE**: We are trying to remove eos token using  $trg[:,-1]$. However, this will remove pad token and not eos token. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = 'green'> **SOLUTION**: Response from  https://github.com/bentrevett/pytorch-seq2seq/issues/182\n",
    "    \n",
    "<font color = 'green'> Our trg sequence will be something like [sos, x1, x2, x3, eos] When we do $trg[:,-1]$ the sequence will be [sos, x1, x2, x3], and our predicted sequence will be [y1, y2, y3, y4], where y1 should be x1, y2 should be x2, y3 should be x3 and y4 should be eos. The predicted sequence should be a shifted version of the target sequence -- this is because we calculate the loss of output against $trg[,1:]$ = [x1, x2, x3, eos]\n",
    "\n",
    "<font color = 'green'> With padding, let's say the target sequence is [sos, x1, x2, x3, eos, pad, pad], thus $trg[:,-1]$ = [sos, x1, x2, x3, eos, pad] and thus our predicted sequence is [y1, y2, y3, y4, y5, y6]. Same as before, but y5 and y6 should be the model predicting pad tokens, so we are calculating the loss of our output against $trg[,1:]$ = [x1, x2, x3, eos, pad, pad]. However, because we use nn.CrossEntropyLoss(ignore_index = TRG_PAD_IDX) we ignore the loss values over the pad tokens, so we only calculate loss from the output compared against $trg[,1:]$ = [x1, x2, x3, eos] -- which is the exact same sequence without padding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = 'green'>**CONCLUSION** <br>\n",
    "Original Sequence: $trg = [sos, x_1, x_2, x_3, eos, pad, pad]$ <br>\n",
    "Input to Model: $trg[:-1][sos, x_1, x_2, x_3, eos, pad]$  <br>\n",
    "Predicted Values: $[y_1, y_2, y_3, eos, garbage, garbage]$ <br>\n",
    "Lable or True y : $trg[1:] = [x_1, x_2, x_3, eos, pad, pad]$ <br>\n",
    "    \n",
    "<font color = 'red'>Since, we ignore pad token in Label while calculationg loss, this does not effect our model. Ideally we do not want to give eos as input to model, but there is no way around with pad sequences. \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T16:51:21.159275Z",
     "iopub.status.busy": "2022-04-02T16:51:21.159129Z",
     "iopub.status.idle": "2022-04-02T16:51:21.161563Z",
     "shell.execute_reply": "2022-04-02T16:51:21.161309Z",
     "shell.execute_reply.started": "2022-04-02T16:51:21.159262Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "trg_in = trg[:, :-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T16:51:21.162095Z",
     "iopub.status.busy": "2022-04-02T16:51:21.161976Z",
     "iopub.status.idle": "2022-04-02T16:51:21.166232Z",
     "shell.execute_reply": "2022-04-02T16:51:21.165997Z",
     "shell.execute_reply.started": "2022-04-02T16:51:21.162083Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1, 21, 25, 26, 27, 28, 21, 29, 30, 14,  2,  3,  3],\n",
       "        [ 1, 15, 16, 17, 18, 19,  9, 20, 21, 22, 23, 24, 14]], device='cuda:0')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trg_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T16:51:21.166774Z",
     "iopub.status.busy": "2022-04-02T16:51:21.166661Z",
     "iopub.status.idle": "2022-04-02T16:51:21.169222Z",
     "shell.execute_reply": "2022-04-02T16:51:21.168974Z",
     "shell.execute_reply.started": "2022-04-02T16:51:21.166762Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 13])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trg_in.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T16:51:21.169758Z",
     "iopub.status.busy": "2022-04-02T16:51:21.169647Z",
     "iopub.status.idle": "2022-04-02T16:51:21.173031Z",
     "shell.execute_reply": "2022-04-02T16:51:21.172651Z",
     "shell.execute_reply.started": "2022-04-02T16:51:21.169746Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 14])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trg.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# <font color = 'blue'> Building the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## <font color = 'blue'> Input Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](assets/transformer-encoder.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = 3, color = 'green'>\n",
    "    \n",
    "1. Pass the token indices through embedding layer. \n",
    "2. Multiply token embedding by a scaling factor :$\\sqrt{d_{model}}$, where $d_{model}$ is the hidden dimension size, `hid_dim`. <font color = 'red'> **NOT UNDERSTOOD**\n",
    "3.Create a vector of token positions (assime max length. pass the positions through the  *positional embedding layer*. <font color = 'red'> **Check the fixed static embeddings used in the original paper** </font>\n",
    "\n",
    "<font color = 'green'>\n",
    "    \n",
    "4. Add the two embeddings  \n",
    "    \n",
    "5. **Dropout is then applied to the combined embeddings.**\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color = 'blue'>  Step 1 Token embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T16:51:21.173618Z",
     "iopub.status.busy": "2022-04-02T16:51:21.173526Z",
     "iopub.status.idle": "2022-04-02T16:51:21.176665Z",
     "shell.execute_reply": "2022-04-02T16:51:21.176384Z",
     "shell.execute_reply.started": "2022-04-02T16:51:21.173606Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "hid_dim = 8\n",
    "torch.manual_seed(0)\n",
    "src_token_embedding_layer = nn.Embedding(len(source_vocab), hid_dim).to(device)\n",
    "trg_token_embedding_layer = nn.Embedding(len(target_vocab), hid_dim).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T16:51:21.177981Z",
     "iopub.status.busy": "2022-04-02T16:51:21.177848Z",
     "iopub.status.idle": "2022-04-02T16:51:21.190069Z",
     "shell.execute_reply": "2022-04-02T16:51:21.189781Z",
     "shell.execute_reply.started": "2022-04-02T16:51:21.177967Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.1258, -1.1524, -0.2506, -0.4339,  0.8487,  0.6920, -0.3160, -2.1152],\n",
      "        [ 0.3223, -1.2633,  0.3500,  0.3081,  0.1198,  1.2377,  1.1168, -0.2473],\n",
      "        [-1.3527, -1.6959,  0.5667,  0.7935,  0.5988, -1.5551, -0.3414,  1.8530],\n",
      "        [ 0.7502, -0.5855, -0.1734,  0.1835,  1.3894,  1.5863,  0.9463, -0.8437],\n",
      "        [-0.6136,  0.0316, -0.4927,  0.2484,  0.4397,  0.1124,  0.6408,  0.4412]],\n",
      "       device='cuda:0', grad_fn=<SliceBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(f'{src_token_embedding_layer.weight[0:5]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T16:51:21.190737Z",
     "iopub.status.busy": "2022-04-02T16:51:21.190593Z",
     "iopub.status.idle": "2022-04-02T16:51:21.194393Z",
     "shell.execute_reply": "2022-04-02T16:51:21.194139Z",
     "shell.execute_reply.started": "2022-04-02T16:51:21.190726Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.5627, -0.8328, -1.3955, -0.3993, -0.3099, -0.0561,  0.5174, -1.5962],\n",
      "        [ 0.3570, -2.2975, -0.8711, -1.6740,  0.5631, -1.4351,  0.7194, -1.3707],\n",
      "        [ 0.3221, -0.1016,  0.2060,  1.2168,  1.2359, -0.1002,  2.1364,  0.0700],\n",
      "        [ 0.4990,  0.0565,  0.4061, -1.7384,  1.1901,  2.6352,  0.2284,  0.3241],\n",
      "        [-1.1154,  2.1914,  0.1158,  0.7773, -1.0921, -0.0611, -1.4928, -1.7644]],\n",
      "       device='cuda:0', grad_fn=<SliceBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(f'{trg_token_embedding_layer.weight[0:5]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T16:51:21.194956Z",
     "iopub.status.busy": "2022-04-02T16:51:21.194844Z",
     "iopub.status.idle": "2022-04-02T16:51:21.199841Z",
     "shell.execute_reply": "2022-04-02T16:51:21.199304Z",
     "shell.execute_reply.started": "2022-04-02T16:51:21.194944Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "src_embedding = src_token_embedding_layer(src)\n",
    "trg_embedding = trg_token_embedding_layer(trg_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T16:51:21.200574Z",
     "iopub.status.busy": "2022-04-02T16:51:21.200445Z",
     "iopub.status.idle": "2022-04-02T16:51:21.202844Z",
     "shell.execute_reply": "2022-04-02T16:51:21.202479Z",
     "shell.execute_reply.started": "2022-04-02T16:51:21.200561Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 12, 8])\n",
      "torch.Size([2, 13, 8])\n"
     ]
    }
   ],
   "source": [
    "print(src_embedding.shape)\n",
    "print(trg_embedding.shape)\n",
    "# batch_size, seq_len, hid_dim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = 3, color = 'green'> Each word is represented as  vector of size hidden_dim. Hidden_dim is same for source and target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T16:51:21.203413Z",
     "iopub.status.busy": "2022-04-02T16:51:21.203280Z",
     "iopub.status.idle": "2022-04-02T16:51:21.207311Z",
     "shell.execute_reply": "2022-04-02T16:51:21.207032Z",
     "shell.execute_reply.started": "2022-04-02T16:51:21.203401Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.3223, -1.2633,  0.3500,  0.3081,  0.1198,  1.2377,  1.1168, -0.2473],\n",
       "       device='cuda:0', grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src_embedding[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T16:51:21.207992Z",
     "iopub.status.busy": "2022-04-02T16:51:21.207803Z",
     "iopub.status.idle": "2022-04-02T16:51:21.211568Z",
     "shell.execute_reply": "2022-04-02T16:51:21.211309Z",
     "shell.execute_reply.started": "2022-04-02T16:51:21.207979Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.3570, -2.2975, -0.8711, -1.6740,  0.5631, -1.4351,  0.7194, -1.3707],\n",
       "       device='cuda:0', grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trg_embedding[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color = 'blue'>  Step 2 - scale output of embedding\n",
    "<font color = 'red'> **NOT UNDERSTOOD**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T16:51:21.212246Z",
     "iopub.status.busy": "2022-04-02T16:51:21.212030Z",
     "iopub.status.idle": "2022-04-02T16:51:21.216950Z",
     "shell.execute_reply": "2022-04-02T16:51:21.216691Z",
     "shell.execute_reply.started": "2022-04-02T16:51:21.212234Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.0456, device='cuda:0', grad_fn=<VarBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.5988, device='cuda:0', grad_fn=<VarBackward0>)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(torch.var(src_embedding [0][4]))\n",
    "torch.var(trg_embedding [0][4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T16:51:21.217540Z",
     "iopub.status.busy": "2022-04-02T16:51:21.217421Z",
     "iopub.status.idle": "2022-04-02T16:51:21.222468Z",
     "shell.execute_reply": "2022-04-02T16:51:21.222149Z",
     "shell.execute_reply.started": "2022-04-02T16:51:21.217528Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.8284], device='cuda:0')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scale = torch.sqrt(torch.FloatTensor([hid_dim])).to(device)\n",
    "scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T16:51:21.223059Z",
     "iopub.status.busy": "2022-04-02T16:51:21.222940Z",
     "iopub.status.idle": "2022-04-02T16:51:21.224975Z",
     "shell.execute_reply": "2022-04-02T16:51:21.224713Z",
     "shell.execute_reply.started": "2022-04-02T16:51:21.223047Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "src_embedding_scaled = src_embedding*scale\n",
    "trg_embedding_scaled = trg_embedding*scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T16:51:21.225632Z",
     "iopub.status.busy": "2022-04-02T16:51:21.225512Z",
     "iopub.status.idle": "2022-04-02T16:51:21.230097Z",
     "shell.execute_reply": "2022-04-02T16:51:21.229839Z",
     "shell.execute_reply.started": "2022-04-02T16:51:21.225620Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(8.3652, device='cuda:0', grad_fn=<VarBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(4.7907, device='cuda:0', grad_fn=<VarBackward0>)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(torch.var(src_embedding_scaled[0][4]))\n",
    "torch.var(trg_embedding_scaled[0][4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color = 'blue'>  Step 3 Positional Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T16:51:21.230733Z",
     "iopub.status.busy": "2022-04-02T16:51:21.230558Z",
     "iopub.status.idle": "2022-04-02T16:51:21.233093Z",
     "shell.execute_reply": "2022-04-02T16:51:21.232832Z",
     "shell.execute_reply.started": "2022-04-02T16:51:21.230721Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "max_length = 20\n",
    "src_position_embedding_layer = nn.Embedding(max_length, hid_dim).to(device)\n",
    "trg_position_embedding_layer = nn.Embedding(max_length, hid_dim).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T16:51:21.233825Z",
     "iopub.status.busy": "2022-04-02T16:51:21.233582Z",
     "iopub.status.idle": "2022-04-02T16:51:21.239087Z",
     "shell.execute_reply": "2022-04-02T16:51:21.238507Z",
     "shell.execute_reply.started": "2022-04-02T16:51:21.233812Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 8])\n",
      "torch.Size([20, 8])\n"
     ]
    }
   ],
   "source": [
    "print(src_position_embedding_layer.weight.shape)\n",
    "print(trg_position_embedding_layer.weight.shape)\n",
    "# max seq len, hid_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T16:51:21.240178Z",
     "iopub.status.busy": "2022-04-02T16:51:21.239932Z",
     "iopub.status.idle": "2022-04-02T16:51:21.245511Z",
     "shell.execute_reply": "2022-04-02T16:51:21.245165Z",
     "shell.execute_reply.started": "2022-04-02T16:51:21.240157Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.1258, -1.1524, -0.2506, -0.4339,  0.8487,  0.6920, -0.3160, -2.1152],\n",
       "        [ 0.3223, -1.2633,  0.3500,  0.3081,  0.1198,  1.2377,  1.1168, -0.2473],\n",
       "        [-1.3527, -1.6959,  0.5667,  0.7935,  0.5988, -1.5551, -0.3414,  1.8530],\n",
       "        [ 0.7502, -0.5855, -0.1734,  0.1835,  1.3894,  1.5863,  0.9463, -0.8437],\n",
       "        [-0.6136,  0.0316, -0.4927,  0.2484,  0.4397,  0.1124,  0.6408,  0.4412]],\n",
       "       device='cuda:0', grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src_position_embedding_layer.weight[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T16:51:21.246434Z",
     "iopub.status.busy": "2022-04-02T16:51:21.246161Z",
     "iopub.status.idle": "2022-04-02T16:51:21.248901Z",
     "shell.execute_reply": "2022-04-02T16:51:21.248495Z",
     "shell.execute_reply.started": "2022-04-02T16:51:21.246417Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size = src_embedding_scaled.shape[0]\n",
    "src_len = src_embedding_scaled.shape[1]\n",
    "trg_len = trg_embedding_scaled.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T16:51:21.249771Z",
     "iopub.status.busy": "2022-04-02T16:51:21.249504Z",
     "iopub.status.idle": "2022-04-02T16:51:21.254841Z",
     "shell.execute_reply": "2022-04-02T16:51:21.254458Z",
     "shell.execute_reply.started": "2022-04-02T16:51:21.249753Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "12\n",
      "13\n"
     ]
    }
   ],
   "source": [
    "print(batch_size)\n",
    "print(src_len)\n",
    "print(trg_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T16:51:21.255527Z",
     "iopub.status.busy": "2022-04-02T16:51:21.255374Z",
     "iopub.status.idle": "2022-04-02T16:51:21.260366Z",
     "shell.execute_reply": "2022-04-02T16:51:21.260029Z",
     "shell.execute_reply.started": "2022-04-02T16:51:21.255509Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11])\n",
      "torch.Size([12])\n"
     ]
    }
   ],
   "source": [
    "src_position = torch.arange(0, src_len)\n",
    "print(src_position)\n",
    "print(src_position.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T16:51:21.261030Z",
     "iopub.status.busy": "2022-04-02T16:51:21.260877Z",
     "iopub.status.idle": "2022-04-02T16:51:21.265321Z",
     "shell.execute_reply": "2022-04-02T16:51:21.264987Z",
     "shell.execute_reply.started": "2022-04-02T16:51:21.261012Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 12])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src_position = src_position.unsqueeze(0)\n",
    "print(src_position.shape)\n",
    "src_position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T16:51:21.266052Z",
     "iopub.status.busy": "2022-04-02T16:51:21.265814Z",
     "iopub.status.idle": "2022-04-02T16:51:21.268259Z",
     "shell.execute_reply": "2022-04-02T16:51:21.267946Z",
     "shell.execute_reply.started": "2022-04-02T16:51:21.266036Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "src_position = src_position.repeat(batch_size,1)\n",
    "src_position = src_position.to(device)\n",
    "# [batch_size, seq_len]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T16:51:21.271015Z",
     "iopub.status.busy": "2022-04-02T16:51:21.270764Z",
     "iopub.status.idle": "2022-04-02T16:51:21.273253Z",
     "shell.execute_reply": "2022-04-02T16:51:21.272989Z",
     "shell.execute_reply.started": "2022-04-02T16:51:21.271001Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 12])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src_position.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T16:51:21.273733Z",
     "iopub.status.busy": "2022-04-02T16:51:21.273620Z",
     "iopub.status.idle": "2022-04-02T16:51:21.277957Z",
     "shell.execute_reply": "2022-04-02T16:51:21.277614Z",
     "shell.execute_reply.started": "2022-04-02T16:51:21.273721Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11],\n",
       "        [ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11]], device='cuda:0')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src_position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T16:51:21.278503Z",
     "iopub.status.busy": "2022-04-02T16:51:21.278385Z",
     "iopub.status.idle": "2022-04-02T16:51:21.281076Z",
     "shell.execute_reply": "2022-04-02T16:51:21.280828Z",
     "shell.execute_reply.started": "2022-04-02T16:51:21.278491Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "trg_position = torch.arange(trg_len).view(1,-1).repeat(batch_size,1).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T16:51:21.281585Z",
     "iopub.status.busy": "2022-04-02T16:51:21.281477Z",
     "iopub.status.idle": "2022-04-02T16:51:21.284477Z",
     "shell.execute_reply": "2022-04-02T16:51:21.284233Z",
     "shell.execute_reply.started": "2022-04-02T16:51:21.281573Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12],\n",
      "        [ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12]], device='cuda:0')\n",
      "torch.Size([2, 13])\n"
     ]
    }
   ],
   "source": [
    "print(trg_position)\n",
    "print(trg_position.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T16:51:21.284977Z",
     "iopub.status.busy": "2022-04-02T16:51:21.284873Z",
     "iopub.status.idle": "2022-04-02T16:51:21.287778Z",
     "shell.execute_reply": "2022-04-02T16:51:21.287531Z",
     "shell.execute_reply.started": "2022-04-02T16:51:21.284966Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "src_position_embedding = src_position_embedding_layer(src_position)\n",
    "trg_position_embedding = trg_position_embedding_layer(trg_position)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T16:51:21.288288Z",
     "iopub.status.busy": "2022-04-02T16:51:21.288182Z",
     "iopub.status.idle": "2022-04-02T16:51:21.290911Z",
     "shell.execute_reply": "2022-04-02T16:51:21.290598Z",
     "shell.execute_reply.started": "2022-04-02T16:51:21.288276Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 12, 8])\n",
      "torch.Size([2, 13, 8])\n"
     ]
    }
   ],
   "source": [
    "print(src_position_embedding.shape)\n",
    "print(trg_position_embedding.shape)\n",
    "# [ batch_size, seq_len, hid_dim]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color = 'blue'> Step 4 Combine scaled token embedding and position embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T16:51:21.291440Z",
     "iopub.status.busy": "2022-04-02T16:51:21.291332Z",
     "iopub.status.idle": "2022-04-02T16:51:21.294876Z",
     "shell.execute_reply": "2022-04-02T16:51:21.294602Z",
     "shell.execute_reply.started": "2022-04-02T16:51:21.291428Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "encoder_input = src_position_embedding + src_embedding_scaled\n",
    "decoder_input = trg_position_embedding + trg_embedding_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T16:51:21.295412Z",
     "iopub.status.busy": "2022-04-02T16:51:21.295303Z",
     "iopub.status.idle": "2022-04-02T16:51:21.299433Z",
     "shell.execute_reply": "2022-04-02T16:51:21.299181Z",
     "shell.execute_reply.started": "2022-04-02T16:51:21.295400Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.2143, -4.7256,  0.7393,  0.4377,  1.1877,  4.1926,  2.8427, -2.8146],\n",
       "       device='cuda:0', grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_input[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color = 'blue'> Step 5 Apply Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T16:51:21.299976Z",
     "iopub.status.busy": "2022-04-02T16:51:21.299869Z",
     "iopub.status.idle": "2022-04-02T16:51:21.301925Z",
     "shell.execute_reply": "2022-04-02T16:51:21.301667Z",
     "shell.execute_reply.started": "2022-04-02T16:51:21.299964Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "encoder_input_dropout_layer = nn.Dropout(p=0.1)\n",
    "decoder_input_dropout_layer = nn.Dropout(p=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T16:51:21.302436Z",
     "iopub.status.busy": "2022-04-02T16:51:21.302330Z",
     "iopub.status.idle": "2022-04-02T16:51:21.305235Z",
     "shell.execute_reply": "2022-04-02T16:51:21.304984Z",
     "shell.execute_reply.started": "2022-04-02T16:51:21.302425Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "encoder_input_after_dropout = encoder_input_dropout_layer(encoder_input)\n",
    "decoder_input_after_dropout = encoder_input_dropout_layer(decoder_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T16:51:21.305828Z",
     "iopub.status.busy": "2022-04-02T16:51:21.305640Z",
     "iopub.status.idle": "2022-04-02T16:51:21.310510Z",
     "shell.execute_reply": "2022-04-02T16:51:21.310231Z",
     "shell.execute_reply.started": "2022-04-02T16:51:21.305816Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.2381, -5.2507,  0.8215,  0.4863,  1.3196,  0.0000,  3.1586, -3.1274],\n",
       "       device='cuda:0', grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_input_after_dropout[0][0]\n",
    "# [batch_size, seq_len, hid_dim]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = 3, color = 'green'> **Dropout layer set 10% (p =0.1) of neurons to zero and divides the other by 0.9 (1-p)**. We do not apply dropout during inference. In pytorch when we use model.train() - dropout layer is applied, whereas when we use model.eval() dropout layer is not applied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T16:51:21.311300Z",
     "iopub.status.busy": "2022-04-02T16:51:21.311122Z",
     "iopub.status.idle": "2022-04-02T16:51:21.316128Z",
     "shell.execute_reply": "2022-04-02T16:51:21.315619Z",
     "shell.execute_reply.started": "2022-04-02T16:51:21.311282Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.2381, -5.2507,  0.8215,  0.4863,  1.3196,  4.6585,  3.1586, -3.1274],\n",
       "       device='cuda:0', grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_input[0][0]/0.9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## <font color = 'blue'>  <font size =5> **Encoder Layers**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<font size =4, color = 'green'> Sublayer Self Attention </font>\n",
    "\n",
    "<font color = 'green'>\n",
    "    \n",
    "- Step1: Pass the source sentence and its mask into the *multi-head attention layer*- self attention.\n",
    "    \n",
    "- Step2: Layer Noramalization(dropout(output of self attention) + input self attention). Adding input to the output layer is also referred as redidual connection or skip connection.\n",
    "</font>\n",
    "\n",
    "<font size =4, color = 'green'> Sublayer Position-Wise Feedforward </font>\n",
    "\n",
    "<font color = 'green'>\n",
    "    \n",
    "- Step3: Pass the output of Self attention through following layers: Linear layer > RELU > Dropout > Linear\n",
    "   \n",
    "- Step4: Again, apply dropout, a residual connection and then layer normalization i.e. Layer Noramalization(dropout(output of position-wise feedforward) + input position-wise feedforward)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color = 'blue'> **Self Attention**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Mutli Head Attention Layer**\n",
    "\n",
    "\n",
    "![](assets/transformer-attention.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = 'green'>\n",
    "    \n",
    "- Attention can be thought of as *queries*, *keys* and *values* - where the query is used with the key to get an attention vector (usually the output of a *softmax* operation and has all values between 0 and 1 which sum to 1) which is then used to get a weighted sum of the values.\n",
    "\n",
    "$$ \\text{Attention}(Q, K, V) = \\text{Softmax} \\big( \\frac{QK^T}{\\sqrt{d_k}} \\big)V $$ \n",
    "\n",
    "- Scaling is done to stop the results of the dot products growing large, causing gradients to become too small - similar to some inititalization methods.\n",
    "\n",
    "- However, the scaled dot-product attention isn't simply applied to the queries, keys and values. Instead of doing a single attention application the queries, keys and values have their `hid_dim` split into $h$ *heads* and the scaled dot-product attention is calculated over all heads in parallel. This means instead of paying attention to one concept per attention application, we pay attention to $h$. We then re-combine the heads into their `hid_dim` shape, thus each `hid_dim` is potentially paying attention to $h$ different concepts.\n",
    "\n",
    "$$ \\text{MultiHead}(Q, K, V) = \\text{Concat}(\\text{head}_1,...,\\text{head}_h)W^O $$\n",
    "\n",
    "$$\\text{head}_i = \\text{Attention}(QW_i^Q, KW_i^K, VW_i^V) $$\n",
    "\n",
    "$W^O$ is the linear layer applied at the end of the multi-head attention layer, `fc`. $W^Q, W^K, W^V$ are the linear layers `fc_q`, `fc_k` and `fc_v`.\n",
    "\n",
    "**Steps for Self Attention:** \n",
    "- Step1: first we calculate $QW^Q$, $KW^K$ and $VW^V$ with the linear layers, `fc_q`, `fc_k` and `fc_v`, to give us `Q`, `K` and `V`. \n",
    "- Step2: Next, we split the `hid_dim` of the query, key and value into `n_heads` using `.view` and correctly permute them so they can be multiplied together. \n",
    "- Step3: We then calculate the `energy` (the un-normalized attention) by multiplying `Q` and `K` together and scaling it by the square root of `head_dim`, which is calulated as `hid_dim // n_heads`. \n",
    "- Step 4: We then mask the energy so we do not pay attention over any elements of the sequeuence we shouldn't.\n",
    "- Step 5: then apply the softmax \n",
    "- Step 6: apply dropout on output of softmax. \n",
    "- Step 7: We then apply the attention to the value heads, `V`, before combining the `n_heads` together. \n",
    "- Step 8: Finally, we multiply this $W^O$, represented by `fc_o`.\n",
    "    \n",
    "NOTE - All the above steps can also be applied using nn.Multiheadattention() layer. See the Appendix where we show that we get su=milar results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <font color = 'blue'> **Step 1: Linear Transformation of embeddings to generate Queries, Keys and values**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T16:51:21.316817Z",
     "iopub.status.busy": "2022-04-02T16:51:21.316695Z",
     "iopub.status.idle": "2022-04-02T16:51:21.320102Z",
     "shell.execute_reply": "2022-04-02T16:51:21.319838Z",
     "shell.execute_reply.started": "2022-04-02T16:51:21.316803Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "out_hid_dim = 12\n",
    "hid_dim = 8\n",
    "fc_q = nn.Linear(hid_dim, out_hid_dim).to(device)\n",
    "fc_k = nn.Linear(hid_dim, out_hid_dim).to(device)\n",
    "fc_v = nn.Linear(hid_dim, out_hid_dim).to(device)\n",
    "fc_o = nn.Linear(out_hid_dim, hid_dim).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T16:51:21.320664Z",
     "iopub.status.busy": "2022-04-02T16:51:21.320548Z",
     "iopub.status.idle": "2022-04-02T16:51:21.323048Z",
     "shell.execute_reply": "2022-04-02T16:51:21.322790Z",
     "shell.execute_reply.started": "2022-04-02T16:51:21.320652Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12, 8])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fc_q.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T16:51:21.323652Z",
     "iopub.status.busy": "2022-04-02T16:51:21.323519Z",
     "iopub.status.idle": "2022-04-02T16:51:21.327534Z",
     "shell.execute_reply": "2022-04-02T16:51:21.327275Z",
     "shell.execute_reply.started": "2022-04-02T16:51:21.323639Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fc_q.bias.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T16:51:21.328102Z",
     "iopub.status.busy": "2022-04-02T16:51:21.327990Z",
     "iopub.status.idle": "2022-04-02T16:51:21.892918Z",
     "shell.execute_reply": "2022-04-02T16:51:21.892523Z",
     "shell.execute_reply.started": "2022-04-02T16:51:21.328090Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "Q = fc_q(encoder_input_after_dropout)\n",
    "K = fc_k(encoder_input_after_dropout)\n",
    "V = fc_v(encoder_input_after_dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T16:51:21.893542Z",
     "iopub.status.busy": "2022-04-02T16:51:21.893451Z",
     "iopub.status.idle": "2022-04-02T16:51:21.896453Z",
     "shell.execute_reply": "2022-04-02T16:51:21.896158Z",
     "shell.execute_reply.started": "2022-04-02T16:51:21.893531Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 12, 12])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q.shape\n",
    "#[batch_size, query_len, hid_dim]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <font color = 'blue'>**Step2: Split the `hid_dim` of the query, key and value into `n_heads`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T16:51:21.897039Z",
     "iopub.status.busy": "2022-04-02T16:51:21.896892Z",
     "iopub.status.idle": "2022-04-02T16:51:21.901938Z",
     "shell.execute_reply": "2022-04-02T16:51:21.901668Z",
     "shell.execute_reply.started": "2022-04-02T16:51:21.897025Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "n_heads = 3\n",
    "head_dim = out_hid_dim // n_heads\n",
    "print(head_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T16:51:21.902554Z",
     "iopub.status.busy": "2022-04-02T16:51:21.902393Z",
     "iopub.status.idle": "2022-04-02T16:51:21.905074Z",
     "shell.execute_reply": "2022-04-02T16:51:21.904828Z",
     "shell.execute_reply.started": "2022-04-02T16:51:21.902541Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "assert out_hid_dim % n_heads == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T16:51:21.905565Z",
     "iopub.status.busy": "2022-04-02T16:51:21.905450Z",
     "iopub.status.idle": "2022-04-02T16:51:21.908095Z",
     "shell.execute_reply": "2022-04-02T16:51:21.907849Z",
     "shell.execute_reply.started": "2022-04-02T16:51:21.905553Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "Q = Q.view(batch_size, -1, n_heads, head_dim)\n",
    "K = K.view(batch_size, -1, n_heads, head_dim)\n",
    "V = V.view(batch_size, -1, n_heads, head_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T16:51:21.908589Z",
     "iopub.status.busy": "2022-04-02T16:51:21.908476Z",
     "iopub.status.idle": "2022-04-02T16:51:21.912696Z",
     "shell.execute_reply": "2022-04-02T16:51:21.912458Z",
     "shell.execute_reply.started": "2022-04-02T16:51:21.908577Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 12, 3, 4])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q.shape\n",
    "#[batch_size, query_len, n_heads, head_dim]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T16:51:21.913185Z",
     "iopub.status.busy": "2022-04-02T16:51:21.913070Z",
     "iopub.status.idle": "2022-04-02T16:51:21.916187Z",
     "shell.execute_reply": "2022-04-02T16:51:21.915938Z",
     "shell.execute_reply.started": "2022-04-02T16:51:21.913172Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "Q = Q.permute(0, 2, 1, 3)\n",
    "K = K.permute(0, 2, 1, 3)\n",
    "V = V.permute(0, 2, 1, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T16:51:21.916676Z",
     "iopub.status.busy": "2022-04-02T16:51:21.916560Z",
     "iopub.status.idle": "2022-04-02T16:51:21.919902Z",
     "shell.execute_reply": "2022-04-02T16:51:21.919665Z",
     "shell.execute_reply.started": "2022-04-02T16:51:21.916663Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 12, 4])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q.shape\n",
    "#[batch_size,num_heads, query_len, head_dim ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T16:51:21.920392Z",
     "iopub.status.busy": "2022-04-02T16:51:21.920274Z",
     "iopub.status.idle": "2022-04-02T16:51:21.923079Z",
     "shell.execute_reply": "2022-04-02T16:51:21.922842Z",
     "shell.execute_reply.started": "2022-04-02T16:51:21.920379Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 12, 4])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K.shape\n",
    "#[batch_size,num_heads, key_len, head_dim ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <font color = 'blue'> **Step3: Scaled dot product of Queries and Keys**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T16:51:21.923554Z",
     "iopub.status.busy": "2022-04-02T16:51:21.923440Z",
     "iopub.status.idle": "2022-04-02T16:51:21.925879Z",
     "shell.execute_reply": "2022-04-02T16:51:21.925636Z",
     "shell.execute_reply.started": "2022-04-02T16:51:21.923541Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "scale = torch.sqrt(torch.FloatTensor([head_dim])).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T16:51:21.926363Z",
     "iopub.status.busy": "2022-04-02T16:51:21.926248Z",
     "iopub.status.idle": "2022-04-02T16:51:21.930259Z",
     "shell.execute_reply": "2022-04-02T16:51:21.930004Z",
     "shell.execute_reply.started": "2022-04-02T16:51:21.926350Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "energy = torch.matmul(Q, K.permute(0, 1, 3, 2)) / scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T16:51:21.930780Z",
     "iopub.status.busy": "2022-04-02T16:51:21.930661Z",
     "iopub.status.idle": "2022-04-02T16:51:21.933243Z",
     "shell.execute_reply": "2022-04-02T16:51:21.933004Z",
     "shell.execute_reply.started": "2022-04-02T16:51:21.930767Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 12, 12])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "energy.shape\n",
    "#[batch_size, num_heads, query_len, key_len]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-06T06:32:28.398682Z",
     "iopub.status.busy": "2022-03-06T06:32:28.398556Z",
     "iopub.status.idle": "2022-03-06T06:32:28.401868Z",
     "shell.execute_reply": "2022-03-06T06:32:28.401405Z",
     "shell.execute_reply.started": "2022-03-06T06:32:28.398668Z"
    }
   },
   "source": [
    "##### <font color = 'blue'> **Step4: Apply mask to output of Q, K dot product**</font><br>\n",
    "<font color = 'green'>**We do not want tokens to pay attention to pad tokens**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T16:51:21.934967Z",
     "iopub.status.busy": "2022-04-02T16:51:21.934846Z",
     "iopub.status.idle": "2022-04-02T16:51:21.937299Z",
     "shell.execute_reply": "2022-04-02T16:51:21.937053Z",
     "shell.execute_reply.started": "2022-04-02T16:51:21.934954Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SRC_PAD_IDX = source_vocab['<PAD>']\n",
    "SRC_PAD_IDX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T16:51:21.937850Z",
     "iopub.status.busy": "2022-04-02T16:51:21.937729Z",
     "iopub.status.idle": "2022-04-02T16:51:21.941032Z",
     "shell.execute_reply": "2022-04-02T16:51:21.940784Z",
     "shell.execute_reply.started": "2022-04-02T16:51:21.937837Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True],\n",
       "        [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         False, False]], device='cuda:0')"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src_mask = (src!= SRC_PAD_IDX )\n",
    "src_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T16:51:21.941598Z",
     "iopub.status.busy": "2022-04-02T16:51:21.941479Z",
     "iopub.status.idle": "2022-04-02T16:51:21.944578Z",
     "shell.execute_reply": "2022-04-02T16:51:21.944336Z",
     "shell.execute_reply.started": "2022-04-02T16:51:21.941586Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 12])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T16:51:21.945122Z",
     "iopub.status.busy": "2022-04-02T16:51:21.945003Z",
     "iopub.status.idle": "2022-04-02T16:51:21.947247Z",
     "shell.execute_reply": "2022-04-02T16:51:21.946997Z",
     "shell.execute_reply.started": "2022-04-02T16:51:21.945109Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "src_mask = src_mask.unsqueeze(1).unsqueeze(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T16:51:21.947774Z",
     "iopub.status.busy": "2022-04-02T16:51:21.947657Z",
     "iopub.status.idle": "2022-04-02T16:51:21.950611Z",
     "shell.execute_reply": "2022-04-02T16:51:21.950337Z",
     "shell.execute_reply.started": "2022-04-02T16:51:21.947761Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 1, 12])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T16:51:21.951166Z",
     "iopub.status.busy": "2022-04-02T16:51:21.951049Z",
     "iopub.status.idle": "2022-04-02T16:51:21.953460Z",
     "shell.execute_reply": "2022-04-02T16:51:21.953217Z",
     "shell.execute_reply.started": "2022-04-02T16:51:21.951153Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "src_mask = src_mask.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T16:51:21.954045Z",
     "iopub.status.busy": "2022-04-02T16:51:21.953848Z",
     "iopub.status.idle": "2022-04-02T16:51:21.958525Z",
     "shell.execute_reply": "2022-04-02T16:51:21.957995Z",
     "shell.execute_reply.started": "2022-04-02T16:51:21.954033Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "energy_masked = energy.masked_fill(src_mask == 0, -1e10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = 'red'>**Print energy values for second sentence**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color ='green'> **We can see below that for the last two tokens (pad tokens) energy has a very high negative value.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T16:51:21.959218Z",
     "iopub.status.busy": "2022-04-02T16:51:21.959077Z",
     "iopub.status.idle": "2022-04-02T16:51:21.964290Z",
     "shell.execute_reply": "2022-04-02T16:51:21.963995Z",
     "shell.execute_reply.started": "2022-04-02T16:51:21.959200Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-1.0000e+10, device='cuda:0') tensor(-1.0000e+10, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(energy_masked[1,1,1,10].data, energy_masked[1,1,1,11].data)\n",
    "      \n",
    "#[batch_size, num_heads, query_len, key_len]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T16:51:21.964913Z",
     "iopub.status.busy": "2022-04-02T16:51:21.964757Z",
     "iopub.status.idle": "2022-04-02T16:51:21.967932Z",
     "shell.execute_reply": "2022-04-02T16:51:21.967644Z",
     "shell.execute_reply.started": "2022-04-02T16:51:21.964899Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-1.0000e+10, device='cuda:0') tensor(-1.0000e+10, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(energy_masked[1,0,5,10].data, energy_masked[1,0,5,11].data)\n",
    "      \n",
    "#[batch_size, num_heads, query_len, key_len]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-06T06:40:33.100053Z",
     "iopub.status.busy": "2022-03-06T06:40:33.099853Z",
     "iopub.status.idle": "2022-03-06T06:40:33.103065Z",
     "shell.execute_reply": "2022-03-06T06:40:33.102543Z",
     "shell.execute_reply.started": "2022-03-06T06:40:33.100033Z"
    }
   },
   "source": [
    "<font color = 'green'> **We are not ignoring pad tokens completely - we are ignoring pad tokens in keys but not in queries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T16:51:21.968497Z",
     "iopub.status.busy": "2022-04-02T16:51:21.968375Z",
     "iopub.status.idle": "2022-04-02T16:51:21.972241Z",
     "shell.execute_reply": "2022-04-02T16:51:21.971973Z",
     "shell.execute_reply.started": "2022-04-02T16:51:21.968484Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-3.0029, device='cuda:0') tensor(-1.2690, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(energy_masked[1,0,10,1].data, energy_masked[1,0,11,1].data)      \n",
    "#[batch_size, num_heads, query_len, key_len]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-06T06:19:41.356628Z",
     "iopub.status.busy": "2022-03-06T06:19:41.356490Z",
     "iopub.status.idle": "2022-03-06T06:19:41.359837Z",
     "shell.execute_reply": "2022-03-06T06:19:41.359442Z",
     "shell.execute_reply.started": "2022-03-06T06:19:41.356616Z"
    }
   },
   "source": [
    "<font color = 'green'>**Print energy values for first sentence**</font>\n",
    "<font color = 'green'> **There are no pad tokens for the first sentence**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T16:51:21.972814Z",
     "iopub.status.busy": "2022-04-02T16:51:21.972695Z",
     "iopub.status.idle": "2022-04-02T16:51:21.976993Z",
     "shell.execute_reply": "2022-04-02T16:51:21.976681Z",
     "shell.execute_reply.started": "2022-04-02T16:51:21.972801Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-1.5125, device='cuda:0') tensor(-0.4217, device='cuda:0') tensor(-0.7463, device='cuda:0') tensor(-1.1680, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(energy_masked[0,0,5,10].data, energy_masked[0,1,5,11].data, \n",
    "      energy_masked[0,0,10,5].data, energy_masked[0,1,11,5].data)\n",
    "#[batch_size, num_heads, query_len, key_len]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-06T18:33:44.838351Z",
     "iopub.status.busy": "2022-03-06T18:33:44.838200Z",
     "iopub.status.idle": "2022-03-06T18:33:44.840959Z",
     "shell.execute_reply": "2022-03-06T18:33:44.840599Z",
     "shell.execute_reply.started": "2022-03-06T18:33:44.838337Z"
    }
   },
   "source": [
    "##### <font color = 'blue'>**Step 5: Apply softmax to convert QV dot product to probabilities**</font><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T16:51:21.977592Z",
     "iopub.status.busy": "2022-04-02T16:51:21.977466Z",
     "iopub.status.idle": "2022-04-02T16:51:21.979738Z",
     "shell.execute_reply": "2022-04-02T16:51:21.979487Z",
     "shell.execute_reply.started": "2022-04-02T16:51:21.977578Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "attention_prob = torch.softmax(energy_masked, dim = -1)                 \n",
    "#attention_prob = [batch size, n heads, query len, key len]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color ='green'> **Query will not pay attention to last two tokens in the Key as these has zero attention probabilities. The last two tokens were pad tokens. Teh softmax for very high negative values is zero**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T16:51:21.980310Z",
     "iopub.status.busy": "2022-04-02T16:51:21.980199Z",
     "iopub.status.idle": "2022-04-02T16:51:21.983079Z",
     "shell.execute_reply": "2022-04-02T16:51:21.982764Z",
     "shell.execute_reply.started": "2022-04-02T16:51:21.980298Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0., device='cuda:0') tensor(0., device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(attention_prob [1,1,1,10].data, attention_prob [1,1,1,11].data)\n",
    "#[batch_size, num_heads, query_len, key_len]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color ='green'> **We do not obseve zero probabilites for the first senence as it has no pad tokens**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T16:51:21.983655Z",
     "iopub.status.busy": "2022-04-02T16:51:21.983542Z",
     "iopub.status.idle": "2022-04-02T16:51:21.986992Z",
     "shell.execute_reply": "2022-04-02T16:51:21.986739Z",
     "shell.execute_reply.started": "2022-04-02T16:51:21.983643Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([7.9895e-03, 3.0690e-02, 1.1646e-05, 2.0567e-03, 2.4597e-03, 6.2799e-01,\n",
      "        2.9352e-02, 1.9576e-03, 4.1289e-03, 2.9197e-01, 1.3934e-03, 1.5670e-06],\n",
      "       device='cuda:0', grad_fn=<SliceBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(attention_prob[0, 1,1, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T16:51:21.988368Z",
     "iopub.status.busy": "2022-04-02T16:51:21.988100Z",
     "iopub.status.idle": "2022-04-02T16:51:21.990998Z",
     "shell.execute_reply": "2022-04-02T16:51:21.990748Z",
     "shell.execute_reply.started": "2022-04-02T16:51:21.988355Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([8.5804e-03, 1.7263e-02, 2.7257e-05, 1.6996e-03, 7.9512e-04, 1.5986e-02,\n",
      "        6.9464e-03, 2.9713e-03, 3.5198e-02, 9.0983e-01, 6.8868e-04, 1.1910e-05],\n",
      "       device='cuda:0', grad_fn=<SliceBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(attention_prob[0, 0,1, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T16:51:21.991562Z",
     "iopub.status.busy": "2022-04-02T16:51:21.991446Z",
     "iopub.status.idle": "2022-04-02T16:51:21.994931Z",
     "shell.execute_reply": "2022-04-02T16:51:21.994686Z",
     "shell.execute_reply.started": "2022-04-02T16:51:21.991550Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1., device='cuda:0', grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_prob[0, 0,1, :].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-06T17:49:26.353174Z",
     "iopub.status.busy": "2022-03-06T17:49:26.353003Z",
     "iopub.status.idle": "2022-03-06T17:49:26.356619Z",
     "shell.execute_reply": "2022-03-06T17:49:26.356140Z",
     "shell.execute_reply.started": "2022-03-06T17:49:26.353143Z"
    }
   },
   "source": [
    "##### <font color = 'blue'>**Step 6: Apply dropout layer to attention probabilities**</font><br>\n",
    "<font color = 'red'>**NOT UNDERSTOOD- why apply dropout here (probs will not sum to 1)**</font><br>\n",
    "<font color = 'green'>**Quotes from paper --We apply dropout [33] to the output of each sub-layer, before it is added to the sub-layer input and normalized.**</font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T16:51:22.009535Z",
     "iopub.status.busy": "2022-04-02T16:51:22.009349Z",
     "iopub.status.idle": "2022-04-02T16:51:22.012316Z",
     "shell.execute_reply": "2022-04-02T16:51:22.011955Z",
     "shell.execute_reply.started": "2022-04-02T16:51:22.009512Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "att_enc_dropout =  nn.Dropout(p=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T16:51:22.037987Z",
     "iopub.status.busy": "2022-04-02T16:51:22.037860Z",
     "iopub.status.idle": "2022-04-02T16:51:22.040471Z",
     "shell.execute_reply": "2022-04-02T16:51:22.040080Z",
     "shell.execute_reply.started": "2022-04-02T16:51:22.037972Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "attention_prob_after_dropout = att_enc_dropout(attention_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T16:51:22.067364Z",
     "iopub.status.busy": "2022-04-02T16:51:22.067237Z",
     "iopub.status.idle": "2022-04-02T16:51:22.070779Z",
     "shell.execute_reply": "2022-04-02T16:51:22.070463Z",
     "shell.execute_reply.started": "2022-04-02T16:51:22.067350Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0000e+00, 1.9181e-02, 3.0286e-05, 1.8884e-03, 0.0000e+00, 1.7762e-02,\n",
      "        7.7182e-03, 3.3015e-03, 3.9109e-02, 1.0109e+00, 7.6521e-04, 1.3233e-05],\n",
      "       device='cuda:0', grad_fn=<SliceBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(attention_prob_after_dropout [0, 0,1, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T16:51:22.140406Z",
     "iopub.status.busy": "2022-04-02T16:51:22.140224Z",
     "iopub.status.idle": "2022-04-02T16:51:22.145187Z",
     "shell.execute_reply": "2022-04-02T16:51:22.144759Z",
     "shell.execute_reply.started": "2022-04-02T16:51:22.140385Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.1007, device='cuda:0', grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_prob_after_dropout[0, 0,1, :].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-06T18:30:59.789080Z",
     "iopub.status.busy": "2022-03-06T18:30:59.788942Z",
     "iopub.status.idle": "2022-03-06T18:30:59.792284Z",
     "shell.execute_reply": "2022-03-06T18:30:59.791922Z",
     "shell.execute_reply.started": "2022-03-06T18:30:59.789068Z"
    },
    "tags": []
   },
   "source": [
    "<font size = 3, color = 'red'>**Probs do not sum to 1, sometimes these are greater than one and sometimes these are less than one**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <font color = 'blue'>**Step 7: Apply the attention to the value heads**</font><br>\n",
    "<font size = 3, color = 'green'>**Final vectors are wighted sum of values. This gives us the final embeddings afer considering the context words. These represent the contextualized embeddings for the tokens**</font><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T16:51:22.188809Z",
     "iopub.status.busy": "2022-04-02T16:51:22.188683Z",
     "iopub.status.idle": "2022-04-02T16:51:22.191442Z",
     "shell.execute_reply": "2022-04-02T16:51:22.191143Z",
     "shell.execute_reply.started": "2022-04-02T16:51:22.188795Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 12, 4])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "V.shape\n",
    "# [batch_size, num_heads, value_len, head_dim]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T16:51:22.218663Z",
     "iopub.status.busy": "2022-04-02T16:51:22.218446Z",
     "iopub.status.idle": "2022-04-02T16:51:22.221256Z",
     "shell.execute_reply": "2022-04-02T16:51:22.221003Z",
     "shell.execute_reply.started": "2022-04-02T16:51:22.218648Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 12, 12])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_prob_after_dropout.shape\n",
    "#[batch_size, num_heads, query_len, key_len]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-06T20:32:06.562614Z",
     "iopub.status.busy": "2022-03-06T20:32:06.562473Z",
     "iopub.status.idle": "2022-03-06T20:32:06.565543Z",
     "shell.execute_reply": "2022-03-06T20:32:06.565175Z",
     "shell.execute_reply.started": "2022-03-06T20:32:06.562601Z"
    }
   },
   "source": [
    "<font size = 3, color = 'green'>**NOTE: key_len will be same as value_len**.<br>\n",
    "\n",
    "<font size = 3, color = 'green'>\n",
    "    \n",
    "- Query comes from focal word (sentence), keys and values are from context.\n",
    "- In self attention both focal words and context are based on same sentence and hence same length.\n",
    "- In encoder-decoder attention of machine translation - focal word is target sentence and context word comes from source language. Hence queries are generated from target language. Whereas keys and values are generated from source language. We are trying to find which focal word in target language should pay attention to which words in source language.\n",
    "\n",
    "<font size = 3, color = 'red'>**Not Understood** - Since keys and values both capture context, why can we not use same matrix for Values and Keys i.e fc_k = fc_v. This is exacyly what we did in seq2seq paper with attention (without self attention). The source vectors were used both as keys and values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T16:51:22.297129Z",
     "iopub.status.busy": "2022-04-02T16:51:22.297005Z",
     "iopub.status.idle": "2022-04-02T16:51:22.299476Z",
     "shell.execute_reply": "2022-04-02T16:51:22.299100Z",
     "shell.execute_reply.started": "2022-04-02T16:51:22.297116Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# We can do this batch multiplication of the matrices of shape \n",
    "# [query_len, key_len] and [value_len, head_dim] as key_len = value_len\n",
    "encoder_self_att_output = torch.matmul(attention_prob_after_dropout, V)\n",
    "#[batch_size, num_heads, query_len, head_dim]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T16:51:22.310239Z",
     "iopub.status.busy": "2022-04-02T16:51:22.310118Z",
     "iopub.status.idle": "2022-04-02T16:51:22.312927Z",
     "shell.execute_reply": "2022-04-02T16:51:22.312664Z",
     "shell.execute_reply.started": "2022-04-02T16:51:22.310225Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 12, 4])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_self_att_output.shape\n",
    "# [batch_size, number_of_heads, query_len, head_dim]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T16:51:22.339379Z",
     "iopub.status.busy": "2022-04-02T16:51:22.339226Z",
     "iopub.status.idle": "2022-04-02T16:51:22.341709Z",
     "shell.execute_reply": "2022-04-02T16:51:22.341439Z",
     "shell.execute_reply.started": "2022-04-02T16:51:22.339364Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "encoder_self_att_output = encoder_self_att_output.permute(0, 2, 1, 3)\n",
    "# [batch_size, query_len, number_of_heads, head_dim]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T16:51:22.368554Z",
     "iopub.status.busy": "2022-04-02T16:51:22.368430Z",
     "iopub.status.idle": "2022-04-02T16:51:22.371350Z",
     "shell.execute_reply": "2022-04-02T16:51:22.371070Z",
     "shell.execute_reply.started": "2022-04-02T16:51:22.368540Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 12, 3, 4])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_self_att_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T16:51:22.450793Z",
     "iopub.status.busy": "2022-04-02T16:51:22.450445Z",
     "iopub.status.idle": "2022-04-02T16:51:22.568960Z",
     "shell.execute_reply": "2022-04-02T16:51:22.568416Z",
     "shell.execute_reply.started": "2022-04-02T16:51:22.450777Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_5752/20175146.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mencoder_self_att_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_self_att_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_hid_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead."
     ]
    }
   ],
   "source": [
    "encoder_self_att_output = encoder_self_att_output.view(batch_size, -1, out_hid_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We cannot use .view because the tensor is no londer contiguous. We can use reshape which will create a copy and make a contiguous tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T16:52:27.018095Z",
     "iopub.status.busy": "2022-04-02T16:52:27.017953Z",
     "iopub.status.idle": "2022-04-02T16:52:27.035443Z",
     "shell.execute_reply": "2022-04-02T16:52:27.034990Z",
     "shell.execute_reply.started": "2022-04-02T16:52:27.018081Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "encoder_self_att_output = encoder_self_att_output.reshape(batch_size, -1, out_hid_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T16:52:27.782706Z",
     "iopub.status.busy": "2022-04-02T16:52:27.782461Z",
     "iopub.status.idle": "2022-04-02T16:52:27.785578Z",
     "shell.execute_reply": "2022-04-02T16:52:27.785245Z",
     "shell.execute_reply.started": "2022-04-02T16:52:27.782690Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 12, 12])"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_self_att_output.shape\n",
    "#[batch_size, query_len, out_hid_dim]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = 3, color = 'green'>We need to project the final values to have same shape as  input embedding. To accomplish this we will use fc_o linear layer we created earlier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <font color = 'blue'>**Step 8: Apply the linear layer to get the output representaion as hid_dim**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T16:52:29.497619Z",
     "iopub.status.busy": "2022-04-02T16:52:29.497481Z",
     "iopub.status.idle": "2022-04-02T16:52:29.500043Z",
     "shell.execute_reply": "2022-04-02T16:52:29.499677Z",
     "shell.execute_reply.started": "2022-04-02T16:52:29.497606Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "encoder_self_att_output = fc_o(encoder_self_att_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T16:52:30.040533Z",
     "iopub.status.busy": "2022-04-02T16:52:30.040267Z",
     "iopub.status.idle": "2022-04-02T16:52:30.043569Z",
     "shell.execute_reply": "2022-04-02T16:52:30.043231Z",
     "shell.execute_reply.started": "2022-04-02T16:52:30.040512Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 12, 8])"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_self_att_output.shape\n",
    "#[batch_size, query_len, hid_dim]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T16:52:30.249170Z",
     "iopub.status.busy": "2022-04-02T16:52:30.249029Z",
     "iopub.status.idle": "2022-04-02T16:52:30.252613Z",
     "shell.execute_reply": "2022-04-02T16:52:30.252251Z",
     "shell.execute_reply.started": "2022-04-02T16:52:30.249157Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.1231, -0.9036,  0.3362,  0.6744,  0.0063, -0.5722, -0.7662, -0.7788],\n",
       "       device='cuda:0', grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_self_att_output[0,0,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-07T00:06:41.510426Z",
     "iopub.status.busy": "2022-03-07T00:06:41.510268Z",
     "iopub.status.idle": "2022-03-07T00:06:41.513328Z",
     "shell.execute_reply": "2022-03-07T00:06:41.512871Z",
     "shell.execute_reply.started": "2022-03-07T00:06:41.510413Z"
    }
   },
   "source": [
    "<font  size =3, color ='green'>**Implementing MultiHeadAttention using Pytorch Layer**\n",
    "Limitation: hid_dim = output_hid_dim. Moved to separate notebook    \n",
    "if hid_dim = output_hid_dim , we can use torch.nn.MultiheadAttention for attention sublayer </font>\n",
    "**See the Appendix**\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-12T04:10:24.958984Z",
     "iopub.status.busy": "2022-03-12T04:10:24.958838Z",
     "iopub.status.idle": "2022-03-12T04:10:24.961460Z",
     "shell.execute_reply": "2022-03-12T04:10:24.961179Z",
     "shell.execute_reply.started": "2022-03-12T04:10:24.958969Z"
    }
   },
   "source": [
    "##### <font color = 'blue'>**Step 9: Apply dropout**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T16:52:30.896030Z",
     "iopub.status.busy": "2022-04-02T16:52:30.895887Z",
     "iopub.status.idle": "2022-04-02T16:52:30.898775Z",
     "shell.execute_reply": "2022-04-02T16:52:30.898374Z",
     "shell.execute_reply.started": "2022-04-02T16:52:30.896017Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "encoder_self_attn_dropout = nn.Dropout(p=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T16:52:31.090453Z",
     "iopub.status.busy": "2022-04-02T16:52:31.090285Z",
     "iopub.status.idle": "2022-04-02T16:52:31.093148Z",
     "shell.execute_reply": "2022-04-02T16:52:31.092755Z",
     "shell.execute_reply.started": "2022-04-02T16:52:31.090438Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "encoder_self_att_output_after_dropout = encoder_self_attn_dropout(encoder_self_att_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <font color = 'blue'>**Step 10 Add input to output of the sublayer**</font><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T16:52:31.691806Z",
     "iopub.status.busy": "2022-04-02T16:52:31.691637Z",
     "iopub.status.idle": "2022-04-02T16:52:31.694423Z",
     "shell.execute_reply": "2022-04-02T16:52:31.694149Z",
     "shell.execute_reply.started": "2022-04-02T16:52:31.691777Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "encoder_self_att_output_plus_input = encoder_input_after_dropout + encoder_self_att_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T16:52:31.856297Z",
     "iopub.status.busy": "2022-04-02T16:52:31.856173Z",
     "iopub.status.idle": "2022-04-02T16:52:31.859460Z",
     "shell.execute_reply": "2022-04-02T16:52:31.859118Z",
     "shell.execute_reply.started": "2022-04-02T16:52:31.856282Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 12, 8])"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_self_att_output_plus_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T16:52:32.360982Z",
     "iopub.status.busy": "2022-04-02T16:52:32.360825Z",
     "iopub.status.idle": "2022-04-02T16:52:32.364655Z",
     "shell.execute_reply": "2022-04-02T16:52:32.364304Z",
     "shell.execute_reply.started": "2022-04-02T16:52:32.360954Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.0798, -4.8025, -5.0172,  0.1274, -0.6700,  0.8240,  5.5056,  1.9648],\n",
       "       device='cuda:0', grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first sentence first worrd, all dimensions\n",
    "encoder_self_att_output_plus_input[0, 1, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-06T21:57:52.730819Z",
     "iopub.status.busy": "2022-03-06T21:57:52.730679Z",
     "iopub.status.idle": "2022-03-06T21:57:52.733204Z",
     "shell.execute_reply": "2022-03-06T21:57:52.732842Z",
     "shell.execute_reply.started": "2022-03-06T21:57:52.730806Z"
    }
   },
   "source": [
    "##### <font color = 'blue'>**Step 11: Normalize Encoder Output**</font><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T16:52:33.233822Z",
     "iopub.status.busy": "2022-04-02T16:52:33.233632Z",
     "iopub.status.idle": "2022-04-02T16:52:33.236578Z",
     "shell.execute_reply": "2022-04-02T16:52:33.236196Z",
     "shell.execute_reply.started": "2022-04-02T16:52:33.233806Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "norm_layer_encoder_attention = nn.LayerNorm(hid_dim).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T16:52:33.237326Z",
     "iopub.status.busy": "2022-04-02T16:52:33.237181Z",
     "iopub.status.idle": "2022-04-02T16:52:33.242452Z",
     "shell.execute_reply": "2022-04-02T16:52:33.242127Z",
     "shell.execute_reply.started": "2022-04-02T16:52:33.237314Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "encoder_self_att_output_plus_input_normalized = norm_layer_encoder_attention(encoder_self_att_output_plus_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T16:52:33.243120Z",
     "iopub.status.busy": "2022-04-02T16:52:33.242980Z",
     "iopub.status.idle": "2022-04-02T16:52:33.247166Z",
     "shell.execute_reply": "2022-04-02T16:52:33.246886Z",
     "shell.execute_reply.started": "2022-04-02T16:52:33.243106Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.3700, -1.4389, -1.5049,  0.0772, -0.1681,  0.2914,  1.7310,  0.6422],\n",
       "       device='cuda:0', grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_self_att_output_plus_input_normalized[0, 1, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-06T22:20:58.525267Z",
     "iopub.status.busy": "2022-03-06T22:20:58.525113Z",
     "iopub.status.idle": "2022-03-06T22:20:58.527846Z",
     "shell.execute_reply": "2022-03-06T22:20:58.527424Z",
     "shell.execute_reply.started": "2022-03-06T22:20:58.525255Z"
    }
   },
   "source": [
    "<font color = 'green'>**Norm Layer Manual Calculations for one word**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T16:52:33.824059Z",
     "iopub.status.busy": "2022-04-02T16:52:33.823900Z",
     "iopub.status.idle": "2022-04-02T16:52:33.828495Z",
     "shell.execute_reply": "2022-04-02T16:52:33.828107Z",
     "shell.execute_reply.started": "2022-04-02T16:52:33.824044Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight tensor([1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0')\n",
      "bias tensor([0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "for name, param in norm_layer_encoder_attention.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name, param.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T16:52:34.005823Z",
     "iopub.status.busy": "2022-04-02T16:52:34.005682Z",
     "iopub.status.idle": "2022-04-02T16:52:34.009565Z",
     "shell.execute_reply": "2022-04-02T16:52:34.009287Z",
     "shell.execute_reply.started": "2022-04-02T16:52:34.005810Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "_mean = torch.mean(encoder_self_att_output_plus_input[0, 1, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T16:52:34.212338Z",
     "iopub.status.busy": "2022-04-02T16:52:34.212123Z",
     "iopub.status.idle": "2022-04-02T16:52:34.215333Z",
     "shell.execute_reply": "2022-04-02T16:52:34.214911Z",
     "shell.execute_reply.started": "2022-04-02T16:52:34.212306Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "_std = torch.std(encoder_self_att_output_plus_input[0, 1, :], unbiased= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T16:52:34.438081Z",
     "iopub.status.busy": "2022-04-02T16:52:34.437943Z",
     "iopub.status.idle": "2022-04-02T16:52:34.440741Z",
     "shell.execute_reply": "2022-04-02T16:52:34.440210Z",
     "shell.execute_reply.started": "2022-04-02T16:52:34.438068Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "nl_w = norm_layer_encoder_attention.weight\n",
    "nl_b = norm_layer_encoder_attention.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T16:52:34.641938Z",
     "iopub.status.busy": "2022-04-02T16:52:34.641809Z",
     "iopub.status.idle": "2022-04-02T16:52:34.644569Z",
     "shell.execute_reply": "2022-04-02T16:52:34.644274Z",
     "shell.execute_reply.started": "2022-04-02T16:52:34.641925Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "encoder_attention_output_normalized_manual =  nl_b + nl_w * (encoder_self_att_output_plus_input[0, 1, :]-_mean)/_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T16:52:34.858906Z",
     "iopub.status.busy": "2022-04-02T16:52:34.858733Z",
     "iopub.status.idle": "2022-04-02T16:52:34.862681Z",
     "shell.execute_reply": "2022-04-02T16:52:34.862337Z",
     "shell.execute_reply.started": "2022-04-02T16:52:34.858892Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.3700, -1.4389, -1.5049,  0.0772, -0.1681,  0.2914,  1.7310,  0.6422],\n",
       "       device='cuda:0', grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_attention_output_normalized_manual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color = 'blue'> **Positionwise FeedForward Layer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T16:52:35.209909Z",
     "iopub.status.busy": "2022-04-02T16:52:35.209765Z",
     "iopub.status.idle": "2022-04-02T16:52:35.213679Z",
     "shell.execute_reply": "2022-04-02T16:52:35.213209Z",
     "shell.execute_reply.started": "2022-04-02T16:52:35.209894Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "pf_dim = 16\n",
    "enc_positionwise_feed_forward_layer = nn.Sequential(nn.Linear(hid_dim, pf_dim),\n",
    "                                nn.ReLU(),\n",
    "                                nn.Dropout(p=0.1),\n",
    "                                nn.Linear(pf_dim, hid_dim)).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T16:52:35.413486Z",
     "iopub.status.busy": "2022-04-02T16:52:35.413359Z",
     "iopub.status.idle": "2022-04-02T16:52:35.417245Z",
     "shell.execute_reply": "2022-04-02T16:52:35.416886Z",
     "shell.execute_reply.started": "2022-04-02T16:52:35.413472Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "enc_positionwise_output = enc_positionwise_feed_forward_layer(encoder_self_att_output_plus_input_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T16:52:35.597609Z",
     "iopub.status.busy": "2022-04-02T16:52:35.597456Z",
     "iopub.status.idle": "2022-04-02T16:52:35.600785Z",
     "shell.execute_reply": "2022-04-02T16:52:35.600434Z",
     "shell.execute_reply.started": "2022-04-02T16:52:35.597595Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 12, 8])"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_positionwise_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T16:52:35.808524Z",
     "iopub.status.busy": "2022-04-02T16:52:35.808399Z",
     "iopub.status.idle": "2022-04-02T16:52:35.811219Z",
     "shell.execute_reply": "2022-04-02T16:52:35.810766Z",
     "shell.execute_reply.started": "2022-04-02T16:52:35.808510Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "enc_dropout_positionwise =  nn.Dropout(p=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T16:52:36.023639Z",
     "iopub.status.busy": "2022-04-02T16:52:36.023434Z",
     "iopub.status.idle": "2022-04-02T16:52:36.025605Z",
     "shell.execute_reply": "2022-04-02T16:52:36.025342Z",
     "shell.execute_reply.started": "2022-04-02T16:52:36.023622Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "enc_positionwise_output_after_dropout = enc_dropout_positionwise(enc_positionwise_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T16:52:36.220004Z",
     "iopub.status.busy": "2022-04-02T16:52:36.219879Z",
     "iopub.status.idle": "2022-04-02T16:52:36.222763Z",
     "shell.execute_reply": "2022-04-02T16:52:36.222371Z",
     "shell.execute_reply.started": "2022-04-02T16:52:36.219991Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "norm_layer_encoder_positionwise = nn.LayerNorm(hid_dim).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T16:52:36.422862Z",
     "iopub.status.busy": "2022-04-02T16:52:36.422474Z",
     "iopub.status.idle": "2022-04-02T16:52:36.425630Z",
     "shell.execute_reply": "2022-04-02T16:52:36.425095Z",
     "shell.execute_reply.started": "2022-04-02T16:52:36.422832Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "encoder_layer_output = enc_positionwise_feed_forward_layer(\n",
    "                        enc_positionwise_output_after_dropout + \n",
    "                        encoder_self_att_output_plus_input_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T16:52:36.604575Z",
     "iopub.status.busy": "2022-04-02T16:52:36.604381Z",
     "iopub.status.idle": "2022-04-02T16:52:36.607725Z",
     "shell.execute_reply": "2022-04-02T16:52:36.607415Z",
     "shell.execute_reply.started": "2022-04-02T16:52:36.604548Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 12, 8])"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_layer_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T16:52:36.777306Z",
     "iopub.status.busy": "2022-04-02T16:52:36.777183Z",
     "iopub.status.idle": "2022-04-02T16:52:36.780109Z",
     "shell.execute_reply": "2022-04-02T16:52:36.779842Z",
     "shell.execute_reply.started": "2022-04-02T16:52:36.777292Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_layer_output.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-06T22:39:52.086759Z",
     "iopub.status.busy": "2022-03-06T22:39:52.086621Z",
     "iopub.status.idle": "2022-03-06T22:39:52.088991Z",
     "shell.execute_reply": "2022-03-06T22:39:52.088580Z",
     "shell.execute_reply.started": "2022-03-06T22:39:52.086746Z"
    }
   },
   "source": [
    "## <font color = 'blue'> Decoder Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color = 'blue'> Decoder Self Attention Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned previously, the decoder layer is similar to the encoder layer except that it now has two multi-head attention layers, `self_attention` and `encoder_attention`. \n",
    "\n",
    "The first performs self-attention, as in the encoder, by using the decoder representation so far as the query, key and value. This is followed by dropout, residual connection and layer normalization. This `self_attention` layer uses the target sequence mask, `trg_mask`, in order to prevent the decoder from \"cheating\" by paying attention to tokens that are \"ahead\" of the one it is currently processing as it processes all tokens in the target sentence in parallel.\n",
    "\n",
    "The second is how we actually feed the encoded source sentence, `enc_src`, into our decoder. In this multi-head attention layer the queries are the decoder representations and the keys and values are the encoder representations. Here, the source mask, `src_mask` is used to prevent the multi-head attention layer from attending to `<pad>` tokens within the source sentence. This is then followed by the dropout, residual connection and layer normalization layers. \n",
    "\n",
    "Finally, we pass this through the position-wise feedforward layer and yet another sequence of dropout, residual connection and layer normalization.\n",
    "\n",
    "The decoder layer isn't introducing any new concepts, just using the same set of layers as the encoder in a slightly different way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-07T06:19:56.442785Z",
     "iopub.status.busy": "2022-03-07T06:19:56.442483Z",
     "iopub.status.idle": "2022-03-07T06:19:56.445103Z",
     "shell.execute_reply": "2022-03-07T06:19:56.444791Z",
     "shell.execute_reply.started": "2022-03-07T06:19:56.442683Z"
    }
   },
   "source": [
    "#### <font color = 'blue'> Multi Head Attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-07T00:06:41.510426Z",
     "iopub.status.busy": "2022-03-07T00:06:41.510268Z",
     "iopub.status.idle": "2022-03-07T00:06:41.513328Z",
     "shell.execute_reply": "2022-03-07T00:06:41.512871Z",
     "shell.execute_reply.started": "2022-03-07T00:06:41.510413Z"
    }
   },
   "source": [
    "<font  size =3, color ='green'>**Implementing MultiHeadAttention using Pytorch Layer**\n",
    "Limitation: hid_dim == output_hid_dim.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T16:52:37.970678Z",
     "iopub.status.busy": "2022-04-02T16:52:37.970507Z",
     "iopub.status.idle": "2022-04-02T16:52:37.973037Z",
     "shell.execute_reply": "2022-04-02T16:52:37.972764Z",
     "shell.execute_reply.started": "2022-04-02T16:52:37.970665Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "hid_dim = 8\n",
    "n_heads = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T16:52:38.169656Z",
     "iopub.status.busy": "2022-04-02T16:52:38.169506Z",
     "iopub.status.idle": "2022-04-02T16:52:38.173267Z",
     "shell.execute_reply": "2022-04-02T16:52:38.172938Z",
     "shell.execute_reply.started": "2022-04-02T16:52:38.169642Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "multihead_attnetion_layer = torch.nn.MultiheadAttention(embed_dim=hid_dim, num_heads=n_heads, \n",
    "                                                        dropout=0.0, \n",
    "                                                        bias=True, add_bias_kv=False, \n",
    "                                                        add_zero_attn=False, kdim=None, \n",
    "                                                        vdim=None, batch_first=True, \n",
    "                                                        device=device, dtype=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = 3, color = 'green'>It combines Q, Kand V into one metrics. To compare the results, we need to make sure that initial merices are the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T16:52:38.637967Z",
     "iopub.status.busy": "2022-04-02T16:52:38.637812Z",
     "iopub.status.idle": "2022-04-02T16:52:38.641064Z",
     "shell.execute_reply": "2022-04-02T16:52:38.640785Z",
     "shell.execute_reply.started": "2022-04-02T16:52:38.637952Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in_proj_weight torch.Size([24, 8])\n",
      "in_proj_bias torch.Size([24])\n",
      "out_proj.weight torch.Size([8, 8])\n",
      "out_proj.bias torch.Size([8])\n"
     ]
    }
   ],
   "source": [
    "for name, parameter in multihead_attnetion_layer.named_parameters():\n",
    "    print(name, parameter.data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T16:52:38.870460Z",
     "iopub.status.busy": "2022-04-02T16:52:38.870302Z",
     "iopub.status.idle": "2022-04-02T16:52:38.873490Z",
     "shell.execute_reply": "2022-04-02T16:52:38.873220Z",
     "shell.execute_reply.started": "2022-04-02T16:52:38.870446Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRG_PAD_IDX = target_vocab['<PAD>']\n",
    "TRG_PAD_IDX "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = 'green'> Index where we will apply mask i.e. not pay attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T16:52:39.221404Z",
     "iopub.status.busy": "2022-04-02T16:52:39.221223Z",
     "iopub.status.idle": "2022-04-02T16:52:39.223618Z",
     "shell.execute_reply": "2022-04-02T16:52:39.223343Z",
     "shell.execute_reply.started": "2022-04-02T16:52:39.221390Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "trg_pad_mask = (trg_in== TRG_PAD_IDX )\n",
    "trg_pad_mask=trg_pad_mask.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T16:52:39.420444Z",
     "iopub.status.busy": "2022-04-02T16:52:39.420245Z",
     "iopub.status.idle": "2022-04-02T16:52:39.424110Z",
     "shell.execute_reply": "2022-04-02T16:52:39.423750Z",
     "shell.execute_reply.started": "2022-04-02T16:52:39.420429Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False, False, False, False, False, False, False, False, False, False,\n",
       "         False,  True,  True],\n",
       "        [False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False]], device='cuda:0')"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trg_pad_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T16:52:39.620199Z",
     "iopub.status.busy": "2022-04-02T16:52:39.620011Z",
     "iopub.status.idle": "2022-04-02T16:52:39.622975Z",
     "shell.execute_reply": "2022-04-02T16:52:39.622709Z",
     "shell.execute_reply.started": "2022-04-02T16:52:39.620171Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 13])"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trg_pad_mask.shape\n",
    "# batchsize, seq_len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = 'green'> In deocoder a token can pay attention to only preceeding tokens. Hence we need to create a mask for all the tokens ahead for a goven token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T16:52:40.002020Z",
     "iopub.status.busy": "2022-04-02T16:52:40.001835Z",
     "iopub.status.idle": "2022-04-02T16:52:40.009747Z",
     "shell.execute_reply": "2022-04-02T16:52:40.009398Z",
     "shell.execute_reply.started": "2022-04-02T16:52:40.002005Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]], device='cuda:0')"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tril(torch.ones(trg_in.shape[1], trg_in.shape[1], device = device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T16:52:40.199527Z",
     "iopub.status.busy": "2022-04-02T16:52:40.199321Z",
     "iopub.status.idle": "2022-04-02T16:52:40.202127Z",
     "shell.execute_reply": "2022-04-02T16:52:40.201781Z",
     "shell.execute_reply.started": "2022-04-02T16:52:40.199511Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "trg_att_mask = ~torch.tril(torch.ones((trg_in.shape[1], trg_in.shape[1]), device = device)).bool()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T16:52:40.385221Z",
     "iopub.status.busy": "2022-04-02T16:52:40.385001Z",
     "iopub.status.idle": "2022-04-02T16:52:40.390580Z",
     "shell.execute_reply": "2022-04-02T16:52:40.390285Z",
     "shell.execute_reply.started": "2022-04-02T16:52:40.385186Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True],\n",
       "        [False, False,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True],\n",
       "        [False, False, False,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True],\n",
       "        [False, False, False, False,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True],\n",
       "        [False, False, False, False, False,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True],\n",
       "        [False, False, False, False, False, False,  True,  True,  True,  True,\n",
       "          True,  True,  True],\n",
       "        [False, False, False, False, False, False, False,  True,  True,  True,\n",
       "          True,  True,  True],\n",
       "        [False, False, False, False, False, False, False, False,  True,  True,\n",
       "          True,  True,  True],\n",
       "        [False, False, False, False, False, False, False, False, False,  True,\n",
       "          True,  True,  True],\n",
       "        [False, False, False, False, False, False, False, False, False, False,\n",
       "          True,  True,  True],\n",
       "        [False, False, False, False, False, False, False, False, False, False,\n",
       "         False,  True,  True],\n",
       "        [False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False,  True],\n",
       "        [False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False]], device='cuda:0')"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trg_att_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T16:52:40.582860Z",
     "iopub.status.busy": "2022-04-02T16:52:40.582667Z",
     "iopub.status.idle": "2022-04-02T16:52:40.586178Z",
     "shell.execute_reply": "2022-04-02T16:52:40.585907Z",
     "shell.execute_reply.started": "2022-04-02T16:52:40.582845Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "decoder_self_att_output, decoder_self_att_probs = multihead_attnetion_layer (\n",
    "                                              query=decoder_input_after_dropout, \n",
    "                                              key= decoder_input_after_dropout,\n",
    "                                              value= decoder_input_after_dropout, \n",
    "                                              key_padding_mask=trg_pad_mask, \n",
    "                                              need_weights=True, \n",
    "                                              attn_mask=trg_att_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T16:52:40.785828Z",
     "iopub.status.busy": "2022-04-02T16:52:40.785337Z",
     "iopub.status.idle": "2022-04-02T16:52:40.789316Z",
     "shell.execute_reply": "2022-04-02T16:52:40.788960Z",
     "shell.execute_reply.started": "2022-04-02T16:52:40.785793Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.4591, -0.7687,  0.4112, -0.3029, -0.4572,  0.3844,  0.5456, -0.5902],\n",
       "       device='cuda:0', grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_self_att_output[1,12,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = 3, color = 'green'> **First word in first sentence can pay attention to itself only**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T16:52:41.173901Z",
     "iopub.status.busy": "2022-04-02T16:52:41.173715Z",
     "iopub.status.idle": "2022-04-02T16:52:41.177448Z",
     "shell.execute_reply": "2022-04-02T16:52:41.177199Z",
     "shell.execute_reply.started": "2022-04-02T16:52:41.173887Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0',\n",
       "       grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_self_att_probs[0,0,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = 3, color = 'green'> **Second word in first sentence can pay attention to itself and previous word**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T16:52:41.584949Z",
     "iopub.status.busy": "2022-04-02T16:52:41.584766Z",
     "iopub.status.idle": "2022-04-02T16:52:41.588786Z",
     "shell.execute_reply": "2022-04-02T16:52:41.588260Z",
     "shell.execute_reply.started": "2022-04-02T16:52:41.584930Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.5225, 0.4775, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000], device='cuda:0',\n",
       "       grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_self_att_probs[0,1,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = 3, color = 'green'> **Last word in first sentence can pay attention to all the words except last two words as last three words are pad tokens**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T16:52:41.985932Z",
     "iopub.status.busy": "2022-04-02T16:52:41.985421Z",
     "iopub.status.idle": "2022-04-02T16:52:41.989289Z",
     "shell.execute_reply": "2022-04-02T16:52:41.988913Z",
     "shell.execute_reply.started": "2022-04-02T16:52:41.985914Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5.2618e-01, 2.7541e-07, 4.4419e-03, 1.1549e-10, 8.9900e-04, 7.2436e-05,\n",
       "        3.2480e-08, 3.0348e-07, 1.2610e-03, 1.3610e-05, 4.6713e-01, 0.0000e+00,\n",
       "        0.0000e+00], device='cuda:0', grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_self_att_probs[0,12,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = 3, color = 'green'> **Last word in second sentence can pay attention to all the words as this sentence has no pad tokens**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T16:52:42.381811Z",
     "iopub.status.busy": "2022-04-02T16:52:42.381687Z",
     "iopub.status.idle": "2022-04-02T16:52:42.386414Z",
     "shell.execute_reply": "2022-04-02T16:52:42.386153Z",
     "shell.execute_reply.started": "2022-04-02T16:52:42.381797Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0217, 0.0448, 0.1272, 0.0989, 0.0915, 0.1613, 0.2903, 0.0122, 0.0374,\n",
       "        0.0046, 0.0096, 0.0764, 0.0242], device='cuda:0',\n",
       "       grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_self_att_probs[1,12,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = 3, color = 'green'> **The probbalitoes sum to 1 as I have kept dropout = 0**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T16:52:42.765695Z",
     "iopub.status.busy": "2022-04-02T16:52:42.765549Z",
     "iopub.status.idle": "2022-04-02T16:52:42.770297Z",
     "shell.execute_reply": "2022-04-02T16:52:42.769864Z",
     "shell.execute_reply.started": "2022-04-02T16:52:42.765681Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1., device='cuda:0', grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_self_att_probs[1,12,:].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-10T01:00:05.138593Z",
     "iopub.status.busy": "2022-03-10T01:00:05.138451Z",
     "iopub.status.idle": "2022-03-10T01:00:05.140851Z",
     "shell.execute_reply": "2022-03-10T01:00:05.140545Z",
     "shell.execute_reply.started": "2022-03-10T01:00:05.138579Z"
    }
   },
   "source": [
    "#### <font color = 'blue'>  Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T16:52:47.495881Z",
     "iopub.status.busy": "2022-04-02T16:52:47.495740Z",
     "iopub.status.idle": "2022-04-02T16:52:47.498909Z",
     "shell.execute_reply": "2022-04-02T16:52:47.498434Z",
     "shell.execute_reply.started": "2022-04-02T16:52:47.495867Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "decoder_self_att_dropout = nn.Dropout(p=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color = 'blue'>  Residual Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T16:52:47.925792Z",
     "iopub.status.busy": "2022-04-02T16:52:47.925640Z",
     "iopub.status.idle": "2022-04-02T16:52:47.928932Z",
     "shell.execute_reply": "2022-04-02T16:52:47.928533Z",
     "shell.execute_reply.started": "2022-04-02T16:52:47.925779Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "decoder_self_att_output_after_dropout = decoder_self_att_dropout(decoder_self_att_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T16:52:48.143508Z",
     "iopub.status.busy": "2022-04-02T16:52:48.143321Z",
     "iopub.status.idle": "2022-04-02T16:52:48.146200Z",
     "shell.execute_reply": "2022-04-02T16:52:48.145798Z",
     "shell.execute_reply.started": "2022-04-02T16:52:48.143494Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "decoder_self_att_plus_input = decoder_input_after_dropout + \\\n",
    "                                  decoder_self_att_output_after_dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T16:52:48.335163Z",
     "iopub.status.busy": "2022-04-02T16:52:48.335021Z",
     "iopub.status.idle": "2022-04-02T16:52:48.338075Z",
     "shell.execute_reply": "2022-04-02T16:52:48.337790Z",
     "shell.execute_reply.started": "2022-04-02T16:52:48.335149Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 13, 8])"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_self_att_plus_input.shape\n",
    "#Batch_size, query_len, hid_dim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color = 'blue'>  Layer_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T16:52:48.727488Z",
     "iopub.status.busy": "2022-04-02T16:52:48.727347Z",
     "iopub.status.idle": "2022-04-02T16:52:48.730870Z",
     "shell.execute_reply": "2022-04-02T16:52:48.730581Z",
     "shell.execute_reply.started": "2022-04-02T16:52:48.727475Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dec_self_att_layer_norm= nn.LayerNorm(hid_dim).to(device)\n",
    "decoder_self_att_plus_input_normalized = dec_self_att_layer_norm(decoder_self_att_plus_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T16:52:48.928781Z",
     "iopub.status.busy": "2022-04-02T16:52:48.928620Z",
     "iopub.status.idle": "2022-04-02T16:52:48.931782Z",
     "shell.execute_reply": "2022-04-02T16:52:48.931508Z",
     "shell.execute_reply.started": "2022-04-02T16:52:48.928730Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 13, 8])"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_self_att_plus_input_normalized.shape\n",
    "#batch_size, query_len, hid_dim]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color = 'blue'> Decoder Encoder Attention Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned previously, the decoder layer is similar to the encoder layer except that it now has two multi-head attention layers, `self_attention` and `encoder_attention`. \n",
    "\n",
    "The first performs self-attention, as in the encoder, by using the decoder representation so far as the query, key and value. This is followed by dropout, residual connection and layer normalization. This `self_attention` layer uses the target sequence mask, `trg_mask`, in order to prevent the decoder from \"cheating\" by paying attention to tokens that are \"ahead\" of the one it is currently processing as it processes all tokens in the target sentence in parallel.\n",
    "\n",
    "The second is how we actually feed the encoded source sentence, `enc_src`, into our decoder. In this multi-head attention layer the queries are the decoder representations and the keys and values are the encoder representations. Here, the source mask, `src_mask` is used to prevent the multi-head attention layer from attending to `<pad>` tokens within the source sentence. This is then followed by the dropout, residual connection and layer normalization layers. \n",
    "\n",
    "Finally, we pass this through the position-wise feedforward layer and yet another sequence of dropout, residual connection and layer normalization.\n",
    "\n",
    "The decoder layer isn't introducing any new concepts, just using the same set of layers as the encoder in a slightly different way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-07T06:19:56.442785Z",
     "iopub.status.busy": "2022-03-07T06:19:56.442483Z",
     "iopub.status.idle": "2022-03-07T06:19:56.445103Z",
     "shell.execute_reply": "2022-03-07T06:19:56.444791Z",
     "shell.execute_reply.started": "2022-03-07T06:19:56.442683Z"
    }
   },
   "source": [
    "#### <font color = 'blue'> Multi Head Attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-07T00:06:41.510426Z",
     "iopub.status.busy": "2022-03-07T00:06:41.510268Z",
     "iopub.status.idle": "2022-03-07T00:06:41.513328Z",
     "shell.execute_reply": "2022-03-07T00:06:41.512871Z",
     "shell.execute_reply.started": "2022-03-07T00:06:41.510413Z"
    }
   },
   "source": [
    "<font  size =3, color ='green'>**Implementing MultiHeadAttention using Pytorch Layer**\n",
    "Limitation: hid_dim == output_hid_dim.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T16:52:50.082861Z",
     "iopub.status.busy": "2022-04-02T16:52:50.082708Z",
     "iopub.status.idle": "2022-04-02T16:52:50.085430Z",
     "shell.execute_reply": "2022-04-02T16:52:50.085080Z",
     "shell.execute_reply.started": "2022-04-02T16:52:50.082848Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "hid_dim = 8\n",
    "n_heads = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T16:52:50.325822Z",
     "iopub.status.busy": "2022-04-02T16:52:50.325662Z",
     "iopub.status.idle": "2022-04-02T16:52:50.329151Z",
     "shell.execute_reply": "2022-04-02T16:52:50.328779Z",
     "shell.execute_reply.started": "2022-04-02T16:52:50.325794Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "multihead_attnetion_layer = torch.nn.MultiheadAttention(embed_dim=hid_dim, num_heads=n_heads, \n",
    "                                                        dropout=0.0, \n",
    "                                                        bias=True, add_bias_kv=False, \n",
    "                                                        add_zero_attn=False, kdim=None, \n",
    "                                                        vdim=None, batch_first=True, \n",
    "                                                        device=device, dtype=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = 3, color = 'green'>It combines Q, Kand V into one metrics. To compare the results, we need to make sure that initial merices are the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T16:52:51.310069Z",
     "iopub.status.busy": "2022-04-02T16:52:51.309913Z",
     "iopub.status.idle": "2022-04-02T16:52:51.313710Z",
     "shell.execute_reply": "2022-04-02T16:52:51.313422Z",
     "shell.execute_reply.started": "2022-04-02T16:52:51.310055Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in_proj_weight torch.Size([24, 8])\n",
      "in_proj_bias torch.Size([24])\n",
      "out_proj.weight torch.Size([8, 8])\n",
      "out_proj.bias torch.Size([8])\n"
     ]
    }
   ],
   "source": [
    "for name, parameter in multihead_attnetion_layer.named_parameters():\n",
    "    print(name, parameter.data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T16:52:51.526639Z",
     "iopub.status.busy": "2022-04-02T16:52:51.526443Z",
     "iopub.status.idle": "2022-04-02T16:52:51.529898Z",
     "shell.execute_reply": "2022-04-02T16:52:51.529535Z",
     "shell.execute_reply.started": "2022-04-02T16:52:51.526612Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SRC_PAD_IDX = target_vocab['<SRC>']\n",
    "SRC_PAD_IDX "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = 'green'> Index where we will apply mask i.e. not pay attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T16:52:51.924580Z",
     "iopub.status.busy": "2022-04-02T16:52:51.924456Z",
     "iopub.status.idle": "2022-04-02T16:52:51.927126Z",
     "shell.execute_reply": "2022-04-02T16:52:51.926792Z",
     "shell.execute_reply.started": "2022-04-02T16:52:51.924566Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "src_pad_mask = (src== SRC_PAD_IDX )\n",
    "src_pad_mask = src_pad_mask.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T16:52:52.126425Z",
     "iopub.status.busy": "2022-04-02T16:52:52.126224Z",
     "iopub.status.idle": "2022-04-02T16:52:52.130405Z",
     "shell.execute_reply": "2022-04-02T16:52:52.130126Z",
     "shell.execute_reply.started": "2022-04-02T16:52:52.126407Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False],\n",
       "        [False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False]], device='cuda:0')"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src_pad_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T16:52:52.342773Z",
     "iopub.status.busy": "2022-04-02T16:52:52.342617Z",
     "iopub.status.idle": "2022-04-02T16:52:52.346393Z",
     "shell.execute_reply": "2022-04-02T16:52:52.346118Z",
     "shell.execute_reply.started": "2022-04-02T16:52:52.342759Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 12])"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src_pad_mask.shape\n",
    "# batchsize, seq_len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = 'green'> Here we only need src_pad_mask. The query will not pay attention to pad tokens of source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T16:52:52.775207Z",
     "iopub.status.busy": "2022-04-02T16:52:52.775019Z",
     "iopub.status.idle": "2022-04-02T16:52:52.778456Z",
     "shell.execute_reply": "2022-04-02T16:52:52.778165Z",
     "shell.execute_reply.started": "2022-04-02T16:52:52.775194Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "decoder_enc_att_output, decoder_enc_att_probs = multihead_attnetion_layer (\n",
    "                                              query=decoder_self_att_plus_input_normalized,\n",
    "                                              key=encoder_layer_output,\n",
    "                                              value=encoder_layer_output, \n",
    "                                              key_padding_mask=src_pad_mask, \n",
    "                                              need_weights=True, \n",
    "                                              attn_mask=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T16:52:52.998295Z",
     "iopub.status.busy": "2022-04-02T16:52:52.998119Z",
     "iopub.status.idle": "2022-04-02T16:52:53.002189Z",
     "shell.execute_reply": "2022-04-02T16:52:53.001703Z",
     "shell.execute_reply.started": "2022-04-02T16:52:52.998281Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.1441,  0.1203, -0.0382,  0.0077,  0.0479, -0.1381, -0.1649,  0.0225],\n",
       "       device='cuda:0', grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_enc_att_output[1,12,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = 3, color = 'green'> **Last word in first sentence of target can pay attention to all the words of source except last three words as last three words are pad tokens**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T16:52:53.791725Z",
     "iopub.status.busy": "2022-04-02T16:52:53.791598Z",
     "iopub.status.idle": "2022-04-02T16:52:53.795558Z",
     "shell.execute_reply": "2022-04-02T16:52:53.795230Z",
     "shell.execute_reply.started": "2022-04-02T16:52:53.791710Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0883, 0.0860, 0.0854, 0.0795, 0.0856, 0.0767, 0.0878, 0.0778, 0.0777,\n",
       "        0.0891, 0.0822, 0.0840], device='cuda:0', grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_enc_att_probs[0,12,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = 3, color = 'green'> **Last word in second sentence OF target can pay attention to all the words of teh source as this sentence has no pad tokens**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T16:52:54.460203Z",
     "iopub.status.busy": "2022-04-02T16:52:54.460050Z",
     "iopub.status.idle": "2022-04-02T16:52:54.464538Z",
     "shell.execute_reply": "2022-04-02T16:52:54.464100Z",
     "shell.execute_reply.started": "2022-04-02T16:52:54.460189Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0814, 0.0804, 0.0882, 0.0843, 0.0853, 0.0858, 0.0787, 0.0862, 0.0812,\n",
       "        0.0831, 0.0808, 0.0846], device='cuda:0', grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_enc_att_probs[1,12,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = 3, color = 'green'> **The probbalitoes sum to 1 as I have kept dropout = 0**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T16:52:55.092808Z",
     "iopub.status.busy": "2022-04-02T16:52:55.092665Z",
     "iopub.status.idle": "2022-04-02T16:52:55.096770Z",
     "shell.execute_reply": "2022-04-02T16:52:55.096487Z",
     "shell.execute_reply.started": "2022-04-02T16:52:55.092795Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1., device='cuda:0', grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_enc_att_probs[1,12,:].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-10T01:00:05.138593Z",
     "iopub.status.busy": "2022-03-10T01:00:05.138451Z",
     "iopub.status.idle": "2022-03-10T01:00:05.140851Z",
     "shell.execute_reply": "2022-03-10T01:00:05.140545Z",
     "shell.execute_reply.started": "2022-03-10T01:00:05.138579Z"
    }
   },
   "source": [
    "#### <font color = 'blue'>  Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T16:52:55.703899Z",
     "iopub.status.busy": "2022-04-02T16:52:55.703745Z",
     "iopub.status.idle": "2022-04-02T16:52:55.706725Z",
     "shell.execute_reply": "2022-04-02T16:52:55.706340Z",
     "shell.execute_reply.started": "2022-04-02T16:52:55.703885Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "decoder_enc_att_dropout = nn.Dropout(p=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color = 'blue'>  Residual Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T16:52:56.120135Z",
     "iopub.status.busy": "2022-04-02T16:52:56.119920Z",
     "iopub.status.idle": "2022-04-02T16:52:56.122809Z",
     "shell.execute_reply": "2022-04-02T16:52:56.122504Z",
     "shell.execute_reply.started": "2022-04-02T16:52:56.120115Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "decoder_enc_att_output_after_dropout = decoder_enc_att_dropout(decoder_enc_att_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T16:52:56.337741Z",
     "iopub.status.busy": "2022-04-02T16:52:56.337591Z",
     "iopub.status.idle": "2022-04-02T16:52:56.339794Z",
     "shell.execute_reply": "2022-04-02T16:52:56.339508Z",
     "shell.execute_reply.started": "2022-04-02T16:52:56.337727Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "decoder_enc_att_plus_input = decoder_self_att_plus_input_normalized + \\\n",
    "                             decoder_enc_att_output_after_dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T16:52:56.538954Z",
     "iopub.status.busy": "2022-04-02T16:52:56.538815Z",
     "iopub.status.idle": "2022-04-02T16:52:56.542158Z",
     "shell.execute_reply": "2022-04-02T16:52:56.541853Z",
     "shell.execute_reply.started": "2022-04-02T16:52:56.538941Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 13, 8])"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_enc_att_plus_input.shape\n",
    "#Batch_size, query_len, hid_dim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color = 'blue'>  Layer_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T16:52:56.935623Z",
     "iopub.status.busy": "2022-04-02T16:52:56.935479Z",
     "iopub.status.idle": "2022-04-02T16:52:56.938800Z",
     "shell.execute_reply": "2022-04-02T16:52:56.938455Z",
     "shell.execute_reply.started": "2022-04-02T16:52:56.935608Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dec_enc_att_layer_norm= nn.LayerNorm(hid_dim).to(device)\n",
    "decoder_enc_att_plus_input_normalized = dec_self_att_layer_norm(decoder_self_att_plus_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T16:52:57.110175Z",
     "iopub.status.busy": "2022-04-02T16:52:57.110020Z",
     "iopub.status.idle": "2022-04-02T16:52:57.113106Z",
     "shell.execute_reply": "2022-04-02T16:52:57.112851Z",
     "shell.execute_reply.started": "2022-04-02T16:52:57.110160Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 13, 8])"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_enc_att_plus_input_normalized.shape\n",
    "#batch_size, query_len, hid_dim]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color = 'blue'> **Decoder Positionwise FeedForward Layer**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-26T20:11:42.017250Z",
     "iopub.status.busy": "2022-03-26T20:11:42.017035Z",
     "iopub.status.idle": "2022-03-26T20:11:42.019269Z",
     "shell.execute_reply": "2022-03-26T20:11:42.018978Z",
     "shell.execute_reply.started": "2022-03-26T20:11:42.017218Z"
    }
   },
   "source": [
    "#### <font color = 'blue'>  Linera Layers and ReLU Activation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T16:52:57.635184Z",
     "iopub.status.busy": "2022-04-02T16:52:57.635058Z",
     "iopub.status.idle": "2022-04-02T16:52:57.639328Z",
     "shell.execute_reply": "2022-04-02T16:52:57.638919Z",
     "shell.execute_reply.started": "2022-04-02T16:52:57.635169Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "pf_dim = 16\n",
    "dec_positionwise_feed_forward_layer = nn.Sequential(nn.Linear(hid_dim, pf_dim),\n",
    "                                nn.ReLU(),\n",
    "                                nn.Dropout(p=0.1),\n",
    "                                nn.Linear(pf_dim, hid_dim)).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T16:52:57.808428Z",
     "iopub.status.busy": "2022-04-02T16:52:57.808287Z",
     "iopub.status.idle": "2022-04-02T16:52:57.811007Z",
     "shell.execute_reply": "2022-04-02T16:52:57.810526Z",
     "shell.execute_reply.started": "2022-04-02T16:52:57.808415Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dec_positionwise_output = dec_positionwise_feed_forward_layer(\n",
    "                                              decoder_enc_att_plus_input_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T16:52:58.003623Z",
     "iopub.status.busy": "2022-04-02T16:52:58.003471Z",
     "iopub.status.idle": "2022-04-02T16:52:58.007096Z",
     "shell.execute_reply": "2022-04-02T16:52:58.006724Z",
     "shell.execute_reply.started": "2022-04-02T16:52:58.003609Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 13, 8])"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dec_positionwise_output.shape\n",
    "# batch_size, query_len(trg_len), hid_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color = 'blue'>  Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T16:52:58.371203Z",
     "iopub.status.busy": "2022-04-02T16:52:58.371062Z",
     "iopub.status.idle": "2022-04-02T16:52:58.374228Z",
     "shell.execute_reply": "2022-04-02T16:52:58.373859Z",
     "shell.execute_reply.started": "2022-04-02T16:52:58.371190Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "decoder_pos_dropout =  nn.Dropout(p=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T16:52:58.569979Z",
     "iopub.status.busy": "2022-04-02T16:52:58.569855Z",
     "iopub.status.idle": "2022-04-02T16:52:58.572300Z",
     "shell.execute_reply": "2022-04-02T16:52:58.571980Z",
     "shell.execute_reply.started": "2022-04-02T16:52:58.569966Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dec_positionwise_output_after_dropout = decoder_pos_dropout(dec_positionwise_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color = 'blue'>  Residual Connection + Layer Norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T16:52:58.970294Z",
     "iopub.status.busy": "2022-04-02T16:52:58.970135Z",
     "iopub.status.idle": "2022-04-02T16:52:58.973862Z",
     "shell.execute_reply": "2022-04-02T16:52:58.973399Z",
     "shell.execute_reply.started": "2022-04-02T16:52:58.970280Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "norm_layer_decoder_pos = nn.LayerNorm(hid_dim).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T16:52:59.170829Z",
     "iopub.status.busy": "2022-04-02T16:52:59.170705Z",
     "iopub.status.idle": "2022-04-02T16:52:59.173662Z",
     "shell.execute_reply": "2022-04-02T16:52:59.173225Z",
     "shell.execute_reply.started": "2022-04-02T16:52:59.170816Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dec_positionwise_plus_input_norm = norm_layer_decoder_pos(\n",
    "                                     dec_positionwise_output_after_dropout + \n",
    "                                     decoder_enc_att_plus_input_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T16:52:59.373207Z",
     "iopub.status.busy": "2022-04-02T16:52:59.373056Z",
     "iopub.status.idle": "2022-04-02T16:52:59.376010Z",
     "shell.execute_reply": "2022-04-02T16:52:59.375593Z",
     "shell.execute_reply.started": "2022-04-02T16:52:59.373193Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 13, 8])"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dec_positionwise_plus_input_norm.shape\n",
    "# batch_size, query_len(trg_len), hid_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color = 'blue'> **Decoder Final Linear Layer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T16:52:59.733056Z",
     "iopub.status.busy": "2022-04-02T16:52:59.732915Z",
     "iopub.status.idle": "2022-04-02T16:52:59.735746Z",
     "shell.execute_reply": "2022-04-02T16:52:59.735387Z",
     "shell.execute_reply.started": "2022-04-02T16:52:59.733042Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "final_linear_layer = nn.Linear(hid_dim, len(target_vocab)).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T16:52:59.967696Z",
     "iopub.status.busy": "2022-04-02T16:52:59.967533Z",
     "iopub.status.idle": "2022-04-02T16:52:59.970378Z",
     "shell.execute_reply": "2022-04-02T16:52:59.969921Z",
     "shell.execute_reply.started": "2022-04-02T16:52:59.967682Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "decoder_output = final_linear_layer(dec_positionwise_plus_input_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T16:53:00.172574Z",
     "iopub.status.busy": "2022-04-02T16:53:00.172431Z",
     "iopub.status.idle": "2022-04-02T16:53:00.175570Z",
     "shell.execute_reply": "2022-04-02T16:53:00.175122Z",
     "shell.execute_reply.started": "2022-04-02T16:53:00.172560Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 13, 40])"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_output.shape\n",
    "# batch, seq_len, vocab_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color = 'blue'> **Loss Calculation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Original Sequence: $trg = [sos, x_1, x_2, x_3, eos]$ <br>\n",
    "Input to Model: $trg[:-1][sos, x_1, x_2, x_3]$  <br>\n",
    "Predicted Values: $[y_1, y_2, y_3, eos]$<br>\n",
    "Lable or True y : $trg[1:] = [x_1, x_2, x_3, eos]$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T16:53:00.774340Z",
     "iopub.status.busy": "2022-04-02T16:53:00.774209Z",
     "iopub.status.idle": "2022-04-02T16:53:00.777367Z",
     "shell.execute_reply": "2022-04-02T16:53:00.777105Z",
     "shell.execute_reply.started": "2022-04-02T16:53:00.774326Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_dim = decoder_output.shape[-1]\n",
    "output_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T16:53:00.971728Z",
     "iopub.status.busy": "2022-04-02T16:53:00.971598Z",
     "iopub.status.idle": "2022-04-02T16:53:00.974253Z",
     "shell.execute_reply": "2022-04-02T16:53:00.973860Z",
     "shell.execute_reply.started": "2022-04-02T16:53:00.971714Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "output = decoder_output.contiguous().view(-1, output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T16:53:01.173072Z",
     "iopub.status.busy": "2022-04-02T16:53:01.172933Z",
     "iopub.status.idle": "2022-04-02T16:53:01.175741Z",
     "shell.execute_reply": "2022-04-02T16:53:01.175454Z",
     "shell.execute_reply.started": "2022-04-02T16:53:01.173060Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([26, 40])"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T16:53:01.372836Z",
     "iopub.status.busy": "2022-04-02T16:53:01.372697Z",
     "iopub.status.idle": "2022-04-02T16:53:01.375775Z",
     "shell.execute_reply": "2022-04-02T16:53:01.375338Z",
     "shell.execute_reply.started": "2022-04-02T16:53:01.372823Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 14])"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T16:53:01.572761Z",
     "iopub.status.busy": "2022-04-02T16:53:01.572639Z",
     "iopub.status.idle": "2022-04-02T16:53:01.576456Z",
     "shell.execute_reply": "2022-04-02T16:53:01.576202Z",
     "shell.execute_reply.started": "2022-04-02T16:53:01.572747Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1, 21, 25, 26, 27, 28, 21, 29, 30, 14,  2,  3,  3,  3],\n",
       "        [ 1, 15, 16, 17, 18, 19,  9, 20, 21, 22, 23, 24, 14,  2]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = 'green'> Remove <BOS> token from trg for loss computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T16:53:01.982525Z",
     "iopub.status.busy": "2022-04-02T16:53:01.982364Z",
     "iopub.status.idle": "2022-04-02T16:53:01.985221Z",
     "shell.execute_reply": "2022-04-02T16:53:01.984853Z",
     "shell.execute_reply.started": "2022-04-02T16:53:01.982510Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "trg_y = trg[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T16:53:02.185122Z",
     "iopub.status.busy": "2022-04-02T16:53:02.184999Z",
     "iopub.status.idle": "2022-04-02T16:53:02.188931Z",
     "shell.execute_reply": "2022-04-02T16:53:02.188570Z",
     "shell.execute_reply.started": "2022-04-02T16:53:02.185109Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[21, 25, 26, 27, 28, 21, 29, 30, 14,  2,  3,  3,  3],\n",
       "        [15, 16, 17, 18, 19,  9, 20, 21, 22, 23, 24, 14,  2]], device='cuda:0')"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trg_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T16:53:02.418224Z",
     "iopub.status.busy": "2022-04-02T16:53:02.418068Z",
     "iopub.status.idle": "2022-04-02T16:53:02.421641Z",
     "shell.execute_reply": "2022-04-02T16:53:02.421227Z",
     "shell.execute_reply.started": "2022-04-02T16:53:02.418210Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 13])"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trg_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T16:53:02.621762Z",
     "iopub.status.busy": "2022-04-02T16:53:02.621609Z",
     "iopub.status.idle": "2022-04-02T16:53:02.624462Z",
     "shell.execute_reply": "2022-04-02T16:53:02.624094Z",
     "shell.execute_reply.started": "2022-04-02T16:53:02.621748Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "trg_y = trg_y.contiguous().view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T16:53:02.836398Z",
     "iopub.status.busy": "2022-04-02T16:53:02.836256Z",
     "iopub.status.idle": "2022-04-02T16:53:02.839454Z",
     "shell.execute_reply": "2022-04-02T16:53:02.839078Z",
     "shell.execute_reply.started": "2022-04-02T16:53:02.836385Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([26])"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trg_y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T19:07:51.569319Z",
     "iopub.status.busy": "2022-04-02T19:07:51.569147Z",
     "iopub.status.idle": "2022-04-02T19:07:51.571363Z",
     "shell.execute_reply": "2022-04-02T19:07:51.571079Z",
     "shell.execute_reply.started": "2022-04-02T19:07:51.569290Z"
    }
   },
   "source": [
    "#### <font color = 'blue'> nn.CrossEntropy\n",
    "<font color = 'green'>Note that this case is equivalent to the combination of LogSoftmax and NLLLoss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T16:53:03.596211Z",
     "iopub.status.busy": "2022-04-02T16:53:03.596056Z",
     "iopub.status.idle": "2022-04-02T16:53:03.598848Z",
     "shell.execute_reply": "2022-04-02T16:53:03.598380Z",
     "shell.execute_reply.started": "2022-04-02T16:53:03.596197Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss(ignore_index = TRG_PAD_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T16:55:37.274318Z",
     "iopub.status.busy": "2022-04-02T16:55:37.274133Z",
     "iopub.status.idle": "2022-04-02T16:55:37.296769Z",
     "shell.execute_reply": "2022-04-02T16:55:37.296325Z",
     "shell.execute_reply.started": "2022-04-02T16:55:37.274303Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "loss = criterion(output, trg_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T16:55:43.147377Z",
     "iopub.status.busy": "2022-04-02T16:55:43.146914Z",
     "iopub.status.idle": "2022-04-02T16:55:43.150551Z",
     "shell.execute_reply": "2022-04-02T16:55:43.150259Z",
     "shell.execute_reply.started": "2022-04-02T16:55:43.147360Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.7780, device='cuda:0', grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color = 'blue'> Manual Loss Calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T18:52:46.472913Z",
     "iopub.status.busy": "2022-04-02T18:52:46.472765Z",
     "iopub.status.idle": "2022-04-02T18:52:46.475558Z",
     "shell.execute_reply": "2022-04-02T18:52:46.475078Z",
     "shell.execute_reply.started": "2022-04-02T18:52:46.472898Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def softmax(output):\n",
    "    num = torch.exp(output) # 26, 40 (words, hiddn_dim)\n",
    "    den = torch.sum(num, axis = 1, keepdim= True) #|(26, 1)\n",
    "    return num/den"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T18:53:05.061227Z",
     "iopub.status.busy": "2022-04-02T18:53:05.060956Z",
     "iopub.status.idle": "2022-04-02T18:53:05.063405Z",
     "shell.execute_reply": "2022-04-02T18:53:05.063111Z",
     "shell.execute_reply.started": "2022-04-02T18:53:05.061210Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def crossentropy_m(prob, y):\n",
    "    return - torch.log(prob[range(len(y)), y]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T18:53:06.307566Z",
     "iopub.status.busy": "2022-04-02T18:53:06.306990Z",
     "iopub.status.idle": "2022-04-02T18:53:06.314897Z",
     "shell.execute_reply": "2022-04-02T18:53:06.314413Z",
     "shell.execute_reply.started": "2022-04-02T18:53:06.307550Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "loss_m = crossentropy_m(softmax(output), trg_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T18:53:06.857140Z",
     "iopub.status.busy": "2022-04-02T18:53:06.856999Z",
     "iopub.status.idle": "2022-04-02T18:53:06.860586Z",
     "shell.execute_reply": "2022-04-02T18:53:06.860326Z",
     "shell.execute_reply.started": "2022-04-02T18:53:06.857127Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.7797, device='cuda:0', grad_fn=<NegBackward0>)"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T19:10:11.346912Z",
     "iopub.status.busy": "2022-04-02T19:10:11.346724Z",
     "iopub.status.idle": "2022-04-02T19:10:11.349096Z",
     "shell.execute_reply": "2022-04-02T19:10:11.348730Z",
     "shell.execute_reply.started": "2022-04-02T19:10:11.346897Z"
    }
   },
   "source": [
    "#### <font color = 'blue'> Stable Manual Calculations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$${\\displaystyle \\mathrm {LSE} (x_{1},\\dots ,x_{n})=x^{*}+\\log \\left(\\exp(x_{1}-x^{*})+\\cdots +\\exp(x_{n}-x^{*})\\right)}$$\n",
    "where $$ {\\displaystyle x^{*}=\\max {\\{x_{1},\\dots ,x_{n}\\}}}{\\displaystyle x^{*}=\\max {\\{x_{1},\\dots ,x_{n}\\}}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T19:10:30.189714Z",
     "iopub.status.busy": "2022-04-02T19:10:30.189525Z",
     "iopub.status.idle": "2022-04-02T19:10:30.209233Z",
     "shell.execute_reply": "2022-04-02T19:10:30.208861Z",
     "shell.execute_reply.started": "2022-04-02T19:10:30.189699Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([26, 1])"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.log(torch.sum(torch.exp(output-max_output), dim = 1, keepdim=True)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T19:10:30.626113Z",
     "iopub.status.busy": "2022-04-02T19:10:30.625907Z",
     "iopub.status.idle": "2022-04-02T19:10:30.629383Z",
     "shell.execute_reply": "2022-04-02T19:10:30.628994Z",
     "shell.execute_reply.started": "2022-04-02T19:10:30.626098Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def crossentropy_softmax(output, y):\n",
    "    max_output, _ = torch.max(output, dim = 1, keepdim=True)\n",
    "    \n",
    "    neglogp =  -(output[range(len(y)), y]- (max_output + \n",
    "                           torch.log(torch.sum(torch.exp(output-max_output), \n",
    "                                               dim = 1, keepdim=True))))\n",
    "    return neglogp.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T19:10:31.027557Z",
     "iopub.status.busy": "2022-04-02T19:10:31.027368Z",
     "iopub.status.idle": "2022-04-02T19:10:31.031317Z",
     "shell.execute_reply": "2022-04-02T19:10:31.030943Z",
     "shell.execute_reply.started": "2022-04-02T19:10:31.027543Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.7797, device='cuda:0', grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crossentropy_softmax(output, trg_y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pt10",
   "language": "python",
   "name": "pt10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
